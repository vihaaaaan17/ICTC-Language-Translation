{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ben</th>\n",
       "      <th>guj</th>\n",
       "      <th>hin</th>\n",
       "      <th>kan</th>\n",
       "      <th>mal</th>\n",
       "      <th>ori</th>\n",
       "      <th>pan</th>\n",
       "      <th>tam</th>\n",
       "      <th>tel</th>\n",
       "      <th>urd</th>\n",
       "      <th>eng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sidny opera houser ashpashe thaka suijarlander...</td>\n",
       "      <td>sydney opera house aaspaasma yojayeli spardham...</td>\n",
       "      <td>sidney opera house kii prishthbhumi main switz...</td>\n",
       "      <td>sydney opera housein avarandalli aayojislagidd...</td>\n",
       "      <td>sydney oppara hasiൻre parisarsliൽwech, switzeർ...</td>\n",
       "      <td>sidni opera houser pariveshtani madhyare anust...</td>\n",
       "      <td>sidney opera house de aale-duale sthit svissza...</td>\n",
       "      <td>sidney opera housein suzlil natant ant vilyatl...</td>\n",
       "      <td>sydney opera house parisarall jarigin i kridal...</td>\n",
       "      <td>sidney opera house ke gurdonvah main kaayam, s...</td>\n",
       "      <td>Set in the surroundings of the Sydney Opera Ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>con jivanu upar kaaj karbe sei anuyayi aigulo ...</td>\n",
       "      <td>sukshmajivanuona jooth par karaati asarne aadh...</td>\n",
       "      <td>jin sookshmaanuon ke samooh par ye kaam karti ...</td>\n",
       "      <td>ivugannu avu prenam biruv sookshmajivi gumpige...</td>\n",
       "      <td>badhikkunn sukshmajiviute waർggae atisthanmaki...</td>\n",
       "      <td>yeun bhootaanu goshthigudik upare eha kaam kar...</td>\n",
       "      <td>inhan nuun anti- vistyle, anti- fungel, anti-p...</td>\n",
       "      <td>ews ent vaka nunnurigolin midhu vinapurikinden...</td>\n",
       "      <td>ivi prabhavan chupe sukshmajivas samuhaniki an...</td>\n",
       "      <td>inhen in jaraasam ke group ke lihaaz se jin pa...</td>\n",
       "      <td>These are classified as anti-virals, anti-fung...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bharter drut arth lenden vyavastha- upiai-ke a...</td>\n",
       "      <td>bharat bhugatan vyavasthao anaya adhikarakshet...</td>\n",
       "      <td>bharat kii sabase twarit bhugtan pranali - upi...</td>\n",
       "      <td>bharatad vegavad pavati vyavastheyad you.pi.i....</td>\n",
       "      <td>indiaille pettennu panamadaykanavunn nilevilul...</td>\n",
       "      <td>bharatar drut arth pradaan brivastha - eu.pi.a...</td>\n",
       "      <td>bharat de bhugtan karan wale shaylia da doosar...</td>\n",
       "      <td>indiavin yubis enepatum duridab panamseluttal ...</td>\n",
       "      <td>saguthunn bharat shighra chellimp vidhana - yu...</td>\n",
       "      <td>bhaarat ke adaegi ke nizaam ko digar dayera ak...</td>\n",
       "      <td>The possibility of linking India's payment sys...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fasal-poorvavarti evan fasal-paravarty caryakr...</td>\n",
       "      <td>paak poorveni ane paak pachhini pravrittio mat...</td>\n",
       "      <td>fasal kii kataai se pehle or uske baad die jan...</td>\n",
       "      <td>coylige munchin hagu coylen nantarad chatuvati...</td>\n",
       "      <td>villvetuppinumumpu villvetuppinusheavumulla pr...</td>\n",
       "      <td>amal-poorvavartti tatha amal-paravartti karyan...</td>\n",
       "      <td>fasal di kataai ton pihala ate bood vich us te...</td>\n",
       "      <td>aruvadiku mundaiy manllum bindaiy seyalbadugal...</td>\n",
       "      <td>pantakotku mundu, taruvati panul koraku ichche...</td>\n",
       "      <td>kataai se kabel or kataai ke baad kii sargharm...</td>\n",
       "      <td>Loans for pre-harvest and post-harvest activit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>maldwar parikshar paddhati ekati drut paddhati...</td>\n",
       "      <td>gudamarg deetha thati tapas ek jhadpi padhdhat...</td>\n",
       "      <td>malashay-sambandhi pareekshan ek twarit vidhi ...</td>\n",
       "      <td>antah-gudnal pariksheyu kshipravad vidhanvagid...</td>\n",
       "      <td>computaർ samvidhana upyogitchull gudaparishodh...</td>\n",
       "      <td>malashai pariksha eka trit paddhati ate (jane ...</td>\n",
       "      <td>andakosh sambandi nirikhan ik jaladi on vaali ...</td>\n",
       "      <td>asana malakutal parichodanai woru viraivana va...</td>\n",
       "      <td>purishanalam dwara pariksh ock satvar vidhana ...</td>\n",
       "      <td>par-ractil maan ek tej tareeq car hai (ek taju...</td>\n",
       "      <td>The per-rectal examination is a quick method (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1695</th>\n",
       "      <td>1980-r dashake, spanish sanstha asperanja i si...</td>\n",
       "      <td>1980na dayakama spaini company esparanza vaaya...</td>\n",
       "      <td>1980 ke dashak main spani form esparanza vaai ...</td>\n",
       "      <td>1980r dashakadalli, spanish sanstheyad esperan...</td>\n",
       "      <td>1980kaliൽ spanish companyyay asperaൻsaa i sia ...</td>\n",
       "      <td>1980 dashakare, speniya bavasaik pratishthan '...</td>\n",
       "      <td>1980 de dashak vich, spani waparik sanstha asp...</td>\n",
       "      <td>1980kalil, esbarunse sia enjh spain niruvanum ...</td>\n",
       "      <td>1980lalo, spanish sansth ayin asperanja vai si...</td>\n",
       "      <td>1980 kii duhai main haspaanvi firam aspiranzai...</td>\n",
       "      <td>In the 1980s, the Spanish firm Esperanza y Cia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1696</th>\n",
       "      <td>yakhan o game khelena, takhan o sadharant gane...</td>\n",
       "      <td>jayaare e games nathi ramato hoto, tyaare sama...</td>\n",
       "      <td>jab wo game nahin kheltaa he, tab aksar wo gan...</td>\n",
       "      <td>avnu games adod bitre, samanya yavdadru hadin ...</td>\n",
       "      <td>gainsonnu kalicatt nerat avan palpposhu ganath...</td>\n",
       "      <td>se yetevela khelunathae, sadharanthati se kete...</td>\n",
       "      <td>jadon uh kheds nahi khed riha hunda, uh aam fo...</td>\n",
       "      <td>games vilyadadabodhu avan sangit reyality shok...</td>\n",
       "      <td>atle adnapp, mamuluga wadu patal rialati shol ...</td>\n",
       "      <td>jab wo gamiz naheen khel raha ho, to is vakt w...</td>\n",
       "      <td>When he is not playing games, he usually watch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697</th>\n",
       "      <td>analine avedan kara yave.</td>\n",
       "      <td>araji online kari shako chho.</td>\n",
       "      <td>online applai kar sakate hai.</td>\n",
       "      <td>arjienne online sallisbahudu.</td>\n",
       "      <td>apeksh onjainai samarppicam.</td>\n",
       "      <td>aavedan analinre karayai parib |</td>\n",
       "      <td>arzi anline diti jaa sakadi hai|</td>\n",
       "      <td>nings onlinil abla seielam.</td>\n",
       "      <td>darkhastu andine lo chesukovacchu,</td>\n",
       "      <td>darkhwaast aan line daakhil kii jaa sakati hai.</td>\n",
       "      <td>Application can be done online.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1698</th>\n",
       "      <td>ei inguli conorkam asarkari rajnaitik caryakal...</td>\n",
       "      <td>aa kaayadaaoe koipan bin-sarakaari rajakiya pr...</td>\n",
       "      <td>yah kanoon kathorta se kisi bhi gaiyr-sarkari ...</td>\n",
       "      <td>i kanoonugalu yavude sarkaretar rajakiya chatu...</td>\n",
       "      <td>ella sarkkaritar rashtriyapravarthanvu i niyam...</td>\n",
       "      <td>ehi aaingudik teevrabhave yekunsi besalkari ra...</td>\n",
       "      <td>inhan kanunnas ne kise ve gair-sarkari rajniti...</td>\n",
       "      <td>indech chattas arasu chara arasiel seyalbadus ...</td>\n",
       "      <td>i chattal atuvanti prabhuthvetar rajkiya karya...</td>\n",
       "      <td>in kavanian ne kisi bhi gair sarkari siyaasi s...</td>\n",
       "      <td>These laws sharply circumscribed any non-gover...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>harry ken o san heu-min ki tader dakshata die ...</td>\n",
       "      <td>shun heri ken ane san hyung-min temani gunavat...</td>\n",
       "      <td>kya harry ken or son hyung-min apni gunvattta ...</td>\n",
       "      <td>harry ken mattu sun hyang-min tamm utkrisht aa...</td>\n",
       "      <td>tangute gunnilvarankond haari keinu son hung m...</td>\n",
       "      <td>hari ken eban san hung-min nij gun dra ka'na m...</td>\n",
       "      <td>ki herry can ate san heung - min apni kasiit n...</td>\n",
       "      <td>harri canum san hiyung minnum tangas dharaman ...</td>\n",
       "      <td>hyari kein mariyu sun hung-min tam samarthyant...</td>\n",
       "      <td>kiya harry ken or son haung man melon ko apne ...</td>\n",
       "      <td>Will Harry Kane and Son Heung-min blow Milan a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1700 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    ben  \\\n",
       "0     sidny opera houser ashpashe thaka suijarlander...   \n",
       "1     con jivanu upar kaaj karbe sei anuyayi aigulo ...   \n",
       "2     bharter drut arth lenden vyavastha- upiai-ke a...   \n",
       "3     fasal-poorvavarti evan fasal-paravarty caryakr...   \n",
       "4     maldwar parikshar paddhati ekati drut paddhati...   \n",
       "...                                                 ...   \n",
       "1695  1980-r dashake, spanish sanstha asperanja i si...   \n",
       "1696  yakhan o game khelena, takhan o sadharant gane...   \n",
       "1697                          analine avedan kara yave.   \n",
       "1698  ei inguli conorkam asarkari rajnaitik caryakal...   \n",
       "1699  harry ken o san heu-min ki tader dakshata die ...   \n",
       "\n",
       "                                                    guj  \\\n",
       "0     sydney opera house aaspaasma yojayeli spardham...   \n",
       "1     sukshmajivanuona jooth par karaati asarne aadh...   \n",
       "2     bharat bhugatan vyavasthao anaya adhikarakshet...   \n",
       "3     paak poorveni ane paak pachhini pravrittio mat...   \n",
       "4     gudamarg deetha thati tapas ek jhadpi padhdhat...   \n",
       "...                                                 ...   \n",
       "1695  1980na dayakama spaini company esparanza vaaya...   \n",
       "1696  jayaare e games nathi ramato hoto, tyaare sama...   \n",
       "1697                      araji online kari shako chho.   \n",
       "1698  aa kaayadaaoe koipan bin-sarakaari rajakiya pr...   \n",
       "1699  shun heri ken ane san hyung-min temani gunavat...   \n",
       "\n",
       "                                                    hin  \\\n",
       "0     sidney opera house kii prishthbhumi main switz...   \n",
       "1     jin sookshmaanuon ke samooh par ye kaam karti ...   \n",
       "2     bharat kii sabase twarit bhugtan pranali - upi...   \n",
       "3     fasal kii kataai se pehle or uske baad die jan...   \n",
       "4     malashay-sambandhi pareekshan ek twarit vidhi ...   \n",
       "...                                                 ...   \n",
       "1695  1980 ke dashak main spani form esparanza vaai ...   \n",
       "1696  jab wo game nahin kheltaa he, tab aksar wo gan...   \n",
       "1697                      online applai kar sakate hai.   \n",
       "1698  yah kanoon kathorta se kisi bhi gaiyr-sarkari ...   \n",
       "1699  kya harry ken or son hyung-min apni gunvattta ...   \n",
       "\n",
       "                                                    kan  \\\n",
       "0     sydney opera housein avarandalli aayojislagidd...   \n",
       "1     ivugannu avu prenam biruv sookshmajivi gumpige...   \n",
       "2     bharatad vegavad pavati vyavastheyad you.pi.i....   \n",
       "3     coylige munchin hagu coylen nantarad chatuvati...   \n",
       "4     antah-gudnal pariksheyu kshipravad vidhanvagid...   \n",
       "...                                                 ...   \n",
       "1695  1980r dashakadalli, spanish sanstheyad esperan...   \n",
       "1696  avnu games adod bitre, samanya yavdadru hadin ...   \n",
       "1697                      arjienne online sallisbahudu.   \n",
       "1698  i kanoonugalu yavude sarkaretar rajakiya chatu...   \n",
       "1699  harry ken mattu sun hyang-min tamm utkrisht aa...   \n",
       "\n",
       "                                                    mal  \\\n",
       "0     sydney oppara hasiൻre parisarsliൽwech, switzeർ...   \n",
       "1     badhikkunn sukshmajiviute waർggae atisthanmaki...   \n",
       "2     indiaille pettennu panamadaykanavunn nilevilul...   \n",
       "3     villvetuppinumumpu villvetuppinusheavumulla pr...   \n",
       "4     computaർ samvidhana upyogitchull gudaparishodh...   \n",
       "...                                                 ...   \n",
       "1695  1980kaliൽ spanish companyyay asperaൻsaa i sia ...   \n",
       "1696  gainsonnu kalicatt nerat avan palpposhu ganath...   \n",
       "1697                       apeksh onjainai samarppicam.   \n",
       "1698  ella sarkkaritar rashtriyapravarthanvu i niyam...   \n",
       "1699  tangute gunnilvarankond haari keinu son hung m...   \n",
       "\n",
       "                                                    ori  \\\n",
       "0     sidni opera houser pariveshtani madhyare anust...   \n",
       "1     yeun bhootaanu goshthigudik upare eha kaam kar...   \n",
       "2     bharatar drut arth pradaan brivastha - eu.pi.a...   \n",
       "3     amal-poorvavartti tatha amal-paravartti karyan...   \n",
       "4     malashai pariksha eka trit paddhati ate (jane ...   \n",
       "...                                                 ...   \n",
       "1695  1980 dashakare, speniya bavasaik pratishthan '...   \n",
       "1696  se yetevela khelunathae, sadharanthati se kete...   \n",
       "1697                   aavedan analinre karayai parib |   \n",
       "1698  ehi aaingudik teevrabhave yekunsi besalkari ra...   \n",
       "1699  hari ken eban san hung-min nij gun dra ka'na m...   \n",
       "\n",
       "                                                    pan  \\\n",
       "0     sidney opera house de aale-duale sthit svissza...   \n",
       "1     inhan nuun anti- vistyle, anti- fungel, anti-p...   \n",
       "2     bharat de bhugtan karan wale shaylia da doosar...   \n",
       "3     fasal di kataai ton pihala ate bood vich us te...   \n",
       "4     andakosh sambandi nirikhan ik jaladi on vaali ...   \n",
       "...                                                 ...   \n",
       "1695  1980 de dashak vich, spani waparik sanstha asp...   \n",
       "1696  jadon uh kheds nahi khed riha hunda, uh aam fo...   \n",
       "1697                   arzi anline diti jaa sakadi hai|   \n",
       "1698  inhan kanunnas ne kise ve gair-sarkari rajniti...   \n",
       "1699  ki herry can ate san heung - min apni kasiit n...   \n",
       "\n",
       "                                                    tam  \\\n",
       "0     sidney opera housein suzlil natant ant vilyatl...   \n",
       "1     ews ent vaka nunnurigolin midhu vinapurikinden...   \n",
       "2     indiavin yubis enepatum duridab panamseluttal ...   \n",
       "3     aruvadiku mundaiy manllum bindaiy seyalbadugal...   \n",
       "4     asana malakutal parichodanai woru viraivana va...   \n",
       "...                                                 ...   \n",
       "1695  1980kalil, esbarunse sia enjh spain niruvanum ...   \n",
       "1696  games vilyadadabodhu avan sangit reyality shok...   \n",
       "1697                        nings onlinil abla seielam.   \n",
       "1698  indech chattas arasu chara arasiel seyalbadus ...   \n",
       "1699  harri canum san hiyung minnum tangas dharaman ...   \n",
       "\n",
       "                                                    tel  \\\n",
       "0     sydney opera house parisarall jarigin i kridal...   \n",
       "1     ivi prabhavan chupe sukshmajivas samuhaniki an...   \n",
       "2     saguthunn bharat shighra chellimp vidhana - yu...   \n",
       "3     pantakotku mundu, taruvati panul koraku ichche...   \n",
       "4     purishanalam dwara pariksh ock satvar vidhana ...   \n",
       "...                                                 ...   \n",
       "1695  1980lalo, spanish sansth ayin asperanja vai si...   \n",
       "1696  atle adnapp, mamuluga wadu patal rialati shol ...   \n",
       "1697                 darkhastu andine lo chesukovacchu,   \n",
       "1698  i chattal atuvanti prabhuthvetar rajkiya karya...   \n",
       "1699  hyari kein mariyu sun hung-min tam samarthyant...   \n",
       "\n",
       "                                                    urd  \\\n",
       "0     sidney opera house ke gurdonvah main kaayam, s...   \n",
       "1     inhen in jaraasam ke group ke lihaaz se jin pa...   \n",
       "2     bhaarat ke adaegi ke nizaam ko digar dayera ak...   \n",
       "3     kataai se kabel or kataai ke baad kii sargharm...   \n",
       "4     par-ractil maan ek tej tareeq car hai (ek taju...   \n",
       "...                                                 ...   \n",
       "1695  1980 kii duhai main haspaanvi firam aspiranzai...   \n",
       "1696  jab wo gamiz naheen khel raha ho, to is vakt w...   \n",
       "1697    darkhwaast aan line daakhil kii jaa sakati hai.   \n",
       "1698  in kavanian ne kisi bhi gair sarkari siyaasi s...   \n",
       "1699  kiya harry ken or son haung man melon ko apne ...   \n",
       "\n",
       "                                                    eng  \n",
       "0     Set in the surroundings of the Sydney Opera Ho...  \n",
       "1     These are classified as anti-virals, anti-fung...  \n",
       "2     The possibility of linking India's payment sys...  \n",
       "3     Loans for pre-harvest and post-harvest activit...  \n",
       "4     The per-rectal examination is a quick method (...  \n",
       "...                                                 ...  \n",
       "1695  In the 1980s, the Spanish firm Esperanza y Cia...  \n",
       "1696  When he is not playing games, he usually watch...  \n",
       "1697                    Application can be done online.  \n",
       "1698  These laws sharply circumscribed any non-gover...  \n",
       "1699  Will Harry Kane and Son Heung-min blow Milan a...  \n",
       "\n",
       "[1700 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(r\"C:\\Users\\agrvi\\Downloads\\train.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ben', 'guj', 'hin', 'kan', 'mal', 'ori', 'pan', 'tam', 'tel', 'urd',\n",
       "       'eng'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ben': 0, 'guj': 1, 'hin': 2, 'kan': 3, 'mal': 4, 'ori': 5, 'pan': 6, 'tam': 7, 'tel': 8, 'urd': 9, 'eng': 10}\n"
     ]
    }
   ],
   "source": [
    "column_numbers = {col: i for i, col in enumerate(df.columns)}\n",
    "print(column_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "dfs=[]\n",
    "for i,col_name in enumerate(df.columns):\n",
    "    df2=pd.DataFrame({'Comment':df[col_name],'Language_Index': i, 'Language': col_name})\n",
    "    dfs.append(df2)\n",
    "\n",
    "result_df = pd.concat(dfs, ignore_index=True)   \n",
    "print(len(dfs)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 Comment  Language_Index  \\\n",
      "0      sidny opera houser ashpashe thaka suijarlander...               0   \n",
      "1      con jivanu upar kaaj karbe sei anuyayi aigulo ...               0   \n",
      "2      bharter drut arth lenden vyavastha- upiai-ke a...               0   \n",
      "3      fasal-poorvavarti evan fasal-paravarty caryakr...               0   \n",
      "4      maldwar parikshar paddhati ekati drut paddhati...               0   \n",
      "...                                                  ...             ...   \n",
      "18695  In the 1980s, the Spanish firm Esperanza y Cia...              10   \n",
      "18696  When he is not playing games, he usually watch...              10   \n",
      "18697                    Application can be done online.              10   \n",
      "18698  These laws sharply circumscribed any non-gover...              10   \n",
      "18699  Will Harry Kane and Son Heung-min blow Milan a...              10   \n",
      "\n",
      "      Language  \n",
      "0          ben  \n",
      "1          ben  \n",
      "2          ben  \n",
      "3          ben  \n",
      "4          ben  \n",
      "...        ...  \n",
      "18695      eng  \n",
      "18696      eng  \n",
      "18697      eng  \n",
      "18698      eng  \n",
      "18699      eng  \n",
      "\n",
      "[18700 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# this pd dataframe contains all the comments corresponding to the Language_index and Language\n",
    "print(result_df)\n",
    "#result_df.to_csv(r\"C:\\Users\\agrvi\\Downloads\\train_processed.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d22388b1b5964782abcf5f8fb6087ef9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\agrvi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertModel: ['vocab_projector.weight', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing TFDistilBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFDistilBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer 'tf_distil_bert_model_1' (type TFDistilBertModel).\n\nData of type <class 'keras.src.backend.common.keras_tensor.KerasTensor'> is not allowed only (<class 'tensorflow.python.framework.tensor.Tensor'>, <class 'bool'>, <class 'int'>, <class 'transformers.utils.generic.ModelOutput'>, <class 'tuple'>, <class 'list'>, <class 'dict'>, <class 'numpy.ndarray'>) is accepted for input_ids.\n\nCall arguments received by layer 'tf_distil_bert_model_1' (type TFDistilBertModel):\n  • input_ids=['<KerasTensor shape=(None, 128), dtype=int32, sparse=None, name=input_ids>', '<KerasTensor shape=(None, 128), dtype=int32, sparse=None, name=attention_mask>']\n  • attention_mask=None\n  • head_mask=None\n  • inputs_embeds=None\n  • output_attentions=None\n  • output_hidden_states=None\n  • return_dict=None\n  • training=False",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 46\u001b[0m\n\u001b[0;32m     43\u001b[0m attention_mask \u001b[38;5;241m=\u001b[39m Input(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m128\u001b[39m,), dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mint32, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# DistilBERT encoding\u001b[39;00m\n\u001b[1;32m---> 46\u001b[0m distil_bert_output \u001b[38;5;241m=\u001b[39m \u001b[43mdistil_bert_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Add classification head\u001b[39;00m\n\u001b[0;32m     49\u001b[0m output \u001b[38;5;241m=\u001b[39m Dense(num_classes, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m)(distil_bert_output[:, \u001b[38;5;241m0\u001b[39m, :])\n",
      "File \u001b[1;32mc:\\Users\\agrvi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\agrvi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\modeling_tf_utils.py:427\u001b[0m, in \u001b[0;36munpack_inputs.<locals>.run_call_with_unpacked_inputs\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    425\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\n\u001b[1;32m--> 427\u001b[0m unpacked_inputs \u001b[38;5;241m=\u001b[39m \u001b[43minput_processing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_args_and_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    428\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munpacked_inputs)\n",
      "File \u001b[1;32mc:\\Users\\agrvi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\modeling_tf_utils.py:521\u001b[0m, in \u001b[0;36minput_processing\u001b[1;34m(func, config, **kwargs)\u001b[0m\n\u001b[0;32m    519\u001b[0m             output[parameter_names[i]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\n\u001b[0;32m    520\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 521\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    522\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28minput\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not allowed only \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mallowed_types\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is accepted for\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    523\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparameter_names[i]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    524\u001b[0m             )\n\u001b[0;32m    525\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(main_input, Mapping):\n\u001b[0;32m    526\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m main_input:\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer 'tf_distil_bert_model_1' (type TFDistilBertModel).\n\nData of type <class 'keras.src.backend.common.keras_tensor.KerasTensor'> is not allowed only (<class 'tensorflow.python.framework.tensor.Tensor'>, <class 'bool'>, <class 'int'>, <class 'transformers.utils.generic.ModelOutput'>, <class 'tuple'>, <class 'list'>, <class 'dict'>, <class 'numpy.ndarray'>) is accepted for input_ids.\n\nCall arguments received by layer 'tf_distil_bert_model_1' (type TFDistilBertModel):\n  • input_ids=['<KerasTensor shape=(None, 128), dtype=int32, sparse=None, name=input_ids>', '<KerasTensor shape=(None, 128), dtype=int32, sparse=None, name=attention_mask>']\n  • attention_mask=None\n  • head_mask=None\n  • inputs_embeds=None\n  • output_attentions=None\n  • output_hidden_states=None\n  • return_dict=None\n  • training=False"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import TFDistilBertModel, DistilBertTokenizer, DistilBertConfig\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Step 1: Preprocess the data\n",
    "# Load your pandas DataFrame named result_df\n",
    "# Assume 'Comment' is text data and 'Language_Index' is the language label\n",
    "# Convert 'Language_Index' to numerical labels\n",
    "label_encoder = LabelEncoder()\n",
    "result_df['Language_Index'] = label_encoder.fit_transform(result_df['Language_Index'])\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(result_df['Comment'], result_df['Language_Index'], test_size=0.2, random_state=24)\n",
    "\n",
    "# Step 2: Load the pre-trained DistilBERT model\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "config = DistilBertConfig.from_pretrained('distilbert-base-uncased')\n",
    "config.output_hidden_states = False  # Ensure hidden states are not returned\n",
    "distil_bert_model = TFDistilBertModel.from_pretrained('distilbert-base-uncased', config=config, from_pt=True)\n",
    "\n",
    "# # Tokenize input texts\n",
    "# X_train_encoded = tokenizer(X_train.tolist(), truncation=True, padding=True, max_length=128, return_tensors='tf')\n",
    "# X_test_encoded = tokenizer(X_test.tolist(), truncation=True, padding=True, max_length=128, return_tensors='tf')\n",
    "\n",
    "\n",
    "# Tokenize input texts\n",
    "X_train_encoded = tokenizer(X_train.tolist(), truncation=True, padding=True, max_length=128, return_tensors='tf')\n",
    "X_test_encoded = tokenizer(X_test.tolist(), truncation=True, padding=True, max_length=128, return_tensors='tf')\n",
    "\n",
    "# Step 3: Fine-tune the model for language classification\n",
    "# Freeze DistilBERT layers\n",
    "distil_bert_model.trainable = False\n",
    "\n",
    "# Create input layers\n",
    "input_ids = Input(shape=(128,), dtype=tf.int32, name=\"input_ids\")\n",
    "attention_mask = Input(shape=(128,), dtype=tf.int32, name=\"attention_mask\")\n",
    "\n",
    "# DistilBERT encoding\n",
    "distil_bert_output = distil_bert_model([input_ids, attention_mask])[0]\n",
    "\n",
    "# Add classification head\n",
    "output = Dense(num_classes, activation='softmax')(distil_bert_output[:, 0, :])\n",
    "\n",
    "# Create model\n",
    "model = Model(inputs=[input_ids, attention_mask], outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "optimizer = Adam(lr=2e-5)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Step 4: Train and evaluate the model\n",
    "history = model.fit(\n",
    "    [X_train_encoded['input_ids'], X_train_encoded['attention_mask']],\n",
    "    y_train,\n",
    "    validation_data=([X_test_encoded['input_ids'], X_test_encoded['attention_mask']], y_test),\n",
    "    epochs=5,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate([X_test_encoded['input_ids'], X_test_encoded['attention_mask']], y_test)\n",
    "print(f'Test Loss: {test_loss}, Test Accuracy: {test_accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = np.argmax(model.predict([X_test_encoded['input_ids'], X_test_encoded['attention_mask']]), axis=1)\n",
    "\n",
    "# Calculate class-wise F1 scores\n",
    "f1_scores = f1_score(y_test, y_pred, average=None)\n",
    "\n",
    "# Calculate class weights\n",
    "class_counts = np.bincount(y_test)\n",
    "class_weights = class_counts.sum() / (len(class_counts) * class_counts)\n",
    "\n",
    "# Calculate weighted F1 score\n",
    "weighted_f1_score = np.sum(class_weights * f1_scores)\n",
    "\n",
    "print(\"Class-wise F1 Scores:\")\n",
    "print(f1_scores)\n",
    "print(\"Class Weights:\")\n",
    "print(class_weights)\n",
    "print(\"Weighted F1 Score:\", weighted_f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18700 entries, 0 to 18699\n",
      "Data columns (total 3 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   Comment         18700 non-null  object\n",
      " 1   Language_Index  18700 non-null  int64 \n",
      " 2   Language        18700 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 438.4+ KB\n"
     ]
    }
   ],
   "source": [
    "result_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Language_Index</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sidny opera houser ashpashe thaka suijarlander...</td>\n",
       "      <td>0</td>\n",
       "      <td>ben</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>con jivanu upar kaaj karbe sei anuyayi aigulo ...</td>\n",
       "      <td>0</td>\n",
       "      <td>ben</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bharter drut arth lenden vyavastha- upiai-ke a...</td>\n",
       "      <td>0</td>\n",
       "      <td>ben</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fasal-poorvavarti evan fasal-paravarty caryakr...</td>\n",
       "      <td>0</td>\n",
       "      <td>ben</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>maldwar parikshar paddhati ekati drut paddhati...</td>\n",
       "      <td>0</td>\n",
       "      <td>ben</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1695</th>\n",
       "      <td>1980-r dashake, spanish sanstha asperanja i si...</td>\n",
       "      <td>0</td>\n",
       "      <td>ben</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1696</th>\n",
       "      <td>yakhan o game khelena, takhan o sadharant gane...</td>\n",
       "      <td>0</td>\n",
       "      <td>ben</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697</th>\n",
       "      <td>analine avedan kara yave.</td>\n",
       "      <td>0</td>\n",
       "      <td>ben</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1698</th>\n",
       "      <td>ei inguli conorkam asarkari rajnaitik caryakal...</td>\n",
       "      <td>0</td>\n",
       "      <td>ben</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>harry ken o san heu-min ki tader dakshata die ...</td>\n",
       "      <td>0</td>\n",
       "      <td>ben</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1700 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Comment  Language_Index  \\\n",
       "0     sidny opera houser ashpashe thaka suijarlander...               0   \n",
       "1     con jivanu upar kaaj karbe sei anuyayi aigulo ...               0   \n",
       "2     bharter drut arth lenden vyavastha- upiai-ke a...               0   \n",
       "3     fasal-poorvavarti evan fasal-paravarty caryakr...               0   \n",
       "4     maldwar parikshar paddhati ekati drut paddhati...               0   \n",
       "...                                                 ...             ...   \n",
       "1695  1980-r dashake, spanish sanstha asperanja i si...               0   \n",
       "1696  yakhan o game khelena, takhan o sadharant gane...               0   \n",
       "1697                          analine avedan kara yave.               0   \n",
       "1698  ei inguli conorkam asarkari rajnaitik caryakal...               0   \n",
       "1699  harry ken o san heu-min ki tader dakshata die ...               0   \n",
       "\n",
       "     Language  \n",
       "0         ben  \n",
       "1         ben  \n",
       "2         ben  \n",
       "3         ben  \n",
       "4         ben  \n",
       "...       ...  \n",
       "1695      ben  \n",
       "1696      ben  \n",
       "1697      ben  \n",
       "1698      ben  \n",
       "1699      ben  \n",
       "\n",
       "[1700 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df[result_df['Language_Index']==0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X=result_df['Comment']\n",
    "Y=result_df['Language_Index']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vect = vectorizer.fit_transform(X_train)\n",
    "X_test_vect = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train_vect, y_train)\n",
    "pred_nb = nb_classifier.predict(X_test_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier F1 score:  0.9193469276175655\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "rf_classifier = RandomForestClassifier()\n",
    "rf_classifier.fit(X_train_vect, y_train)\n",
    "pred_rf = rf_classifier.predict(X_test_vect)\n",
    "print(\"RandomForestClassifier F1 score: \", f1_score(y_test, pred_rf,average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Obtaining dependency information for xgboost from https://files.pythonhosted.org/packages/24/ec/ad387100fa3cc2b9b81af0829b5ecfe75ec5bb19dd7c19d4fea06fb81802/xgboost-2.0.3-py3-none-win_amd64.whl.metadata\n",
      "  Using cached xgboost-2.0.3-py3-none-win_amd64.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\agrvi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from xgboost) (1.25.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\agrvi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from xgboost) (1.11.1)\n",
      "Downloading xgboost-2.0.3-py3-none-win_amd64.whl (99.8 MB)\n",
      "   ---------------------------------------- 0.0/99.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/99.8 MB 2.6 MB/s eta 0:00:38\n",
      "   ---------------------------------------- 0.2/99.8 MB 2.4 MB/s eta 0:00:43\n",
      "   ---------------------------------------- 0.4/99.8 MB 2.9 MB/s eta 0:00:35\n",
      "   ---------------------------------------- 0.5/99.8 MB 3.3 MB/s eta 0:00:31\n",
      "   ---------------------------------------- 0.8/99.8 MB 3.8 MB/s eta 0:00:27\n",
      "   ---------------------------------------- 1.0/99.8 MB 4.1 MB/s eta 0:00:25\n",
      "    --------------------------------------- 1.4/99.8 MB 4.6 MB/s eta 0:00:22\n",
      "    --------------------------------------- 1.6/99.8 MB 4.8 MB/s eta 0:00:21\n",
      "    --------------------------------------- 1.9/99.8 MB 5.0 MB/s eta 0:00:20\n",
      "    --------------------------------------- 2.2/99.8 MB 5.2 MB/s eta 0:00:19\n",
      "    --------------------------------------- 2.5/99.8 MB 5.4 MB/s eta 0:00:19\n",
      "   - -------------------------------------- 2.5/99.8 MB 5.0 MB/s eta 0:00:20\n",
      "   - -------------------------------------- 2.7/99.8 MB 5.3 MB/s eta 0:00:19\n",
      "   - -------------------------------------- 2.9/99.8 MB 4.9 MB/s eta 0:00:20\n",
      "   - -------------------------------------- 3.1/99.8 MB 4.9 MB/s eta 0:00:20\n",
      "   - -------------------------------------- 3.2/99.8 MB 4.7 MB/s eta 0:00:21\n",
      "   - -------------------------------------- 3.3/99.8 MB 4.8 MB/s eta 0:00:21\n",
      "   - -------------------------------------- 3.3/99.8 MB 4.8 MB/s eta 0:00:21\n",
      "   - -------------------------------------- 3.3/99.8 MB 4.8 MB/s eta 0:00:21\n",
      "   - -------------------------------------- 3.3/99.8 MB 3.9 MB/s eta 0:00:25\n",
      "   - -------------------------------------- 3.9/99.8 MB 4.3 MB/s eta 0:00:23\n",
      "   - -------------------------------------- 3.9/99.8 MB 4.3 MB/s eta 0:00:23\n",
      "   - -------------------------------------- 4.1/99.8 MB 4.1 MB/s eta 0:00:24\n",
      "   - -------------------------------------- 4.2/99.8 MB 4.1 MB/s eta 0:00:24\n",
      "   - -------------------------------------- 4.2/99.8 MB 4.1 MB/s eta 0:00:24\n",
      "   - -------------------------------------- 4.2/99.8 MB 3.9 MB/s eta 0:00:25\n",
      "   - -------------------------------------- 4.3/99.8 MB 3.7 MB/s eta 0:00:27\n",
      "   - -------------------------------------- 4.4/99.8 MB 3.7 MB/s eta 0:00:26\n",
      "   - -------------------------------------- 4.6/99.8 MB 3.7 MB/s eta 0:00:26\n",
      "   - -------------------------------------- 4.9/99.8 MB 3.8 MB/s eta 0:00:25\n",
      "   -- ------------------------------------- 5.3/99.8 MB 4.0 MB/s eta 0:00:24\n",
      "   -- ------------------------------------- 5.6/99.8 MB 4.1 MB/s eta 0:00:24\n",
      "   -- ------------------------------------- 6.0/99.8 MB 4.2 MB/s eta 0:00:23\n",
      "   -- ------------------------------------- 6.3/99.8 MB 4.3 MB/s eta 0:00:22\n",
      "   -- ------------------------------------- 6.7/99.8 MB 4.4 MB/s eta 0:00:21\n",
      "   -- ------------------------------------- 7.1/99.8 MB 4.6 MB/s eta 0:00:21\n",
      "   -- ------------------------------------- 7.5/99.8 MB 4.7 MB/s eta 0:00:20\n",
      "   --- ------------------------------------ 7.8/99.8 MB 4.8 MB/s eta 0:00:20\n",
      "   --- ------------------------------------ 7.8/99.8 MB 4.8 MB/s eta 0:00:20\n",
      "   --- ------------------------------------ 8.1/99.8 MB 4.7 MB/s eta 0:00:20\n",
      "   --- ------------------------------------ 8.3/99.8 MB 4.8 MB/s eta 0:00:20\n",
      "   --- ------------------------------------ 8.6/99.8 MB 4.8 MB/s eta 0:00:19\n",
      "   --- ------------------------------------ 9.1/99.8 MB 4.9 MB/s eta 0:00:19\n",
      "   --- ------------------------------------ 9.3/99.8 MB 5.0 MB/s eta 0:00:19\n",
      "   --- ------------------------------------ 9.7/99.8 MB 5.0 MB/s eta 0:00:18\n",
      "   ---- ----------------------------------- 10.0/99.8 MB 5.1 MB/s eta 0:00:18\n",
      "   ---- ----------------------------------- 10.3/99.8 MB 5.2 MB/s eta 0:00:18\n",
      "   ---- ----------------------------------- 10.6/99.8 MB 5.3 MB/s eta 0:00:17\n",
      "   ---- ----------------------------------- 10.9/99.8 MB 5.4 MB/s eta 0:00:17\n",
      "   ---- ----------------------------------- 11.2/99.8 MB 5.4 MB/s eta 0:00:17\n",
      "   ---- ----------------------------------- 11.5/99.8 MB 5.4 MB/s eta 0:00:17\n",
      "   ---- ----------------------------------- 11.7/99.8 MB 5.5 MB/s eta 0:00:17\n",
      "   ---- ----------------------------------- 12.0/99.8 MB 5.5 MB/s eta 0:00:17\n",
      "   ---- ----------------------------------- 12.2/99.8 MB 5.5 MB/s eta 0:00:17\n",
      "   ---- ----------------------------------- 12.3/99.8 MB 5.3 MB/s eta 0:00:17\n",
      "   ----- ---------------------------------- 12.6/99.8 MB 5.3 MB/s eta 0:00:17\n",
      "   ----- ---------------------------------- 12.6/99.8 MB 5.2 MB/s eta 0:00:17\n",
      "   ----- ---------------------------------- 13.0/99.8 MB 5.2 MB/s eta 0:00:17\n",
      "   ----- ---------------------------------- 13.2/99.8 MB 5.4 MB/s eta 0:00:17\n",
      "   ----- ---------------------------------- 13.2/99.8 MB 5.4 MB/s eta 0:00:17\n",
      "   ----- ---------------------------------- 13.4/99.8 MB 5.3 MB/s eta 0:00:17\n",
      "   ----- ---------------------------------- 13.5/99.8 MB 5.3 MB/s eta 0:00:17\n",
      "   ----- ---------------------------------- 13.5/99.8 MB 5.6 MB/s eta 0:00:16\n",
      "   ----- ---------------------------------- 13.7/99.8 MB 5.6 MB/s eta 0:00:16\n",
      "   ----- ---------------------------------- 13.9/99.8 MB 5.5 MB/s eta 0:00:16\n",
      "   ----- ---------------------------------- 14.1/99.8 MB 5.5 MB/s eta 0:00:16\n",
      "   ----- ---------------------------------- 14.4/99.8 MB 5.6 MB/s eta 0:00:16\n",
      "   ----- ---------------------------------- 14.8/99.8 MB 6.2 MB/s eta 0:00:14\n",
      "   ------ --------------------------------- 15.2/99.8 MB 6.2 MB/s eta 0:00:14\n",
      "   ------ --------------------------------- 15.5/99.8 MB 6.2 MB/s eta 0:00:14\n",
      "   ------ --------------------------------- 15.8/99.8 MB 6.2 MB/s eta 0:00:14\n",
      "   ------ --------------------------------- 16.1/99.8 MB 6.2 MB/s eta 0:00:14\n",
      "   ------ --------------------------------- 16.4/99.8 MB 6.1 MB/s eta 0:00:14\n",
      "   ------ --------------------------------- 16.5/99.8 MB 6.1 MB/s eta 0:00:14\n",
      "   ------ --------------------------------- 16.9/99.8 MB 6.1 MB/s eta 0:00:14\n",
      "   ------ --------------------------------- 17.1/99.8 MB 6.0 MB/s eta 0:00:14\n",
      "   ------ --------------------------------- 17.4/99.8 MB 6.0 MB/s eta 0:00:14\n",
      "   ------- -------------------------------- 17.7/99.8 MB 6.0 MB/s eta 0:00:14\n",
      "   ------- -------------------------------- 18.1/99.8 MB 6.0 MB/s eta 0:00:14\n",
      "   ------- -------------------------------- 18.4/99.8 MB 6.1 MB/s eta 0:00:14\n",
      "   ------- -------------------------------- 18.7/99.8 MB 6.1 MB/s eta 0:00:14\n",
      "   ------- -------------------------------- 19.0/99.8 MB 6.1 MB/s eta 0:00:14\n",
      "   ------- -------------------------------- 19.3/99.8 MB 6.1 MB/s eta 0:00:14\n",
      "   ------- -------------------------------- 19.6/99.8 MB 6.1 MB/s eta 0:00:14\n",
      "   ------- -------------------------------- 19.9/99.8 MB 6.1 MB/s eta 0:00:14\n",
      "   -------- ------------------------------- 20.2/99.8 MB 6.1 MB/s eta 0:00:14\n",
      "   -------- ------------------------------- 20.6/99.8 MB 6.1 MB/s eta 0:00:14\n",
      "   -------- ------------------------------- 20.8/99.8 MB 6.1 MB/s eta 0:00:14\n",
      "   -------- ------------------------------- 21.0/99.8 MB 6.0 MB/s eta 0:00:14\n",
      "   -------- ------------------------------- 21.2/99.8 MB 6.0 MB/s eta 0:00:14\n",
      "   -------- ------------------------------- 21.4/99.8 MB 5.9 MB/s eta 0:00:14\n",
      "   -------- ------------------------------- 21.5/99.8 MB 5.8 MB/s eta 0:00:14\n",
      "   -------- ------------------------------- 21.9/99.8 MB 5.8 MB/s eta 0:00:14\n",
      "   -------- ------------------------------- 22.0/99.8 MB 5.8 MB/s eta 0:00:14\n",
      "   -------- ------------------------------- 22.1/99.8 MB 5.7 MB/s eta 0:00:14\n",
      "   -------- ------------------------------- 22.2/99.8 MB 5.7 MB/s eta 0:00:14\n",
      "   -------- ------------------------------- 22.4/99.8 MB 5.6 MB/s eta 0:00:14\n",
      "   --------- ------------------------------ 22.6/99.8 MB 5.7 MB/s eta 0:00:14\n",
      "   --------- ------------------------------ 22.7/99.8 MB 5.6 MB/s eta 0:00:14\n",
      "   --------- ------------------------------ 22.8/99.8 MB 5.6 MB/s eta 0:00:14\n",
      "   --------- ------------------------------ 22.8/99.8 MB 5.6 MB/s eta 0:00:14\n",
      "   --------- ------------------------------ 22.8/99.8 MB 5.5 MB/s eta 0:00:15\n",
      "   --------- ------------------------------ 22.9/99.8 MB 5.3 MB/s eta 0:00:15\n",
      "   --------- ------------------------------ 22.9/99.8 MB 5.2 MB/s eta 0:00:15\n",
      "   --------- ------------------------------ 22.9/99.8 MB 5.2 MB/s eta 0:00:15\n",
      "   --------- ------------------------------ 23.0/99.8 MB 5.1 MB/s eta 0:00:15\n",
      "   --------- ------------------------------ 23.1/99.8 MB 5.0 MB/s eta 0:00:16\n",
      "   --------- ------------------------------ 23.3/99.8 MB 5.0 MB/s eta 0:00:16\n",
      "   --------- ------------------------------ 23.4/99.8 MB 5.0 MB/s eta 0:00:16\n",
      "   --------- ------------------------------ 23.6/99.8 MB 5.0 MB/s eta 0:00:16\n",
      "   --------- ------------------------------ 23.8/99.8 MB 5.1 MB/s eta 0:00:15\n",
      "   --------- ------------------------------ 23.9/99.8 MB 5.0 MB/s eta 0:00:16\n",
      "   --------- ------------------------------ 24.0/99.8 MB 5.0 MB/s eta 0:00:16\n",
      "   --------- ------------------------------ 24.1/99.8 MB 5.0 MB/s eta 0:00:16\n",
      "   --------- ------------------------------ 24.3/99.8 MB 4.9 MB/s eta 0:00:16\n",
      "   --------- ------------------------------ 24.3/99.8 MB 4.9 MB/s eta 0:00:16\n",
      "   --------- ------------------------------ 24.4/99.8 MB 4.8 MB/s eta 0:00:16\n",
      "   --------- ------------------------------ 24.5/99.8 MB 4.7 MB/s eta 0:00:16\n",
      "   --------- ------------------------------ 24.5/99.8 MB 4.7 MB/s eta 0:00:17\n",
      "   --------- ------------------------------ 24.6/99.8 MB 4.6 MB/s eta 0:00:17\n",
      "   --------- ------------------------------ 24.8/99.8 MB 4.6 MB/s eta 0:00:17\n",
      "   ---------- ----------------------------- 25.0/99.8 MB 4.5 MB/s eta 0:00:17\n",
      "   ---------- ----------------------------- 25.2/99.8 MB 4.5 MB/s eta 0:00:17\n",
      "   ---------- ----------------------------- 25.5/99.8 MB 4.5 MB/s eta 0:00:17\n",
      "   ---------- ----------------------------- 25.5/99.8 MB 4.5 MB/s eta 0:00:17\n",
      "   ---------- ----------------------------- 25.6/99.8 MB 4.3 MB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 25.8/99.8 MB 4.3 MB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 26.1/99.8 MB 4.3 MB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 26.3/99.8 MB 4.3 MB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 26.6/99.8 MB 4.3 MB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 26.8/99.8 MB 4.3 MB/s eta 0:00:17\n",
      "   ---------- ----------------------------- 27.0/99.8 MB 4.2 MB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 27.1/99.8 MB 4.2 MB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 27.3/99.8 MB 4.1 MB/s eta 0:00:18\n",
      "   ----------- ---------------------------- 27.6/99.8 MB 4.1 MB/s eta 0:00:18\n",
      "   ----------- ---------------------------- 27.6/99.8 MB 4.1 MB/s eta 0:00:18\n",
      "   ----------- ---------------------------- 27.6/99.8 MB 4.1 MB/s eta 0:00:18\n",
      "   ----------- ---------------------------- 27.6/99.8 MB 4.0 MB/s eta 0:00:19\n",
      "   ----------- ---------------------------- 27.9/99.8 MB 3.9 MB/s eta 0:00:19\n",
      "   ----------- ---------------------------- 28.0/99.8 MB 3.9 MB/s eta 0:00:19\n",
      "   ----------- ---------------------------- 28.2/99.8 MB 3.9 MB/s eta 0:00:19\n",
      "   ----------- ---------------------------- 28.3/99.8 MB 3.9 MB/s eta 0:00:19\n",
      "   ----------- ---------------------------- 28.4/99.8 MB 3.8 MB/s eta 0:00:19\n",
      "   ----------- ---------------------------- 28.5/99.8 MB 3.8 MB/s eta 0:00:19\n",
      "   ----------- ---------------------------- 28.5/99.8 MB 3.8 MB/s eta 0:00:19\n",
      "   ----------- ---------------------------- 28.6/99.8 MB 3.7 MB/s eta 0:00:20\n",
      "   ----------- ---------------------------- 28.7/99.8 MB 3.6 MB/s eta 0:00:20\n",
      "   ----------- ---------------------------- 28.9/99.8 MB 3.6 MB/s eta 0:00:20\n",
      "   ----------- ---------------------------- 29.0/99.8 MB 3.6 MB/s eta 0:00:20\n",
      "   ----------- ---------------------------- 29.3/99.8 MB 3.6 MB/s eta 0:00:20\n",
      "   ----------- ---------------------------- 29.3/99.8 MB 3.6 MB/s eta 0:00:20\n",
      "   ----------- ---------------------------- 29.5/99.8 MB 3.5 MB/s eta 0:00:21\n",
      "   ----------- ---------------------------- 29.6/99.8 MB 3.5 MB/s eta 0:00:21\n",
      "   ----------- ---------------------------- 29.6/99.8 MB 3.5 MB/s eta 0:00:21\n",
      "   ----------- ---------------------------- 29.8/99.8 MB 3.4 MB/s eta 0:00:21\n",
      "   ----------- ---------------------------- 29.9/99.8 MB 3.4 MB/s eta 0:00:21\n",
      "   ----------- ---------------------------- 29.9/99.8 MB 3.4 MB/s eta 0:00:21\n",
      "   ------------ --------------------------- 30.2/99.8 MB 3.3 MB/s eta 0:00:21\n",
      "   ------------ --------------------------- 30.3/99.8 MB 3.3 MB/s eta 0:00:21\n",
      "   ------------ --------------------------- 30.4/99.8 MB 3.3 MB/s eta 0:00:22\n",
      "   ------------ --------------------------- 30.6/99.8 MB 3.2 MB/s eta 0:00:22\n",
      "   ------------ --------------------------- 30.8/99.8 MB 3.2 MB/s eta 0:00:22\n",
      "   ------------ --------------------------- 31.0/99.8 MB 3.2 MB/s eta 0:00:22\n",
      "   ------------ --------------------------- 31.1/99.8 MB 3.3 MB/s eta 0:00:22\n",
      "   ------------ --------------------------- 31.3/99.8 MB 3.2 MB/s eta 0:00:22\n",
      "   ------------ --------------------------- 31.3/99.8 MB 3.2 MB/s eta 0:00:22\n",
      "   ------------ --------------------------- 31.5/99.8 MB 3.1 MB/s eta 0:00:22\n",
      "   ------------ --------------------------- 31.7/99.8 MB 3.1 MB/s eta 0:00:22\n",
      "   ------------ --------------------------- 31.9/99.8 MB 3.2 MB/s eta 0:00:22\n",
      "   ------------ --------------------------- 32.0/99.8 MB 3.1 MB/s eta 0:00:22\n",
      "   ------------ --------------------------- 32.3/99.8 MB 3.2 MB/s eta 0:00:22\n",
      "   ------------- -------------------------- 32.5/99.8 MB 3.2 MB/s eta 0:00:22\n",
      "   ------------- -------------------------- 32.7/99.8 MB 3.2 MB/s eta 0:00:21\n",
      "   ------------- -------------------------- 32.9/99.8 MB 3.2 MB/s eta 0:00:21\n",
      "   ------------- -------------------------- 33.2/99.8 MB 3.4 MB/s eta 0:00:20\n",
      "   ------------- -------------------------- 33.4/99.8 MB 3.5 MB/s eta 0:00:19\n",
      "   ------------- -------------------------- 33.6/99.8 MB 3.5 MB/s eta 0:00:20\n",
      "   ------------- -------------------------- 33.7/99.8 MB 3.5 MB/s eta 0:00:19\n",
      "   ------------- -------------------------- 33.9/99.8 MB 3.5 MB/s eta 0:00:19\n",
      "   ------------- -------------------------- 34.2/99.8 MB 3.6 MB/s eta 0:00:19\n",
      "   ------------- -------------------------- 34.4/99.8 MB 3.6 MB/s eta 0:00:18\n",
      "   ------------- -------------------------- 34.6/99.8 MB 3.7 MB/s eta 0:00:18\n",
      "   ------------- -------------------------- 34.8/99.8 MB 3.7 MB/s eta 0:00:18\n",
      "   ------------- -------------------------- 34.8/99.8 MB 3.8 MB/s eta 0:00:18\n",
      "   -------------- ------------------------- 35.2/99.8 MB 3.8 MB/s eta 0:00:18\n",
      "   -------------- ------------------------- 35.2/99.8 MB 3.8 MB/s eta 0:00:17\n",
      "   -------------- ------------------------- 35.4/99.8 MB 3.8 MB/s eta 0:00:18\n",
      "   -------------- ------------------------- 35.6/99.8 MB 3.7 MB/s eta 0:00:18\n",
      "   -------------- ------------------------- 35.8/99.8 MB 3.8 MB/s eta 0:00:17\n",
      "   -------------- ------------------------- 36.1/99.8 MB 3.9 MB/s eta 0:00:17\n",
      "   -------------- ------------------------- 36.2/99.8 MB 3.9 MB/s eta 0:00:17\n",
      "   -------------- ------------------------- 36.4/99.8 MB 3.8 MB/s eta 0:00:17\n",
      "   -------------- ------------------------- 36.6/99.8 MB 3.8 MB/s eta 0:00:17\n",
      "   -------------- ------------------------- 36.7/99.8 MB 3.8 MB/s eta 0:00:17\n",
      "   -------------- ------------------------- 37.0/99.8 MB 3.8 MB/s eta 0:00:17\n",
      "   -------------- ------------------------- 37.2/99.8 MB 3.8 MB/s eta 0:00:17\n",
      "   -------------- ------------------------- 37.4/99.8 MB 3.8 MB/s eta 0:00:17\n",
      "   --------------- ------------------------ 37.4/99.8 MB 3.8 MB/s eta 0:00:17\n",
      "   --------------- ------------------------ 37.5/99.8 MB 3.7 MB/s eta 0:00:17\n",
      "   --------------- ------------------------ 37.6/99.8 MB 3.7 MB/s eta 0:00:17\n",
      "   --------------- ------------------------ 37.7/99.8 MB 3.7 MB/s eta 0:00:17\n",
      "   --------------- ------------------------ 37.7/99.8 MB 3.6 MB/s eta 0:00:18\n",
      "   --------------- ------------------------ 37.9/99.8 MB 3.8 MB/s eta 0:00:17\n",
      "   --------------- ------------------------ 37.9/99.8 MB 3.8 MB/s eta 0:00:17\n",
      "   --------------- ------------------------ 38.3/99.8 MB 3.8 MB/s eta 0:00:17\n",
      "   --------------- ------------------------ 38.4/99.8 MB 3.8 MB/s eta 0:00:17\n",
      "   --------------- ------------------------ 38.4/99.8 MB 3.8 MB/s eta 0:00:17\n",
      "   --------------- ------------------------ 38.4/99.8 MB 3.8 MB/s eta 0:00:17\n",
      "   --------------- ------------------------ 38.4/99.8 MB 3.6 MB/s eta 0:00:17\n",
      "   --------------- ------------------------ 38.9/99.8 MB 3.8 MB/s eta 0:00:16\n",
      "   --------------- ------------------------ 38.9/99.8 MB 3.7 MB/s eta 0:00:17\n",
      "   --------------- ------------------------ 39.1/99.8 MB 3.8 MB/s eta 0:00:17\n",
      "   --------------- ------------------------ 39.3/99.8 MB 3.8 MB/s eta 0:00:16\n",
      "   --------------- ------------------------ 39.5/99.8 MB 3.8 MB/s eta 0:00:16\n",
      "   --------------- ------------------------ 39.7/99.8 MB 3.8 MB/s eta 0:00:16\n",
      "   --------------- ------------------------ 39.7/99.8 MB 3.8 MB/s eta 0:00:16\n",
      "   --------------- ------------------------ 39.8/99.8 MB 3.7 MB/s eta 0:00:17\n",
      "   ---------------- ----------------------- 39.9/99.8 MB 3.9 MB/s eta 0:00:16\n",
      "   ---------------- ----------------------- 40.1/99.8 MB 3.8 MB/s eta 0:00:16\n",
      "   ---------------- ----------------------- 40.2/99.8 MB 3.8 MB/s eta 0:00:16\n",
      "   ---------------- ----------------------- 40.4/99.8 MB 3.8 MB/s eta 0:00:16\n",
      "   ---------------- ----------------------- 40.4/99.8 MB 3.8 MB/s eta 0:00:16\n",
      "   ---------------- ----------------------- 40.6/99.8 MB 3.8 MB/s eta 0:00:16\n",
      "   ---------------- ----------------------- 40.8/99.8 MB 3.8 MB/s eta 0:00:16\n",
      "   ---------------- ----------------------- 40.8/99.8 MB 3.9 MB/s eta 0:00:16\n",
      "   ---------------- ----------------------- 41.1/99.8 MB 3.8 MB/s eta 0:00:16\n",
      "   ---------------- ----------------------- 41.2/99.8 MB 3.8 MB/s eta 0:00:16\n",
      "   ---------------- ----------------------- 41.3/99.8 MB 3.7 MB/s eta 0:00:16\n",
      "   ---------------- ----------------------- 41.4/99.8 MB 3.8 MB/s eta 0:00:16\n",
      "   ---------------- ----------------------- 41.5/99.8 MB 3.7 MB/s eta 0:00:16\n",
      "   ---------------- ----------------------- 41.6/99.8 MB 3.7 MB/s eta 0:00:16\n",
      "   ---------------- ----------------------- 41.7/99.8 MB 3.7 MB/s eta 0:00:16\n",
      "   ---------------- ----------------------- 41.7/99.8 MB 3.7 MB/s eta 0:00:16\n",
      "   ---------------- ----------------------- 41.8/99.8 MB 3.6 MB/s eta 0:00:16\n",
      "   ---------------- ----------------------- 41.9/99.8 MB 3.6 MB/s eta 0:00:16\n",
      "   ---------------- ----------------------- 42.1/99.8 MB 3.6 MB/s eta 0:00:16\n",
      "   ---------------- ----------------------- 42.4/99.8 MB 3.6 MB/s eta 0:00:16\n",
      "   ----------------- ---------------------- 42.6/99.8 MB 3.6 MB/s eta 0:00:16\n",
      "   ----------------- ---------------------- 42.7/99.8 MB 3.6 MB/s eta 0:00:16\n",
      "   ----------------- ---------------------- 43.0/99.8 MB 3.7 MB/s eta 0:00:16\n",
      "   ----------------- ---------------------- 43.2/99.8 MB 3.7 MB/s eta 0:00:16\n",
      "   ----------------- ---------------------- 43.2/99.8 MB 3.7 MB/s eta 0:00:16\n",
      "   ----------------- ---------------------- 43.4/99.8 MB 3.6 MB/s eta 0:00:16\n",
      "   ----------------- ---------------------- 43.4/99.8 MB 3.6 MB/s eta 0:00:16\n",
      "   ----------------- ---------------------- 43.4/99.8 MB 3.6 MB/s eta 0:00:16\n",
      "   ----------------- ---------------------- 43.7/99.8 MB 3.5 MB/s eta 0:00:16\n",
      "   ----------------- ---------------------- 43.8/99.8 MB 3.5 MB/s eta 0:00:17\n",
      "   ----------------- ---------------------- 43.9/99.8 MB 3.5 MB/s eta 0:00:17\n",
      "   ----------------- ---------------------- 44.0/99.8 MB 3.4 MB/s eta 0:00:17\n",
      "   ----------------- ---------------------- 44.2/99.8 MB 3.4 MB/s eta 0:00:17\n",
      "   ----------------- ---------------------- 44.2/99.8 MB 3.4 MB/s eta 0:00:17\n",
      "   ----------------- ---------------------- 44.2/99.8 MB 3.4 MB/s eta 0:00:17\n",
      "   ----------------- ---------------------- 44.2/99.8 MB 3.4 MB/s eta 0:00:17\n",
      "   ----------------- ---------------------- 44.2/99.8 MB 3.2 MB/s eta 0:00:18\n",
      "   ----------------- ---------------------- 44.3/99.8 MB 3.2 MB/s eta 0:00:18\n",
      "   ----------------- ---------------------- 44.6/99.8 MB 3.2 MB/s eta 0:00:18\n",
      "   ----------------- ---------------------- 44.7/99.8 MB 3.3 MB/s eta 0:00:17\n",
      "   ----------------- ---------------------- 44.7/99.8 MB 3.3 MB/s eta 0:00:17\n",
      "   ----------------- ---------------------- 44.8/99.8 MB 3.2 MB/s eta 0:00:18\n",
      "   ----------------- ---------------------- 44.9/99.8 MB 3.1 MB/s eta 0:00:18\n",
      "   ----------------- ---------------------- 44.9/99.8 MB 3.1 MB/s eta 0:00:18\n",
      "   ------------------ --------------------- 45.0/99.8 MB 3.1 MB/s eta 0:00:18\n",
      "   ------------------ --------------------- 45.0/99.8 MB 3.1 MB/s eta 0:00:18\n",
      "   ------------------ --------------------- 45.3/99.8 MB 3.0 MB/s eta 0:00:18\n",
      "   ------------------ --------------------- 45.4/99.8 MB 3.0 MB/s eta 0:00:19\n",
      "   ------------------ --------------------- 45.7/99.8 MB 3.1 MB/s eta 0:00:18\n",
      "   ------------------ --------------------- 46.0/99.8 MB 3.1 MB/s eta 0:00:18\n",
      "   ------------------ --------------------- 46.3/99.8 MB 3.1 MB/s eta 0:00:18\n",
      "   ------------------ --------------------- 46.5/99.8 MB 3.1 MB/s eta 0:00:18\n",
      "   ------------------ --------------------- 46.8/99.8 MB 3.1 MB/s eta 0:00:17\n",
      "   ------------------ --------------------- 47.0/99.8 MB 3.1 MB/s eta 0:00:17\n",
      "   ------------------ --------------------- 47.2/99.8 MB 3.1 MB/s eta 0:00:17\n",
      "   ------------------ --------------------- 47.3/99.8 MB 3.1 MB/s eta 0:00:17\n",
      "   ------------------- -------------------- 47.7/99.8 MB 3.2 MB/s eta 0:00:17\n",
      "   ------------------- -------------------- 47.9/99.8 MB 3.2 MB/s eta 0:00:17\n",
      "   ------------------- -------------------- 48.1/99.8 MB 3.3 MB/s eta 0:00:16\n",
      "   ------------------- -------------------- 48.2/99.8 MB 3.3 MB/s eta 0:00:16\n",
      "   ------------------- -------------------- 48.3/99.8 MB 3.3 MB/s eta 0:00:16\n",
      "   ------------------- -------------------- 48.4/99.8 MB 3.2 MB/s eta 0:00:16\n",
      "   ------------------- -------------------- 48.5/99.8 MB 3.2 MB/s eta 0:00:16\n",
      "   ------------------- -------------------- 48.7/99.8 MB 3.4 MB/s eta 0:00:16\n",
      "   ------------------- -------------------- 48.7/99.8 MB 3.4 MB/s eta 0:00:16\n",
      "   ------------------- -------------------- 48.7/99.8 MB 3.4 MB/s eta 0:00:16\n",
      "   ------------------- -------------------- 48.7/99.8 MB 3.4 MB/s eta 0:00:16\n",
      "   ------------------- -------------------- 49.0/99.8 MB 3.2 MB/s eta 0:00:16\n",
      "   ------------------- -------------------- 49.1/99.8 MB 3.1 MB/s eta 0:00:17\n",
      "   ------------------- -------------------- 49.3/99.8 MB 3.2 MB/s eta 0:00:16\n",
      "   ------------------- -------------------- 49.3/99.8 MB 3.1 MB/s eta 0:00:17\n",
      "   ------------------- -------------------- 49.5/99.8 MB 3.1 MB/s eta 0:00:16\n",
      "   ------------------- -------------------- 49.7/99.8 MB 3.2 MB/s eta 0:00:16\n",
      "   -------------------- ------------------- 49.9/99.8 MB 3.2 MB/s eta 0:00:16\n",
      "   -------------------- ------------------- 50.2/99.8 MB 3.3 MB/s eta 0:00:16\n",
      "   -------------------- ------------------- 50.4/99.8 MB 3.3 MB/s eta 0:00:15\n",
      "   -------------------- ------------------- 50.6/99.8 MB 3.3 MB/s eta 0:00:15\n",
      "   -------------------- ------------------- 50.9/99.8 MB 3.4 MB/s eta 0:00:15\n",
      "   -------------------- ------------------- 51.1/99.8 MB 3.4 MB/s eta 0:00:15\n",
      "   -------------------- ------------------- 51.3/99.8 MB 3.4 MB/s eta 0:00:15\n",
      "   -------------------- ------------------- 51.5/99.8 MB 3.4 MB/s eta 0:00:15\n",
      "   -------------------- ------------------- 51.7/99.8 MB 3.5 MB/s eta 0:00:14\n",
      "   -------------------- ------------------- 51.9/99.8 MB 3.5 MB/s eta 0:00:14\n",
      "   -------------------- ------------------- 52.2/99.8 MB 3.6 MB/s eta 0:00:14\n",
      "   -------------------- ------------------- 52.3/99.8 MB 3.7 MB/s eta 0:00:13\n",
      "   --------------------- ------------------ 52.6/99.8 MB 3.6 MB/s eta 0:00:13\n",
      "   --------------------- ------------------ 52.8/99.8 MB 3.7 MB/s eta 0:00:13\n",
      "   --------------------- ------------------ 53.1/99.8 MB 3.7 MB/s eta 0:00:13\n",
      "   --------------------- ------------------ 53.3/99.8 MB 3.7 MB/s eta 0:00:13\n",
      "   --------------------- ------------------ 53.5/99.8 MB 3.7 MB/s eta 0:00:13\n",
      "   --------------------- ------------------ 53.7/99.8 MB 3.9 MB/s eta 0:00:12\n",
      "   --------------------- ------------------ 53.9/99.8 MB 3.8 MB/s eta 0:00:13\n",
      "   --------------------- ------------------ 54.2/99.8 MB 3.9 MB/s eta 0:00:12\n",
      "   --------------------- ------------------ 54.4/99.8 MB 4.2 MB/s eta 0:00:11\n",
      "   --------------------- ------------------ 54.6/99.8 MB 4.2 MB/s eta 0:00:11\n",
      "   --------------------- ------------------ 54.8/99.8 MB 4.2 MB/s eta 0:00:11\n",
      "   ---------------------- ----------------- 55.1/99.8 MB 4.4 MB/s eta 0:00:11\n",
      "   ---------------------- ----------------- 55.2/99.8 MB 4.6 MB/s eta 0:00:10\n",
      "   ---------------------- ----------------- 55.5/99.8 MB 4.7 MB/s eta 0:00:10\n",
      "   ---------------------- ----------------- 55.8/99.8 MB 4.7 MB/s eta 0:00:10\n",
      "   ---------------------- ----------------- 56.1/99.8 MB 4.7 MB/s eta 0:00:10\n",
      "   ---------------------- ----------------- 56.4/99.8 MB 4.7 MB/s eta 0:00:10\n",
      "   ---------------------- ----------------- 56.6/99.8 MB 4.7 MB/s eta 0:00:10\n",
      "   ---------------------- ----------------- 56.9/99.8 MB 4.7 MB/s eta 0:00:10\n",
      "   ---------------------- ----------------- 57.1/99.8 MB 4.6 MB/s eta 0:00:10\n",
      "   ----------------------- ---------------- 57.4/99.8 MB 4.7 MB/s eta 0:00:10\n",
      "   ----------------------- ---------------- 57.6/99.8 MB 4.7 MB/s eta 0:00:09\n",
      "   ----------------------- ---------------- 57.8/99.8 MB 4.7 MB/s eta 0:00:09\n",
      "   ----------------------- ---------------- 58.0/99.8 MB 4.6 MB/s eta 0:00:09\n",
      "   ----------------------- ---------------- 58.0/99.8 MB 4.6 MB/s eta 0:00:10\n",
      "   ----------------------- ---------------- 58.2/99.8 MB 4.6 MB/s eta 0:00:10\n",
      "   ----------------------- ---------------- 58.2/99.8 MB 4.6 MB/s eta 0:00:10\n",
      "   ----------------------- ---------------- 58.4/99.8 MB 4.6 MB/s eta 0:00:09\n",
      "   ----------------------- ---------------- 58.5/99.8 MB 4.5 MB/s eta 0:00:10\n",
      "   ----------------------- ---------------- 58.7/99.8 MB 4.5 MB/s eta 0:00:10\n",
      "   ----------------------- ---------------- 59.0/99.8 MB 5.0 MB/s eta 0:00:09\n",
      "   ----------------------- ---------------- 59.1/99.8 MB 4.9 MB/s eta 0:00:09\n",
      "   ----------------------- ---------------- 59.3/99.8 MB 5.0 MB/s eta 0:00:09\n",
      "   ----------------------- ---------------- 59.6/99.8 MB 5.1 MB/s eta 0:00:08\n",
      "   ----------------------- ---------------- 59.8/99.8 MB 5.1 MB/s eta 0:00:08\n",
      "   ------------------------ --------------- 60.1/99.8 MB 5.1 MB/s eta 0:00:08\n",
      "   ------------------------ --------------- 60.3/99.8 MB 5.1 MB/s eta 0:00:08\n",
      "   ------------------------ --------------- 60.5/99.8 MB 5.1 MB/s eta 0:00:08\n",
      "   ------------------------ --------------- 60.8/99.8 MB 5.1 MB/s eta 0:00:08\n",
      "   ------------------------ --------------- 61.0/99.8 MB 5.1 MB/s eta 0:00:08\n",
      "   ------------------------ --------------- 61.2/99.8 MB 5.1 MB/s eta 0:00:08\n",
      "   ------------------------ --------------- 61.3/99.8 MB 5.0 MB/s eta 0:00:08\n",
      "   ------------------------ --------------- 61.6/99.8 MB 5.1 MB/s eta 0:00:08\n",
      "   ------------------------ --------------- 61.8/99.8 MB 5.0 MB/s eta 0:00:08\n",
      "   ------------------------ --------------- 62.0/99.8 MB 5.0 MB/s eta 0:00:08\n",
      "   ------------------------ --------------- 62.2/99.8 MB 5.0 MB/s eta 0:00:08\n",
      "   ------------------------- -------------- 62.4/99.8 MB 5.0 MB/s eta 0:00:08\n",
      "   ------------------------- -------------- 62.7/99.8 MB 5.1 MB/s eta 0:00:08\n",
      "   ------------------------- -------------- 62.8/99.8 MB 5.0 MB/s eta 0:00:08\n",
      "   ------------------------- -------------- 63.0/99.8 MB 5.0 MB/s eta 0:00:08\n",
      "   ------------------------- -------------- 63.2/99.8 MB 5.0 MB/s eta 0:00:08\n",
      "   ------------------------- -------------- 63.3/99.8 MB 5.0 MB/s eta 0:00:08\n",
      "   ------------------------- -------------- 63.5/99.8 MB 5.0 MB/s eta 0:00:08\n",
      "   ------------------------- -------------- 63.8/99.8 MB 5.0 MB/s eta 0:00:08\n",
      "   ------------------------- -------------- 64.0/99.8 MB 5.0 MB/s eta 0:00:08\n",
      "   ------------------------- -------------- 64.2/99.8 MB 5.0 MB/s eta 0:00:08\n",
      "   ------------------------- -------------- 64.5/99.8 MB 5.0 MB/s eta 0:00:08\n",
      "   ------------------------- -------------- 64.7/99.8 MB 5.0 MB/s eta 0:00:08\n",
      "   -------------------------- ------------- 65.0/99.8 MB 5.0 MB/s eta 0:00:07\n",
      "   -------------------------- ------------- 65.2/99.8 MB 5.0 MB/s eta 0:00:07\n",
      "   -------------------------- ------------- 65.4/99.8 MB 5.0 MB/s eta 0:00:07\n",
      "   -------------------------- ------------- 65.5/99.8 MB 5.0 MB/s eta 0:00:07\n",
      "   -------------------------- ------------- 65.5/99.8 MB 5.0 MB/s eta 0:00:07\n",
      "   -------------------------- ------------- 65.7/99.8 MB 4.8 MB/s eta 0:00:08\n",
      "   -------------------------- ------------- 65.8/99.8 MB 4.8 MB/s eta 0:00:08\n",
      "   -------------------------- ------------- 65.9/99.8 MB 4.7 MB/s eta 0:00:08\n",
      "   -------------------------- ------------- 66.2/99.8 MB 4.7 MB/s eta 0:00:08\n",
      "   -------------------------- ------------- 66.3/99.8 MB 4.7 MB/s eta 0:00:08\n",
      "   -------------------------- ------------- 66.5/99.8 MB 4.6 MB/s eta 0:00:08\n",
      "   -------------------------- ------------- 66.7/99.8 MB 4.6 MB/s eta 0:00:08\n",
      "   -------------------------- ------------- 66.9/99.8 MB 4.6 MB/s eta 0:00:08\n",
      "   -------------------------- ------------- 67.2/99.8 MB 4.6 MB/s eta 0:00:08\n",
      "   --------------------------- ------------ 67.3/99.8 MB 4.6 MB/s eta 0:00:08\n",
      "   --------------------------- ------------ 67.4/99.8 MB 4.5 MB/s eta 0:00:08\n",
      "   --------------------------- ------------ 67.7/99.8 MB 4.5 MB/s eta 0:00:08\n",
      "   --------------------------- ------------ 67.9/99.8 MB 4.5 MB/s eta 0:00:08\n",
      "   --------------------------- ------------ 68.1/99.8 MB 4.5 MB/s eta 0:00:07\n",
      "   --------------------------- ------------ 68.4/99.8 MB 4.6 MB/s eta 0:00:07\n",
      "   --------------------------- ------------ 68.5/99.8 MB 4.7 MB/s eta 0:00:07\n",
      "   --------------------------- ------------ 68.6/99.8 MB 4.7 MB/s eta 0:00:07\n",
      "   --------------------------- ------------ 68.7/99.8 MB 4.8 MB/s eta 0:00:07\n",
      "   --------------------------- ------------ 68.9/99.8 MB 4.7 MB/s eta 0:00:07\n",
      "   --------------------------- ------------ 69.0/99.8 MB 4.6 MB/s eta 0:00:07\n",
      "   --------------------------- ------------ 69.1/99.8 MB 4.6 MB/s eta 0:00:07\n",
      "   --------------------------- ------------ 69.2/99.8 MB 4.5 MB/s eta 0:00:07\n",
      "   --------------------------- ------------ 69.4/99.8 MB 4.5 MB/s eta 0:00:07\n",
      "   --------------------------- ------------ 69.7/99.8 MB 4.6 MB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 70.0/99.8 MB 4.5 MB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 70.3/99.8 MB 4.6 MB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 70.6/99.8 MB 4.6 MB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 70.9/99.8 MB 4.6 MB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 71.1/99.8 MB 4.6 MB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 71.1/99.8 MB 4.5 MB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 71.2/99.8 MB 4.5 MB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 71.3/99.8 MB 4.4 MB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 71.5/99.8 MB 4.5 MB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 71.8/99.8 MB 4.5 MB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 72.1/99.8 MB 4.5 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 72.4/99.8 MB 4.5 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 72.6/99.8 MB 4.5 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 72.6/99.8 MB 4.5 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 72.7/99.8 MB 4.4 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 73.1/99.8 MB 4.5 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 73.2/99.8 MB 4.5 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 73.3/99.8 MB 4.4 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 73.6/99.8 MB 4.4 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 73.8/99.8 MB 4.4 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 73.9/99.8 MB 4.4 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 74.1/99.8 MB 4.4 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 74.2/99.8 MB 4.4 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 74.3/99.8 MB 4.3 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 74.4/99.8 MB 4.3 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 74.4/99.8 MB 4.3 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 74.4/99.8 MB 4.1 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 74.6/99.8 MB 4.1 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 74.6/99.8 MB 4.1 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 74.7/99.8 MB 4.0 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 74.9/99.8 MB 4.0 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 75.0/99.8 MB 3.9 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 75.1/99.8 MB 3.9 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 75.3/99.8 MB 3.9 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 75.4/99.8 MB 3.9 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 75.6/99.8 MB 3.8 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 75.8/99.8 MB 3.9 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 76.0/99.8 MB 4.0 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 76.0/99.8 MB 4.0 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 76.0/99.8 MB 3.9 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 76.1/99.8 MB 3.8 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 76.3/99.8 MB 3.8 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 76.5/99.8 MB 3.8 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 76.7/99.8 MB 3.9 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 76.7/99.8 MB 3.9 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 76.8/99.8 MB 3.8 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 76.9/99.8 MB 3.7 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 77.0/99.8 MB 3.7 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 77.1/99.8 MB 3.6 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 77.3/99.8 MB 3.6 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 77.5/99.8 MB 3.6 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 77.6/99.8 MB 3.6 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 77.7/99.8 MB 3.6 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 77.9/99.8 MB 3.6 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 77.9/99.8 MB 3.6 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 78.1/99.8 MB 3.6 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 78.3/99.8 MB 3.6 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 78.6/99.8 MB 3.6 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 78.7/99.8 MB 3.6 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 79.2/99.8 MB 3.7 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 79.5/99.8 MB 3.8 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 79.7/99.8 MB 3.8 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 80.0/99.8 MB 3.8 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 80.3/99.8 MB 3.8 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 80.6/99.8 MB 3.8 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 80.8/99.8 MB 3.8 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 81.0/99.8 MB 3.8 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 81.1/99.8 MB 3.8 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 81.3/99.8 MB 3.8 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 81.4/99.8 MB 3.8 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 81.7/99.8 MB 3.9 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 81.7/99.8 MB 3.8 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 82.0/99.8 MB 3.8 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 82.2/99.8 MB 3.8 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 82.4/99.8 MB 3.8 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 82.5/99.8 MB 3.8 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 82.5/99.8 MB 3.8 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 82.6/99.8 MB 3.7 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 82.6/99.8 MB 3.7 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 82.8/99.8 MB 3.6 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 82.9/99.8 MB 3.7 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 83.0/99.8 MB 3.6 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 83.1/99.8 MB 3.6 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 83.4/99.8 MB 3.6 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 83.5/99.8 MB 3.6 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 83.7/99.8 MB 3.6 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 84.0/99.8 MB 3.6 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 84.3/99.8 MB 3.6 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 84.5/99.8 MB 3.7 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 84.6/99.8 MB 3.7 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 84.8/99.8 MB 3.8 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 84.9/99.8 MB 3.9 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 85.0/99.8 MB 3.9 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 85.1/99.8 MB 3.9 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 85.3/99.8 MB 3.9 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 85.6/99.8 MB 3.9 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 85.7/99.8 MB 3.9 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 85.7/99.8 MB 3.9 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 85.8/99.8 MB 3.9 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 85.8/99.8 MB 3.9 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 85.9/99.8 MB 3.8 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 86.0/99.8 MB 3.8 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 86.1/99.8 MB 3.7 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 86.2/99.8 MB 3.8 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 86.6/99.8 MB 3.9 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 86.6/99.8 MB 3.9 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 86.7/99.8 MB 3.8 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 86.9/99.8 MB 3.8 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 87.2/99.8 MB 4.0 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 87.3/99.8 MB 4.0 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 87.3/99.8 MB 4.0 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 87.4/99.8 MB 3.9 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 87.6/99.8 MB 3.9 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 87.8/99.8 MB 3.9 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 88.1/99.8 MB 4.0 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 88.3/99.8 MB 4.0 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 88.5/99.8 MB 4.0 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 88.6/99.8 MB 4.0 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 88.6/99.8 MB 3.9 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 88.8/99.8 MB 3.9 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 88.9/99.8 MB 3.9 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 89.2/99.8 MB 3.9 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 89.3/99.8 MB 3.8 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 89.6/99.8 MB 3.8 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 89.8/99.8 MB 3.8 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 90.0/99.8 MB 3.8 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 90.2/99.8 MB 3.8 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 90.4/99.8 MB 3.8 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 90.7/99.8 MB 3.8 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 90.9/99.8 MB 3.8 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 91.1/99.8 MB 3.8 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 91.4/99.8 MB 3.8 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 91.6/99.8 MB 3.8 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 91.8/99.8 MB 3.8 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 92.1/99.8 MB 3.9 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 92.2/99.8 MB 3.9 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 92.3/99.8 MB 3.8 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 92.5/99.8 MB 3.8 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 92.7/99.8 MB 3.8 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 92.7/99.8 MB 3.8 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 92.8/99.8 MB 3.8 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 92.9/99.8 MB 3.9 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 93.0/99.8 MB 3.8 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 93.1/99.8 MB 3.8 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 93.3/99.8 MB 3.9 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 93.5/99.8 MB 3.9 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 93.5/99.8 MB 3.9 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 93.5/99.8 MB 3.8 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 93.7/99.8 MB 3.8 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 93.7/99.8 MB 3.7 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 93.9/99.8 MB 3.7 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 94.1/99.8 MB 3.7 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 94.3/99.8 MB 3.7 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 94.5/99.8 MB 3.7 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 94.8/99.8 MB 3.7 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 94.9/99.8 MB 3.7 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 95.0/99.8 MB 3.7 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 95.1/99.8 MB 3.7 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 95.1/99.8 MB 3.6 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 95.2/99.8 MB 3.6 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 95.2/99.8 MB 3.6 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 95.2/99.8 MB 3.6 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 95.4/99.8 MB 3.5 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 95.6/99.8 MB 3.5 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 95.7/99.8 MB 3.5 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 95.8/99.8 MB 3.5 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 95.9/99.8 MB 3.4 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 95.9/99.8 MB 3.4 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 95.9/99.8 MB 3.4 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 96.1/99.8 MB 3.5 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 96.1/99.8 MB 3.4 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 96.2/99.8 MB 3.4 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 96.3/99.8 MB 3.4 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 96.4/99.8 MB 3.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 96.6/99.8 MB 3.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 96.7/99.8 MB 3.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 96.8/99.8 MB 3.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 97.0/99.8 MB 3.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 97.1/99.8 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  97.3/99.8 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  97.4/99.8 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  97.5/99.8 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  97.6/99.8 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  97.6/99.8 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  97.7/99.8 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  97.8/99.8 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  97.8/99.8 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  98.0/99.8 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  98.1/99.8 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  98.3/99.8 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  98.6/99.8 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  98.8/99.8 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  98.9/99.8 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.2/99.8 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.4/99.8 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.6/99.8 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 99.8/99.8 MB 2.9 MB/s eta 0:00:00\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-2.0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier F1 score:  0.9047475921034769\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_classifier = XGBClassifier()\n",
    "xgb_classifier.fit(X_train_vect, y_train)\n",
    "pred_xgb = xgb_classifier.predict(X_test_vect)\n",
    "print(\"XGBClassifier F1 score: \", f1_score(y_test, pred_xgb,average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting catboost\n",
      "  Obtaining dependency information for catboost from https://files.pythonhosted.org/packages/e8/37/3afd3c02798734efcd7840bfa872d3efc06f5d5c92f9613fea3ff5b4311f/catboost-1.2.3-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading catboost-1.2.3-cp311-cp311-win_amd64.whl.metadata (1.2 kB)\n",
      "Collecting graphviz (from catboost)\n",
      "  Obtaining dependency information for graphviz from https://files.pythonhosted.org/packages/00/be/d59db2d1d52697c6adc9eacaf50e8965b6345cc143f671e1ed068818d5cf/graphviz-0.20.3-py3-none-any.whl.metadata\n",
      "  Downloading graphviz-0.20.3-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\agrvi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from catboost) (3.7.2)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\agrvi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from catboost) (1.25.2)\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\users\\agrvi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from catboost) (2.0.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\agrvi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from catboost) (1.11.1)\n",
      "Requirement already satisfied: plotly in c:\\users\\agrvi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from catboost) (5.18.0)\n",
      "Requirement already satisfied: six in c:\\users\\agrvi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\agrvi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=0.24->catboost) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\agrvi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=0.24->catboost) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\agrvi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=0.24->catboost) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\agrvi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->catboost) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\agrvi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\agrvi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->catboost) (4.42.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\agrvi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->catboost) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\agrvi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->catboost) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\agrvi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->catboost) (10.0.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\agrvi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->catboost) (3.0.9)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\agrvi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from plotly->catboost) (8.2.3)\n",
      "Downloading catboost-1.2.3-cp311-cp311-win_amd64.whl (101.1 MB)\n",
      "   ---------------------------------------- 0.0/101.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/101.1 MB 3.2 MB/s eta 0:00:32\n",
      "   ---------------------------------------- 0.3/101.1 MB 4.9 MB/s eta 0:00:21\n",
      "   ---------------------------------------- 0.7/101.1 MB 6.9 MB/s eta 0:00:15\n",
      "   ---------------------------------------- 1.1/101.1 MB 7.2 MB/s eta 0:00:14\n",
      "    --------------------------------------- 1.5/101.1 MB 8.0 MB/s eta 0:00:13\n",
      "    --------------------------------------- 2.1/101.1 MB 8.8 MB/s eta 0:00:12\n",
      "    --------------------------------------- 2.4/101.1 MB 9.1 MB/s eta 0:00:11\n",
      "   - -------------------------------------- 2.9/101.1 MB 9.1 MB/s eta 0:00:11\n",
      "   - -------------------------------------- 3.2/101.1 MB 9.0 MB/s eta 0:00:11\n",
      "   - -------------------------------------- 3.7/101.1 MB 9.0 MB/s eta 0:00:11\n",
      "   - -------------------------------------- 4.1/101.1 MB 9.3 MB/s eta 0:00:11\n",
      "   - -------------------------------------- 4.5/101.1 MB 9.3 MB/s eta 0:00:11\n",
      "   - -------------------------------------- 4.9/101.1 MB 9.2 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 5.3/101.1 MB 9.4 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 5.7/101.1 MB 9.3 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 6.1/101.1 MB 9.5 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 6.5/101.1 MB 9.4 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 6.8/101.1 MB 9.5 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 7.2/101.1 MB 9.4 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 7.6/101.1 MB 9.3 MB/s eta 0:00:11\n",
      "   --- ------------------------------------ 8.0/101.1 MB 9.3 MB/s eta 0:00:10\n",
      "   --- ------------------------------------ 8.5/101.1 MB 9.5 MB/s eta 0:00:10\n",
      "   --- ------------------------------------ 8.9/101.1 MB 9.5 MB/s eta 0:00:10\n",
      "   --- ------------------------------------ 9.5/101.1 MB 9.6 MB/s eta 0:00:10\n",
      "   --- ------------------------------------ 9.9/101.1 MB 9.7 MB/s eta 0:00:10\n",
      "   ---- ----------------------------------- 10.4/101.1 MB 10.1 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 10.8/101.1 MB 10.1 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 11.4/101.1 MB 10.2 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 11.4/101.1 MB 10.2 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 11.4/101.1 MB 10.2 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 12.4/101.1 MB 10.2 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 12.7/101.1 MB 9.9 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 13.1/101.1 MB 9.8 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 13.4/101.1 MB 9.6 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 13.9/101.1 MB 9.8 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 14.2/101.1 MB 9.5 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 14.4/101.1 MB 9.4 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 14.6/101.1 MB 9.1 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 14.9/101.1 MB 9.1 MB/s eta 0:00:10\n",
      "   ------ --------------------------------- 15.3/101.1 MB 9.0 MB/s eta 0:00:10\n",
      "   ------ --------------------------------- 15.5/101.1 MB 8.7 MB/s eta 0:00:10\n",
      "   ------ --------------------------------- 15.6/101.1 MB 8.7 MB/s eta 0:00:10\n",
      "   ------ --------------------------------- 15.8/101.1 MB 8.6 MB/s eta 0:00:10\n",
      "   ------ --------------------------------- 16.2/101.1 MB 8.5 MB/s eta 0:00:10\n",
      "   ------ --------------------------------- 16.5/101.1 MB 8.4 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 16.7/101.1 MB 8.3 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 17.0/101.1 MB 8.2 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 17.1/101.1 MB 8.0 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 17.5/101.1 MB 8.1 MB/s eta 0:00:11\n",
      "   ------- -------------------------------- 17.9/101.1 MB 7.9 MB/s eta 0:00:11\n",
      "   ------- -------------------------------- 18.1/101.1 MB 7.9 MB/s eta 0:00:11\n",
      "   ------- -------------------------------- 18.3/101.1 MB 7.7 MB/s eta 0:00:11\n",
      "   ------- -------------------------------- 18.6/101.1 MB 7.7 MB/s eta 0:00:11\n",
      "   ------- -------------------------------- 18.9/101.1 MB 7.6 MB/s eta 0:00:11\n",
      "   ------- -------------------------------- 19.1/101.1 MB 7.5 MB/s eta 0:00:11\n",
      "   ------- -------------------------------- 19.5/101.1 MB 7.4 MB/s eta 0:00:12\n",
      "   ------- -------------------------------- 19.7/101.1 MB 7.4 MB/s eta 0:00:12\n",
      "   ------- -------------------------------- 19.9/101.1 MB 7.2 MB/s eta 0:00:12\n",
      "   -------- ------------------------------- 20.4/101.1 MB 7.1 MB/s eta 0:00:12\n",
      "   -------- ------------------------------- 20.8/101.1 MB 7.2 MB/s eta 0:00:12\n",
      "   -------- ------------------------------- 21.2/101.1 MB 7.0 MB/s eta 0:00:12\n",
      "   -------- ------------------------------- 21.7/101.1 MB 7.5 MB/s eta 0:00:11\n",
      "   -------- ------------------------------- 22.0/101.1 MB 7.3 MB/s eta 0:00:11\n",
      "   -------- ------------------------------- 22.6/101.1 MB 7.0 MB/s eta 0:00:12\n",
      "   --------- ------------------------------ 23.0/101.1 MB 7.3 MB/s eta 0:00:11\n",
      "   --------- ------------------------------ 23.4/101.1 MB 7.4 MB/s eta 0:00:11\n",
      "   --------- ------------------------------ 23.9/101.1 MB 7.3 MB/s eta 0:00:11\n",
      "   --------- ------------------------------ 24.3/101.1 MB 7.4 MB/s eta 0:00:11\n",
      "   --------- ------------------------------ 24.6/101.1 MB 7.5 MB/s eta 0:00:11\n",
      "   --------- ------------------------------ 25.1/101.1 MB 7.7 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 25.6/101.1 MB 7.9 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 26.1/101.1 MB 8.3 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 26.6/101.1 MB 8.3 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 27.1/101.1 MB 8.8 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 27.6/101.1 MB 9.2 MB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 28.1/101.1 MB 9.4 MB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 28.6/101.1 MB 9.8 MB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 29.1/101.1 MB 10.2 MB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 29.6/101.1 MB 10.4 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 30.1/101.1 MB 11.1 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 30.6/101.1 MB 11.1 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 31.1/101.1 MB 11.3 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 31.6/101.1 MB 11.3 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 32.1/101.1 MB 11.3 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 32.6/101.1 MB 11.5 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 33.1/101.1 MB 11.5 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 33.5/101.1 MB 11.7 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 33.8/101.1 MB 11.3 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 34.3/101.1 MB 11.5 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 34.8/101.1 MB 11.5 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 35.3/101.1 MB 11.3 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 35.7/101.1 MB 11.5 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 36.2/101.1 MB 11.5 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 36.5/101.1 MB 11.3 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 37.1/101.1 MB 11.3 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 37.4/101.1 MB 11.3 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 37.6/101.1 MB 11.3 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 38.5/101.1 MB 11.1 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 39.0/101.1 MB 11.1 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 39.7/101.1 MB 11.5 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 40.1/101.1 MB 11.5 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 40.7/101.1 MB 11.5 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 41.2/101.1 MB 11.3 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 41.6/101.1 MB 11.3 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 42.2/101.1 MB 11.5 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 42.6/101.1 MB 11.3 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 43.0/101.1 MB 11.3 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 43.4/101.1 MB 11.1 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 43.7/101.1 MB 11.1 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 44.0/101.1 MB 11.1 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 44.4/101.1 MB 11.3 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 44.9/101.1 MB 11.1 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 45.2/101.1 MB 10.9 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 45.6/101.1 MB 10.9 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 46.0/101.1 MB 10.7 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 46.4/101.1 MB 10.9 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 46.8/101.1 MB 10.9 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 47.1/101.1 MB 10.7 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 47.6/101.1 MB 10.7 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 47.9/101.1 MB 11.1 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 48.3/101.1 MB 10.4 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 48.6/101.1 MB 10.4 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 49.0/101.1 MB 10.2 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 49.4/101.1 MB 10.1 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 49.8/101.1 MB 9.9 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 50.2/101.1 MB 9.8 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 50.7/101.1 MB 9.9 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 51.1/101.1 MB 9.8 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 51.5/101.1 MB 9.8 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 52.0/101.1 MB 9.8 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 52.3/101.1 MB 9.5 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 52.7/101.1 MB 9.5 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 52.7/101.1 MB 9.4 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 52.7/101.1 MB 9.4 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 52.7/101.1 MB 9.4 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 52.7/101.1 MB 9.4 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 53.9/101.1 MB 8.7 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 54.0/101.1 MB 8.6 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 54.2/101.1 MB 8.6 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 54.5/101.1 MB 8.4 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 54.7/101.1 MB 8.2 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 55.1/101.1 MB 8.2 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 55.4/101.1 MB 8.1 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 55.6/101.1 MB 8.0 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 55.9/101.1 MB 8.0 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 56.2/101.1 MB 7.9 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 56.5/101.1 MB 8.0 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 56.6/101.1 MB 7.6 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 56.9/101.1 MB 7.5 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 57.3/101.1 MB 7.5 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 57.4/101.1 MB 7.6 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 57.5/101.1 MB 7.3 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 57.7/101.1 MB 7.2 MB/s eta 0:00:07\n",
      "   ---------------------- ----------------- 57.7/101.1 MB 7.0 MB/s eta 0:00:07\n",
      "   ---------------------- ----------------- 58.0/101.1 MB 6.9 MB/s eta 0:00:07\n",
      "   ----------------------- ---------------- 58.4/101.1 MB 7.0 MB/s eta 0:00:07\n",
      "   ----------------------- ---------------- 58.6/101.1 MB 7.0 MB/s eta 0:00:07\n",
      "   ----------------------- ---------------- 59.3/101.1 MB 6.9 MB/s eta 0:00:07\n",
      "   ----------------------- ---------------- 59.3/101.1 MB 6.9 MB/s eta 0:00:07\n",
      "   ----------------------- ---------------- 59.6/101.1 MB 6.7 MB/s eta 0:00:07\n",
      "   ----------------------- ---------------- 60.2/101.1 MB 6.7 MB/s eta 0:00:07\n",
      "   ----------------------- ---------------- 60.3/101.1 MB 6.6 MB/s eta 0:00:07\n",
      "   ----------------------- ---------------- 60.6/101.1 MB 6.5 MB/s eta 0:00:07\n",
      "   ------------------------ --------------- 60.8/101.1 MB 6.4 MB/s eta 0:00:07\n",
      "   ------------------------ --------------- 61.1/101.1 MB 6.3 MB/s eta 0:00:07\n",
      "   ------------------------ --------------- 61.2/101.1 MB 6.2 MB/s eta 0:00:07\n",
      "   ------------------------ --------------- 61.7/101.1 MB 6.2 MB/s eta 0:00:07\n",
      "   ------------------------ --------------- 62.0/101.1 MB 6.1 MB/s eta 0:00:07\n",
      "   ------------------------ --------------- 62.0/101.1 MB 6.1 MB/s eta 0:00:07\n",
      "   ------------------------ --------------- 62.1/101.1 MB 5.9 MB/s eta 0:00:07\n",
      "   ------------------------ --------------- 62.1/101.1 MB 5.6 MB/s eta 0:00:07\n",
      "   ------------------------ --------------- 62.2/101.1 MB 5.7 MB/s eta 0:00:07\n",
      "   ------------------------ --------------- 62.8/101.1 MB 5.7 MB/s eta 0:00:07\n",
      "   ------------------------ --------------- 62.9/101.1 MB 5.6 MB/s eta 0:00:07\n",
      "   ------------------------ --------------- 63.1/101.1 MB 6.1 MB/s eta 0:00:07\n",
      "   ------------------------- -------------- 63.4/101.1 MB 6.0 MB/s eta 0:00:07\n",
      "   ------------------------- -------------- 63.5/101.1 MB 5.9 MB/s eta 0:00:07\n",
      "   ------------------------- -------------- 63.8/101.1 MB 5.7 MB/s eta 0:00:07\n",
      "   ------------------------- -------------- 64.1/101.1 MB 5.6 MB/s eta 0:00:07\n",
      "   ------------------------- -------------- 64.5/101.1 MB 5.7 MB/s eta 0:00:07\n",
      "   ------------------------- -------------- 65.1/101.1 MB 5.9 MB/s eta 0:00:07\n",
      "   ------------------------- -------------- 65.3/101.1 MB 5.8 MB/s eta 0:00:07\n",
      "   ------------------------- -------------- 65.7/101.1 MB 5.9 MB/s eta 0:00:07\n",
      "   -------------------------- ------------- 66.1/101.1 MB 6.1 MB/s eta 0:00:06\n",
      "   -------------------------- ------------- 66.4/101.1 MB 6.1 MB/s eta 0:00:06\n",
      "   -------------------------- ------------- 66.7/101.1 MB 6.0 MB/s eta 0:00:06\n",
      "   -------------------------- ------------- 67.1/101.1 MB 6.2 MB/s eta 0:00:06\n",
      "   -------------------------- ------------- 67.3/101.1 MB 6.2 MB/s eta 0:00:06\n",
      "   -------------------------- ------------- 67.7/101.1 MB 6.4 MB/s eta 0:00:06\n",
      "   -------------------------- ------------- 68.0/101.1 MB 6.5 MB/s eta 0:00:06\n",
      "   --------------------------- ------------ 68.3/101.1 MB 6.5 MB/s eta 0:00:06\n",
      "   --------------------------- ------------ 68.6/101.1 MB 6.5 MB/s eta 0:00:06\n",
      "   --------------------------- ------------ 68.9/101.1 MB 6.5 MB/s eta 0:00:05\n",
      "   --------------------------- ------------ 69.3/101.1 MB 6.5 MB/s eta 0:00:05\n",
      "   --------------------------- ------------ 69.5/101.1 MB 6.6 MB/s eta 0:00:05\n",
      "   --------------------------- ------------ 69.8/101.1 MB 6.5 MB/s eta 0:00:05\n",
      "   --------------------------- ------------ 69.9/101.1 MB 6.5 MB/s eta 0:00:05\n",
      "   --------------------------- ------------ 70.0/101.1 MB 6.3 MB/s eta 0:00:05\n",
      "   --------------------------- ------------ 70.0/101.1 MB 6.3 MB/s eta 0:00:05\n",
      "   --------------------------- ------------ 70.0/101.1 MB 6.3 MB/s eta 0:00:05\n",
      "   --------------------------- ------------ 70.6/101.1 MB 6.1 MB/s eta 0:00:05\n",
      "   ---------------------------- ----------- 70.8/101.1 MB 6.1 MB/s eta 0:00:05\n",
      "   ---------------------------- ----------- 71.1/101.1 MB 6.2 MB/s eta 0:00:05\n",
      "   ---------------------------- ----------- 71.2/101.1 MB 6.2 MB/s eta 0:00:05\n",
      "   ---------------------------- ----------- 71.8/101.1 MB 6.2 MB/s eta 0:00:05\n",
      "   ---------------------------- ----------- 72.0/101.1 MB 6.2 MB/s eta 0:00:05\n",
      "   ---------------------------- ----------- 72.4/101.1 MB 7.0 MB/s eta 0:00:05\n",
      "   ---------------------------- ----------- 72.8/101.1 MB 6.8 MB/s eta 0:00:05\n",
      "   ---------------------------- ----------- 73.2/101.1 MB 7.0 MB/s eta 0:00:05\n",
      "   ----------------------------- ---------- 73.6/101.1 MB 7.0 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 74.0/101.1 MB 7.3 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 74.3/101.1 MB 7.4 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 74.7/101.1 MB 7.3 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 75.0/101.1 MB 7.2 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 75.4/101.1 MB 7.3 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 75.7/101.1 MB 7.2 MB/s eta 0:00:04\n",
      "   ------------------------------ --------- 76.1/101.1 MB 7.3 MB/s eta 0:00:04\n",
      "   ------------------------------ --------- 76.5/101.1 MB 7.2 MB/s eta 0:00:04\n",
      "   ------------------------------ --------- 76.7/101.1 MB 7.1 MB/s eta 0:00:04\n",
      "   ------------------------------ --------- 76.9/101.1 MB 7.0 MB/s eta 0:00:04\n",
      "   ------------------------------ --------- 77.1/101.1 MB 7.0 MB/s eta 0:00:04\n",
      "   ------------------------------ --------- 77.4/101.1 MB 7.0 MB/s eta 0:00:04\n",
      "   ------------------------------ --------- 77.8/101.1 MB 7.0 MB/s eta 0:00:04\n",
      "   ------------------------------ --------- 78.2/101.1 MB 7.0 MB/s eta 0:00:04\n",
      "   ------------------------------- -------- 78.4/101.1 MB 7.0 MB/s eta 0:00:04\n",
      "   ------------------------------- -------- 78.4/101.1 MB 7.0 MB/s eta 0:00:04\n",
      "   ------------------------------- -------- 78.4/101.1 MB 7.0 MB/s eta 0:00:04\n",
      "   ------------------------------- -------- 78.9/101.1 MB 6.8 MB/s eta 0:00:04\n",
      "   ------------------------------- -------- 78.9/101.1 MB 6.5 MB/s eta 0:00:04\n",
      "   ------------------------------- -------- 79.1/101.1 MB 6.5 MB/s eta 0:00:04\n",
      "   ------------------------------- -------- 79.4/101.1 MB 6.5 MB/s eta 0:00:04\n",
      "   ------------------------------- -------- 79.7/101.1 MB 6.5 MB/s eta 0:00:04\n",
      "   ------------------------------- -------- 79.8/101.1 MB 6.5 MB/s eta 0:00:04\n",
      "   ------------------------------- -------- 80.1/101.1 MB 6.4 MB/s eta 0:00:04\n",
      "   ------------------------------- -------- 80.5/101.1 MB 7.2 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 81.0/101.1 MB 7.1 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 81.3/101.1 MB 7.1 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 81.7/101.1 MB 7.2 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 82.0/101.1 MB 7.1 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 82.4/101.1 MB 7.2 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 82.7/101.1 MB 7.2 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 83.1/101.1 MB 7.1 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 83.5/101.1 MB 7.2 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 83.8/101.1 MB 7.1 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 84.2/101.1 MB 7.1 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 84.6/101.1 MB 7.1 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 85.0/101.1 MB 7.1 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 85.4/101.1 MB 7.2 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 85.7/101.1 MB 7.2 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 86.2/101.1 MB 7.2 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 86.6/101.1 MB 7.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 87.0/101.1 MB 7.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 87.3/101.1 MB 7.6 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 87.6/101.1 MB 7.7 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 88.0/101.1 MB 7.6 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 88.3/101.1 MB 7.5 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 88.6/101.1 MB 7.5 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 89.1/101.1 MB 8.0 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 89.3/101.1 MB 8.3 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 89.5/101.1 MB 8.3 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 89.7/101.1 MB 8.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 89.8/101.1 MB 8.1 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 89.9/101.1 MB 7.9 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 90.1/101.1 MB 8.0 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 90.3/101.1 MB 7.7 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 90.6/101.1 MB 7.7 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 90.8/101.1 MB 7.5 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 91.0/101.1 MB 7.5 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 91.1/101.1 MB 7.4 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 91.1/101.1 MB 7.1 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 91.1/101.1 MB 6.8 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 91.2/101.1 MB 6.7 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 91.4/101.1 MB 6.7 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 91.6/101.1 MB 6.5 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 91.8/101.1 MB 6.5 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 92.2/101.1 MB 6.4 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 92.4/101.1 MB 6.3 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 92.7/101.1 MB 6.4 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 92.8/101.1 MB 6.2 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 93.1/101.1 MB 6.2 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 93.4/101.1 MB 6.2 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 93.8/101.1 MB 6.1 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 94.0/101.1 MB 6.0 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 94.3/101.1 MB 6.0 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 94.6/101.1 MB 6.0 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 94.9/101.1 MB 5.9 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 95.1/101.1 MB 5.8 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 95.4/101.1 MB 5.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 95.7/101.1 MB 5.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 95.9/101.1 MB 5.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 96.1/101.1 MB 5.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 96.3/101.1 MB 5.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 96.6/101.1 MB 5.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 96.9/101.1 MB 5.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 97.3/101.1 MB 5.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 97.7/101.1 MB 5.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 98.2/101.1 MB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  98.6/101.1 MB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.0/101.1 MB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.4/101.1 MB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.8/101.1 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  100.2/101.1 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  100.6/101.1 MB 6.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  100.9/101.1 MB 6.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  101.0/101.1 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  101.0/101.1 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  101.0/101.1 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  101.0/101.1 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  101.0/101.1 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  101.0/101.1 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  101.0/101.1 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  101.0/101.1 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 101.1/101.1 MB 5.1 MB/s eta 0:00:00\n",
      "Downloading graphviz-0.20.3-py3-none-any.whl (47 kB)\n",
      "   ---------------------------------------- 0.0/47.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 47.1/47.1 kB ? eta 0:00:00\n",
      "Installing collected packages: graphviz, catboost\n",
      "Successfully installed catboost-1.2.3 graphviz-0.20.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.090833\n",
      "0:\tlearn: 2.2237619\ttotal: 1.5s\tremaining: 25m 2s\n",
      "1:\tlearn: 2.1339310\ttotal: 2.83s\tremaining: 23m 34s\n",
      "2:\tlearn: 2.0608854\ttotal: 4.37s\tremaining: 24m 12s\n",
      "3:\tlearn: 2.0004944\ttotal: 6.13s\tremaining: 25m 27s\n",
      "4:\tlearn: 1.9479734\ttotal: 7.82s\tremaining: 25m 55s\n",
      "5:\tlearn: 1.9062160\ttotal: 9.73s\tremaining: 26m 51s\n",
      "6:\tlearn: 1.8650838\ttotal: 11.7s\tremaining: 27m 33s\n",
      "7:\tlearn: 1.8258721\ttotal: 13.3s\tremaining: 27m 29s\n",
      "8:\tlearn: 1.7985235\ttotal: 14.8s\tremaining: 27m 7s\n",
      "9:\tlearn: 1.7674699\ttotal: 16.3s\tremaining: 26m 50s\n",
      "10:\tlearn: 1.7407183\ttotal: 17.6s\tremaining: 26m 21s\n",
      "11:\tlearn: 1.7209546\ttotal: 18.8s\tremaining: 25m 49s\n",
      "12:\tlearn: 1.6977838\ttotal: 20.2s\tremaining: 25m 37s\n",
      "13:\tlearn: 1.6773939\ttotal: 21.7s\tremaining: 25m 28s\n",
      "14:\tlearn: 1.6574213\ttotal: 23.3s\tremaining: 25m 33s\n",
      "15:\tlearn: 1.6418542\ttotal: 24.9s\tremaining: 25m 34s\n",
      "16:\tlearn: 1.6248921\ttotal: 28.9s\tremaining: 27m 51s\n",
      "17:\tlearn: 1.6076063\ttotal: 35.8s\tremaining: 32m 33s\n",
      "18:\tlearn: 1.5942347\ttotal: 42.3s\tremaining: 36m 22s\n",
      "19:\tlearn: 1.5777600\ttotal: 49.1s\tremaining: 40m 6s\n",
      "20:\tlearn: 1.5641225\ttotal: 59.1s\tremaining: 45m 55s\n",
      "21:\tlearn: 1.5495300\ttotal: 1m 4s\tremaining: 47m 40s\n",
      "22:\tlearn: 1.5393653\ttotal: 1m 10s\tremaining: 49m 49s\n",
      "23:\tlearn: 1.5258259\ttotal: 1m 11s\tremaining: 48m 44s\n",
      "24:\tlearn: 1.5106298\ttotal: 1m 13s\tremaining: 47m 30s\n",
      "25:\tlearn: 1.4980546\ttotal: 1m 14s\tremaining: 46m 22s\n",
      "26:\tlearn: 1.4868887\ttotal: 1m 15s\tremaining: 45m 22s\n",
      "27:\tlearn: 1.4780850\ttotal: 1m 16s\tremaining: 44m 25s\n",
      "28:\tlearn: 1.4673724\ttotal: 1m 17s\tremaining: 43m 31s\n",
      "29:\tlearn: 1.4578186\ttotal: 1m 19s\tremaining: 42m 40s\n",
      "30:\tlearn: 1.4467700\ttotal: 1m 20s\tremaining: 41m 52s\n",
      "31:\tlearn: 1.4388229\ttotal: 1m 21s\tremaining: 41m 10s\n",
      "32:\tlearn: 1.4285196\ttotal: 1m 22s\tremaining: 40m 27s\n",
      "33:\tlearn: 1.4200090\ttotal: 1m 24s\tremaining: 39m 47s\n",
      "34:\tlearn: 1.4117393\ttotal: 1m 25s\tremaining: 39m 10s\n",
      "35:\tlearn: 1.4048311\ttotal: 1m 26s\tremaining: 38m 34s\n",
      "36:\tlearn: 1.3953947\ttotal: 1m 27s\tremaining: 38m 3s\n",
      "37:\tlearn: 1.3855269\ttotal: 1m 28s\tremaining: 37m 32s\n",
      "38:\tlearn: 1.3768424\ttotal: 1m 30s\tremaining: 37m 2s\n",
      "39:\tlearn: 1.3693495\ttotal: 1m 31s\tremaining: 36m 33s\n",
      "40:\tlearn: 1.3624872\ttotal: 1m 32s\tremaining: 36m 5s\n",
      "41:\tlearn: 1.3550468\ttotal: 1m 33s\tremaining: 35m 38s\n",
      "42:\tlearn: 1.3440836\ttotal: 1m 34s\tremaining: 35m 14s\n",
      "43:\tlearn: 1.3376699\ttotal: 1m 36s\tremaining: 34m 50s\n",
      "44:\tlearn: 1.3312949\ttotal: 1m 37s\tremaining: 34m 27s\n",
      "45:\tlearn: 1.3235741\ttotal: 1m 38s\tremaining: 34m 5s\n",
      "46:\tlearn: 1.3174130\ttotal: 1m 39s\tremaining: 33m 45s\n",
      "47:\tlearn: 1.3095012\ttotal: 1m 41s\tremaining: 33m 30s\n",
      "48:\tlearn: 1.3044323\ttotal: 1m 42s\tremaining: 33m 17s\n",
      "49:\tlearn: 1.2972421\ttotal: 1m 44s\tremaining: 33m 2s\n",
      "50:\tlearn: 1.2909946\ttotal: 1m 45s\tremaining: 32m 45s\n",
      "51:\tlearn: 1.2850204\ttotal: 1m 53s\tremaining: 34m 23s\n",
      "52:\tlearn: 1.2794280\ttotal: 1m 57s\tremaining: 35m 4s\n",
      "53:\tlearn: 1.2745988\ttotal: 2m 3s\tremaining: 36m 7s\n",
      "54:\tlearn: 1.2689600\ttotal: 2m 10s\tremaining: 37m 25s\n",
      "55:\tlearn: 1.2626407\ttotal: 2m 18s\tremaining: 38m 50s\n",
      "56:\tlearn: 1.2569486\ttotal: 2m 26s\tremaining: 40m 24s\n",
      "57:\tlearn: 1.2510887\ttotal: 2m 28s\tremaining: 40m 5s\n",
      "58:\tlearn: 1.2458716\ttotal: 2m 29s\tremaining: 39m 42s\n",
      "59:\tlearn: 1.2404205\ttotal: 2m 30s\tremaining: 39m 23s\n",
      "60:\tlearn: 1.2352742\ttotal: 2m 32s\tremaining: 39m 8s\n",
      "61:\tlearn: 1.2319040\ttotal: 2m 33s\tremaining: 38m 48s\n",
      "62:\tlearn: 1.2283116\ttotal: 2m 35s\tremaining: 38m 29s\n",
      "63:\tlearn: 1.2246649\ttotal: 2m 37s\tremaining: 38m 30s\n",
      "64:\tlearn: 1.2209177\ttotal: 2m 45s\tremaining: 39m 44s\n",
      "65:\tlearn: 1.2159850\ttotal: 2m 47s\tremaining: 39m 25s\n",
      "66:\tlearn: 1.2122609\ttotal: 2m 48s\tremaining: 39m 6s\n",
      "67:\tlearn: 1.2052651\ttotal: 2m 49s\tremaining: 38m 47s\n",
      "68:\tlearn: 1.2019529\ttotal: 2m 51s\tremaining: 38m 29s\n",
      "69:\tlearn: 1.1983078\ttotal: 2m 52s\tremaining: 38m 13s\n",
      "70:\tlearn: 1.1931125\ttotal: 2m 54s\tremaining: 37m 56s\n",
      "71:\tlearn: 1.1875905\ttotal: 2m 55s\tremaining: 37m 38s\n",
      "72:\tlearn: 1.1833217\ttotal: 2m 56s\tremaining: 37m 22s\n",
      "73:\tlearn: 1.1794103\ttotal: 2m 58s\tremaining: 37m 9s\n",
      "74:\tlearn: 1.1759325\ttotal: 2m 59s\tremaining: 36m 54s\n",
      "75:\tlearn: 1.1711957\ttotal: 3m\tremaining: 36m 40s\n",
      "76:\tlearn: 1.1675262\ttotal: 3m 2s\tremaining: 36m 26s\n",
      "77:\tlearn: 1.1637705\ttotal: 3m 3s\tremaining: 36m 13s\n",
      "78:\tlearn: 1.1599122\ttotal: 3m 5s\tremaining: 35m 58s\n",
      "79:\tlearn: 1.1566183\ttotal: 3m 6s\tremaining: 35m 45s\n",
      "80:\tlearn: 1.1518173\ttotal: 3m 7s\tremaining: 35m 31s\n",
      "81:\tlearn: 1.1489438\ttotal: 3m 9s\tremaining: 35m 19s\n",
      "82:\tlearn: 1.1449892\ttotal: 3m 10s\tremaining: 35m 7s\n",
      "83:\tlearn: 1.1417879\ttotal: 3m 11s\tremaining: 34m 53s\n",
      "84:\tlearn: 1.1390476\ttotal: 3m 13s\tremaining: 34m 42s\n",
      "85:\tlearn: 1.1355996\ttotal: 3m 14s\tremaining: 34m 31s\n",
      "86:\tlearn: 1.1311424\ttotal: 3m 16s\tremaining: 34m 19s\n",
      "87:\tlearn: 1.1273796\ttotal: 3m 17s\tremaining: 34m 6s\n",
      "88:\tlearn: 1.1240865\ttotal: 3m 18s\tremaining: 33m 54s\n",
      "89:\tlearn: 1.1202015\ttotal: 3m 20s\tremaining: 33m 43s\n",
      "90:\tlearn: 1.1168765\ttotal: 3m 21s\tremaining: 33m 32s\n",
      "91:\tlearn: 1.1134196\ttotal: 3m 22s\tremaining: 33m 23s\n",
      "92:\tlearn: 1.1108857\ttotal: 3m 24s\tremaining: 33m 12s\n",
      "93:\tlearn: 1.1071624\ttotal: 3m 25s\tremaining: 33m 2s\n",
      "94:\tlearn: 1.1033367\ttotal: 3m 26s\tremaining: 32m 51s\n",
      "95:\tlearn: 1.0989999\ttotal: 3m 28s\tremaining: 32m 42s\n",
      "96:\tlearn: 1.0958620\ttotal: 3m 29s\tremaining: 32m 32s\n",
      "97:\tlearn: 1.0931960\ttotal: 3m 31s\tremaining: 32m 23s\n",
      "98:\tlearn: 1.0892604\ttotal: 3m 32s\tremaining: 32m 15s\n",
      "99:\tlearn: 1.0865388\ttotal: 3m 34s\tremaining: 32m 7s\n",
      "100:\tlearn: 1.0829700\ttotal: 3m 35s\tremaining: 32m\n",
      "101:\tlearn: 1.0797636\ttotal: 3m 37s\tremaining: 31m 52s\n",
      "102:\tlearn: 1.0771431\ttotal: 3m 38s\tremaining: 31m 44s\n",
      "103:\tlearn: 1.0746232\ttotal: 3m 40s\tremaining: 31m 35s\n",
      "104:\tlearn: 1.0718618\ttotal: 3m 41s\tremaining: 31m 27s\n",
      "105:\tlearn: 1.0692570\ttotal: 3m 42s\tremaining: 31m 19s\n",
      "106:\tlearn: 1.0667694\ttotal: 3m 44s\tremaining: 31m 12s\n",
      "107:\tlearn: 1.0637335\ttotal: 3m 45s\tremaining: 31m 5s\n",
      "108:\tlearn: 1.0608049\ttotal: 3m 47s\tremaining: 30m 57s\n",
      "109:\tlearn: 1.0572820\ttotal: 3m 48s\tremaining: 30m 48s\n",
      "110:\tlearn: 1.0544523\ttotal: 3m 49s\tremaining: 30m 40s\n",
      "111:\tlearn: 1.0520841\ttotal: 3m 51s\tremaining: 30m 34s\n",
      "112:\tlearn: 1.0496117\ttotal: 3m 52s\tremaining: 30m 27s\n",
      "113:\tlearn: 1.0473478\ttotal: 3m 54s\tremaining: 30m 19s\n",
      "114:\tlearn: 1.0440167\ttotal: 3m 55s\tremaining: 30m 13s\n",
      "115:\tlearn: 1.0415851\ttotal: 3m 57s\tremaining: 30m 7s\n",
      "116:\tlearn: 1.0380197\ttotal: 3m 58s\tremaining: 30m\n",
      "117:\tlearn: 1.0357522\ttotal: 4m\tremaining: 29m 55s\n",
      "118:\tlearn: 1.0332639\ttotal: 4m 1s\tremaining: 29m 47s\n",
      "119:\tlearn: 1.0301302\ttotal: 4m 2s\tremaining: 29m 41s\n",
      "120:\tlearn: 1.0270030\ttotal: 4m 4s\tremaining: 29m 35s\n",
      "121:\tlearn: 1.0248897\ttotal: 4m 5s\tremaining: 29m 28s\n",
      "122:\tlearn: 1.0225380\ttotal: 4m 7s\tremaining: 29m 22s\n",
      "123:\tlearn: 1.0203364\ttotal: 4m 8s\tremaining: 29m 15s\n",
      "124:\tlearn: 1.0182133\ttotal: 4m 10s\tremaining: 29m 10s\n",
      "125:\tlearn: 1.0145288\ttotal: 4m 11s\tremaining: 29m 5s\n",
      "126:\tlearn: 1.0123950\ttotal: 4m 12s\tremaining: 28m 58s\n",
      "127:\tlearn: 1.0091500\ttotal: 4m 14s\tremaining: 28m 51s\n",
      "128:\tlearn: 1.0073166\ttotal: 4m 15s\tremaining: 28m 46s\n",
      "129:\tlearn: 1.0046005\ttotal: 4m 17s\tremaining: 28m 41s\n",
      "130:\tlearn: 1.0025900\ttotal: 4m 18s\tremaining: 28m 35s\n",
      "131:\tlearn: 1.0004202\ttotal: 4m 20s\tremaining: 28m 29s\n",
      "132:\tlearn: 0.9985804\ttotal: 4m 21s\tremaining: 28m 24s\n",
      "133:\tlearn: 0.9967131\ttotal: 4m 22s\tremaining: 28m 18s\n",
      "134:\tlearn: 0.9944130\ttotal: 4m 24s\tremaining: 28m 12s\n",
      "135:\tlearn: 0.9924745\ttotal: 4m 25s\tremaining: 28m 6s\n",
      "136:\tlearn: 0.9907684\ttotal: 4m 26s\tremaining: 28m\n",
      "137:\tlearn: 0.9863159\ttotal: 4m 28s\tremaining: 27m 54s\n",
      "138:\tlearn: 0.9842946\ttotal: 4m 29s\tremaining: 27m 49s\n",
      "139:\tlearn: 0.9822426\ttotal: 4m 31s\tremaining: 27m 44s\n",
      "140:\tlearn: 0.9802899\ttotal: 4m 32s\tremaining: 27m 39s\n",
      "141:\tlearn: 0.9782862\ttotal: 4m 34s\tremaining: 27m 38s\n",
      "142:\tlearn: 0.9759124\ttotal: 4m 39s\tremaining: 27m 57s\n",
      "143:\tlearn: 0.9732204\ttotal: 4m 44s\tremaining: 28m 11s\n",
      "144:\tlearn: 0.9713403\ttotal: 4m 49s\tremaining: 28m 28s\n",
      "145:\tlearn: 0.9697806\ttotal: 4m 57s\tremaining: 28m 58s\n",
      "146:\tlearn: 0.9671060\ttotal: 5m 4s\tremaining: 29m 24s\n",
      "147:\tlearn: 0.9652990\ttotal: 5m 10s\tremaining: 29m 46s\n",
      "148:\tlearn: 0.9630394\ttotal: 5m 14s\tremaining: 29m 58s\n",
      "149:\tlearn: 0.9597534\ttotal: 5m 19s\tremaining: 30m 10s\n",
      "150:\tlearn: 0.9583579\ttotal: 5m 27s\tremaining: 30m 38s\n",
      "151:\tlearn: 0.9567126\ttotal: 5m 33s\tremaining: 31m 3s\n",
      "152:\tlearn: 0.9550557\ttotal: 5m 40s\tremaining: 31m 23s\n",
      "153:\tlearn: 0.9535418\ttotal: 5m 41s\tremaining: 31m 17s\n",
      "154:\tlearn: 0.9518892\ttotal: 5m 43s\tremaining: 31m 10s\n",
      "155:\tlearn: 0.9502911\ttotal: 5m 44s\tremaining: 31m 3s\n",
      "156:\tlearn: 0.9487320\ttotal: 5m 45s\tremaining: 30m 56s\n",
      "157:\tlearn: 0.9467032\ttotal: 5m 47s\tremaining: 30m 51s\n",
      "158:\tlearn: 0.9455359\ttotal: 5m 48s\tremaining: 30m 45s\n",
      "159:\tlearn: 0.9442963\ttotal: 5m 50s\tremaining: 30m 39s\n",
      "160:\tlearn: 0.9413363\ttotal: 5m 51s\tremaining: 30m 32s\n",
      "161:\tlearn: 0.9397387\ttotal: 5m 52s\tremaining: 30m 25s\n",
      "162:\tlearn: 0.9381696\ttotal: 5m 54s\tremaining: 30m 18s\n",
      "163:\tlearn: 0.9367543\ttotal: 5m 55s\tremaining: 30m 12s\n",
      "164:\tlearn: 0.9354435\ttotal: 5m 57s\tremaining: 30m 6s\n",
      "165:\tlearn: 0.9337945\ttotal: 5m 58s\tremaining: 30m\n",
      "166:\tlearn: 0.9323850\ttotal: 5m 59s\tremaining: 29m 55s\n",
      "167:\tlearn: 0.9309734\ttotal: 6m 1s\tremaining: 29m 48s\n",
      "168:\tlearn: 0.9295982\ttotal: 6m 2s\tremaining: 29m 42s\n",
      "169:\tlearn: 0.9281759\ttotal: 6m 4s\tremaining: 29m 37s\n",
      "170:\tlearn: 0.9255586\ttotal: 6m 5s\tremaining: 29m 31s\n",
      "171:\tlearn: 0.9237873\ttotal: 6m 6s\tremaining: 29m 26s\n",
      "172:\tlearn: 0.9223433\ttotal: 6m 8s\tremaining: 29m 19s\n",
      "173:\tlearn: 0.9206710\ttotal: 6m 9s\tremaining: 29m 13s\n",
      "174:\tlearn: 0.9191750\ttotal: 6m 10s\tremaining: 29m 7s\n",
      "175:\tlearn: 0.9179487\ttotal: 6m 12s\tremaining: 29m 2s\n",
      "176:\tlearn: 0.9165898\ttotal: 6m 13s\tremaining: 28m 56s\n",
      "177:\tlearn: 0.9153648\ttotal: 6m 14s\tremaining: 28m 51s\n",
      "178:\tlearn: 0.9139243\ttotal: 6m 16s\tremaining: 28m 47s\n",
      "179:\tlearn: 0.9128657\ttotal: 6m 18s\tremaining: 28m 42s\n",
      "180:\tlearn: 0.9116370\ttotal: 6m 19s\tremaining: 28m 37s\n",
      "181:\tlearn: 0.9103228\ttotal: 6m 20s\tremaining: 28m 31s\n",
      "182:\tlearn: 0.9090639\ttotal: 6m 22s\tremaining: 28m 25s\n",
      "183:\tlearn: 0.9079680\ttotal: 6m 23s\tremaining: 28m 20s\n",
      "184:\tlearn: 0.9066462\ttotal: 6m 24s\tremaining: 28m 15s\n",
      "185:\tlearn: 0.9049852\ttotal: 6m 26s\tremaining: 28m 10s\n",
      "186:\tlearn: 0.9036742\ttotal: 6m 27s\tremaining: 28m 5s\n",
      "187:\tlearn: 0.9020016\ttotal: 6m 29s\tremaining: 28m 1s\n",
      "188:\tlearn: 0.9003906\ttotal: 6m 30s\tremaining: 27m 56s\n",
      "189:\tlearn: 0.8989581\ttotal: 6m 32s\tremaining: 27m 52s\n",
      "190:\tlearn: 0.8978954\ttotal: 6m 33s\tremaining: 27m 48s\n",
      "191:\tlearn: 0.8957041\ttotal: 6m 35s\tremaining: 27m 43s\n",
      "192:\tlearn: 0.8933881\ttotal: 6m 36s\tremaining: 27m 37s\n",
      "193:\tlearn: 0.8920329\ttotal: 6m 37s\tremaining: 27m 33s\n",
      "194:\tlearn: 0.8905522\ttotal: 6m 39s\tremaining: 27m 28s\n",
      "195:\tlearn: 0.8892711\ttotal: 6m 40s\tremaining: 27m 24s\n",
      "196:\tlearn: 0.8877896\ttotal: 6m 42s\tremaining: 27m 20s\n",
      "197:\tlearn: 0.8866879\ttotal: 6m 43s\tremaining: 27m 15s\n",
      "198:\tlearn: 0.8852217\ttotal: 6m 45s\tremaining: 27m 10s\n",
      "199:\tlearn: 0.8841170\ttotal: 6m 46s\tremaining: 27m 5s\n",
      "200:\tlearn: 0.8829979\ttotal: 6m 47s\tremaining: 27m\n",
      "201:\tlearn: 0.8819125\ttotal: 6m 48s\tremaining: 26m 54s\n",
      "202:\tlearn: 0.8803222\ttotal: 6m 50s\tremaining: 26m 50s\n",
      "203:\tlearn: 0.8789581\ttotal: 6m 51s\tremaining: 26m 45s\n",
      "204:\tlearn: 0.8776822\ttotal: 6m 52s\tremaining: 26m 40s\n",
      "205:\tlearn: 0.8766969\ttotal: 6m 53s\tremaining: 26m 35s\n",
      "206:\tlearn: 0.8755421\ttotal: 6m 55s\tremaining: 26m 31s\n",
      "207:\tlearn: 0.8743509\ttotal: 6m 56s\tremaining: 26m 26s\n",
      "208:\tlearn: 0.8734052\ttotal: 6m 57s\tremaining: 26m 21s\n",
      "209:\tlearn: 0.8722238\ttotal: 6m 59s\tremaining: 26m 16s\n",
      "210:\tlearn: 0.8712118\ttotal: 7m\tremaining: 26m 12s\n",
      "211:\tlearn: 0.8699838\ttotal: 7m 1s\tremaining: 26m 7s\n",
      "212:\tlearn: 0.8688404\ttotal: 7m 3s\tremaining: 26m 3s\n",
      "213:\tlearn: 0.8675236\ttotal: 7m 4s\tremaining: 25m 59s\n",
      "214:\tlearn: 0.8666365\ttotal: 7m 5s\tremaining: 25m 54s\n",
      "215:\tlearn: 0.8656106\ttotal: 7m 7s\tremaining: 25m 50s\n",
      "216:\tlearn: 0.8646602\ttotal: 7m 8s\tremaining: 25m 45s\n",
      "217:\tlearn: 0.8617020\ttotal: 7m 9s\tremaining: 25m 40s\n",
      "218:\tlearn: 0.8606612\ttotal: 7m 10s\tremaining: 25m 36s\n",
      "219:\tlearn: 0.8595208\ttotal: 7m 11s\tremaining: 25m 31s\n",
      "220:\tlearn: 0.8582580\ttotal: 7m 13s\tremaining: 25m 27s\n",
      "221:\tlearn: 0.8573863\ttotal: 7m 14s\tremaining: 25m 23s\n",
      "222:\tlearn: 0.8564005\ttotal: 7m 16s\tremaining: 25m 19s\n",
      "223:\tlearn: 0.8556479\ttotal: 7m 17s\tremaining: 25m 15s\n",
      "224:\tlearn: 0.8546378\ttotal: 7m 18s\tremaining: 25m 11s\n",
      "225:\tlearn: 0.8532325\ttotal: 7m 20s\tremaining: 25m 8s\n",
      "226:\tlearn: 0.8523296\ttotal: 7m 21s\tremaining: 25m 4s\n",
      "227:\tlearn: 0.8512758\ttotal: 7m 23s\tremaining: 25m 1s\n",
      "228:\tlearn: 0.8505742\ttotal: 7m 24s\tremaining: 24m 57s\n",
      "229:\tlearn: 0.8489677\ttotal: 7m 26s\tremaining: 24m 53s\n",
      "230:\tlearn: 0.8475416\ttotal: 7m 27s\tremaining: 24m 50s\n",
      "231:\tlearn: 0.8461178\ttotal: 7m 29s\tremaining: 24m 46s\n",
      "232:\tlearn: 0.8450336\ttotal: 7m 30s\tremaining: 24m 42s\n",
      "233:\tlearn: 0.8436642\ttotal: 7m 31s\tremaining: 24m 39s\n",
      "234:\tlearn: 0.8420645\ttotal: 7m 33s\tremaining: 24m 34s\n",
      "235:\tlearn: 0.8412662\ttotal: 7m 34s\tremaining: 24m 31s\n",
      "236:\tlearn: 0.8398600\ttotal: 7m 35s\tremaining: 24m 27s\n",
      "237:\tlearn: 0.8386890\ttotal: 7m 37s\tremaining: 24m 24s\n",
      "238:\tlearn: 0.8379775\ttotal: 7m 38s\tremaining: 24m 21s\n",
      "239:\tlearn: 0.8369381\ttotal: 7m 40s\tremaining: 24m 17s\n",
      "240:\tlearn: 0.8361497\ttotal: 7m 41s\tremaining: 24m 13s\n",
      "241:\tlearn: 0.8351971\ttotal: 7m 43s\tremaining: 24m 10s\n",
      "242:\tlearn: 0.8332945\ttotal: 7m 44s\tremaining: 24m 7s\n",
      "243:\tlearn: 0.8322754\ttotal: 7m 45s\tremaining: 24m 3s\n",
      "244:\tlearn: 0.8313574\ttotal: 7m 47s\tremaining: 23m 59s\n",
      "245:\tlearn: 0.8276488\ttotal: 7m 48s\tremaining: 23m 56s\n",
      "246:\tlearn: 0.8267044\ttotal: 7m 50s\tremaining: 23m 53s\n",
      "247:\tlearn: 0.8259313\ttotal: 7m 51s\tremaining: 23m 49s\n",
      "248:\tlearn: 0.8250573\ttotal: 7m 52s\tremaining: 23m 46s\n",
      "249:\tlearn: 0.8238824\ttotal: 7m 54s\tremaining: 23m 44s\n",
      "250:\tlearn: 0.8231337\ttotal: 7m 56s\tremaining: 23m 42s\n",
      "251:\tlearn: 0.8224538\ttotal: 7m 58s\tremaining: 23m 39s\n",
      "252:\tlearn: 0.8216509\ttotal: 7m 59s\tremaining: 23m 36s\n",
      "253:\tlearn: 0.8208962\ttotal: 8m 1s\tremaining: 23m 33s\n",
      "254:\tlearn: 0.8190737\ttotal: 8m 2s\tremaining: 23m 30s\n",
      "255:\tlearn: 0.8183476\ttotal: 8m 4s\tremaining: 23m 26s\n",
      "256:\tlearn: 0.8176222\ttotal: 8m 5s\tremaining: 23m 24s\n",
      "257:\tlearn: 0.8169240\ttotal: 8m 7s\tremaining: 23m 21s\n",
      "258:\tlearn: 0.8160732\ttotal: 8m 8s\tremaining: 23m 18s\n",
      "259:\tlearn: 0.8153969\ttotal: 8m 10s\tremaining: 23m 15s\n",
      "260:\tlearn: 0.8145548\ttotal: 8m 11s\tremaining: 23m 12s\n",
      "261:\tlearn: 0.8135270\ttotal: 8m 13s\tremaining: 23m 9s\n",
      "262:\tlearn: 0.8128906\ttotal: 8m 14s\tremaining: 23m 5s\n",
      "263:\tlearn: 0.8123190\ttotal: 8m 15s\tremaining: 23m 2s\n",
      "264:\tlearn: 0.8117081\ttotal: 8m 17s\tremaining: 22m 59s\n",
      "265:\tlearn: 0.8108430\ttotal: 8m 18s\tremaining: 22m 56s\n",
      "266:\tlearn: 0.8102934\ttotal: 8m 20s\tremaining: 22m 53s\n",
      "267:\tlearn: 0.8096398\ttotal: 8m 21s\tremaining: 22m 49s\n",
      "268:\tlearn: 0.8086295\ttotal: 8m 22s\tremaining: 22m 46s\n",
      "269:\tlearn: 0.8078353\ttotal: 8m 24s\tremaining: 22m 43s\n",
      "270:\tlearn: 0.8070963\ttotal: 8m 25s\tremaining: 22m 40s\n",
      "271:\tlearn: 0.8051912\ttotal: 8m 27s\tremaining: 22m 37s\n",
      "272:\tlearn: 0.8047111\ttotal: 8m 28s\tremaining: 22m 34s\n",
      "273:\tlearn: 0.8040727\ttotal: 8m 30s\tremaining: 22m 31s\n",
      "274:\tlearn: 0.8027509\ttotal: 8m 31s\tremaining: 22m 28s\n",
      "275:\tlearn: 0.8020610\ttotal: 8m 32s\tremaining: 22m 25s\n",
      "276:\tlearn: 0.8013332\ttotal: 8m 34s\tremaining: 22m 22s\n",
      "277:\tlearn: 0.8004309\ttotal: 8m 36s\tremaining: 22m 20s\n",
      "278:\tlearn: 0.7994340\ttotal: 8m 37s\tremaining: 22m 18s\n",
      "279:\tlearn: 0.7986827\ttotal: 8m 39s\tremaining: 22m 16s\n",
      "280:\tlearn: 0.7981755\ttotal: 8m 45s\tremaining: 22m 23s\n",
      "281:\tlearn: 0.7973982\ttotal: 8m 48s\tremaining: 22m 24s\n",
      "282:\tlearn: 0.7963040\ttotal: 8m 51s\tremaining: 22m 25s\n",
      "283:\tlearn: 0.7956794\ttotal: 8m 53s\tremaining: 22m 26s\n",
      "284:\tlearn: 0.7950619\ttotal: 8m 57s\tremaining: 22m 29s\n",
      "285:\tlearn: 0.7944612\ttotal: 9m\tremaining: 22m 29s\n",
      "286:\tlearn: 0.7937892\ttotal: 9m 3s\tremaining: 22m 30s\n",
      "287:\tlearn: 0.7928079\ttotal: 9m 6s\tremaining: 22m 31s\n",
      "288:\tlearn: 0.7919988\ttotal: 9m 12s\tremaining: 22m 38s\n",
      "289:\tlearn: 0.7912628\ttotal: 9m 16s\tremaining: 22m 42s\n",
      "290:\tlearn: 0.7905171\ttotal: 9m 21s\tremaining: 22m 47s\n",
      "291:\tlearn: 0.7898464\ttotal: 9m 27s\tremaining: 22m 56s\n",
      "292:\tlearn: 0.7890832\ttotal: 9m 31s\tremaining: 22m 59s\n",
      "293:\tlearn: 0.7882691\ttotal: 9m 35s\tremaining: 23m 2s\n",
      "294:\tlearn: 0.7876994\ttotal: 9m 41s\tremaining: 23m 9s\n",
      "295:\tlearn: 0.7868497\ttotal: 9m 51s\tremaining: 23m 25s\n",
      "296:\tlearn: 0.7857072\ttotal: 9m 58s\tremaining: 23m 35s\n",
      "297:\tlearn: 0.7850743\ttotal: 10m 1s\tremaining: 23m 36s\n",
      "298:\tlearn: 0.7845558\ttotal: 10m 4s\tremaining: 23m 36s\n",
      "299:\tlearn: 0.7830788\ttotal: 10m 9s\tremaining: 23m 42s\n",
      "300:\tlearn: 0.7821116\ttotal: 10m 21s\tremaining: 24m 2s\n",
      "301:\tlearn: 0.7815856\ttotal: 10m 26s\tremaining: 24m 7s\n",
      "302:\tlearn: 0.7805192\ttotal: 10m 34s\tremaining: 24m 20s\n",
      "303:\tlearn: 0.7799579\ttotal: 10m 41s\tremaining: 24m 28s\n",
      "304:\tlearn: 0.7790035\ttotal: 10m 49s\tremaining: 24m 39s\n",
      "305:\tlearn: 0.7783659\ttotal: 10m 54s\tremaining: 24m 43s\n",
      "306:\tlearn: 0.7776609\ttotal: 11m 1s\tremaining: 24m 53s\n",
      "307:\tlearn: 0.7770751\ttotal: 11m 4s\tremaining: 24m 54s\n",
      "308:\tlearn: 0.7764066\ttotal: 11m 8s\tremaining: 24m 55s\n",
      "309:\tlearn: 0.7757671\ttotal: 11m 14s\tremaining: 25m 1s\n",
      "310:\tlearn: 0.7752879\ttotal: 11m 21s\tremaining: 25m 9s\n",
      "311:\tlearn: 0.7746758\ttotal: 11m 27s\tremaining: 25m 14s\n",
      "312:\tlearn: 0.7740706\ttotal: 11m 36s\tremaining: 25m 29s\n",
      "313:\tlearn: 0.7733840\ttotal: 11m 43s\tremaining: 25m 36s\n",
      "314:\tlearn: 0.7726821\ttotal: 11m 48s\tremaining: 25m 40s\n",
      "315:\tlearn: 0.7721725\ttotal: 11m 53s\tremaining: 25m 44s\n",
      "316:\tlearn: 0.7716208\ttotal: 11m 57s\tremaining: 25m 46s\n",
      "317:\tlearn: 0.7709272\ttotal: 12m 3s\tremaining: 25m 51s\n",
      "318:\tlearn: 0.7704614\ttotal: 12m 7s\tremaining: 25m 52s\n",
      "319:\tlearn: 0.7697769\ttotal: 12m 12s\tremaining: 25m 57s\n",
      "320:\tlearn: 0.7690568\ttotal: 12m 16s\tremaining: 25m 57s\n",
      "321:\tlearn: 0.7674092\ttotal: 12m 21s\tremaining: 26m 1s\n",
      "322:\tlearn: 0.7668951\ttotal: 12m 28s\tremaining: 26m 7s\n",
      "323:\tlearn: 0.7663306\ttotal: 12m 32s\tremaining: 26m 9s\n",
      "324:\tlearn: 0.7654222\ttotal: 12m 36s\tremaining: 26m 10s\n",
      "325:\tlearn: 0.7645486\ttotal: 12m 43s\tremaining: 26m 19s\n",
      "326:\tlearn: 0.7641236\ttotal: 12m 49s\tremaining: 26m 23s\n",
      "327:\tlearn: 0.7635392\ttotal: 12m 54s\tremaining: 26m 26s\n",
      "328:\tlearn: 0.7629700\ttotal: 12m 59s\tremaining: 26m 30s\n",
      "329:\tlearn: 0.7624667\ttotal: 13m 3s\tremaining: 26m 29s\n",
      "330:\tlearn: 0.7619959\ttotal: 13m 6s\tremaining: 26m 30s\n",
      "331:\tlearn: 0.7613949\ttotal: 13m 10s\tremaining: 26m 31s\n",
      "332:\tlearn: 0.7609107\ttotal: 13m 14s\tremaining: 26m 30s\n",
      "333:\tlearn: 0.7604966\ttotal: 13m 19s\tremaining: 26m 33s\n",
      "334:\tlearn: 0.7597377\ttotal: 13m 24s\tremaining: 26m 36s\n",
      "335:\tlearn: 0.7591701\ttotal: 13m 27s\tremaining: 26m 35s\n",
      "336:\tlearn: 0.7585808\ttotal: 13m 35s\tremaining: 26m 43s\n",
      "337:\tlearn: 0.7580540\ttotal: 13m 40s\tremaining: 26m 46s\n",
      "338:\tlearn: 0.7575376\ttotal: 13m 45s\tremaining: 26m 49s\n",
      "339:\tlearn: 0.7561088\ttotal: 13m 49s\tremaining: 26m 51s\n",
      "340:\tlearn: 0.7557080\ttotal: 13m 54s\tremaining: 26m 52s\n",
      "341:\tlearn: 0.7553212\ttotal: 13m 57s\tremaining: 26m 52s\n",
      "342:\tlearn: 0.7546423\ttotal: 14m 4s\tremaining: 26m 57s\n",
      "343:\tlearn: 0.7539021\ttotal: 14m 9s\tremaining: 26m 59s\n",
      "344:\tlearn: 0.7534539\ttotal: 14m 15s\tremaining: 27m 3s\n",
      "345:\tlearn: 0.7530062\ttotal: 14m 20s\tremaining: 27m 5s\n",
      "346:\tlearn: 0.7523047\ttotal: 14m 27s\tremaining: 27m 13s\n",
      "347:\tlearn: 0.7516054\ttotal: 14m 35s\tremaining: 27m 20s\n",
      "348:\tlearn: 0.7509175\ttotal: 14m 40s\tremaining: 27m 21s\n",
      "349:\tlearn: 0.7502325\ttotal: 14m 44s\tremaining: 27m 23s\n",
      "350:\tlearn: 0.7499240\ttotal: 14m 54s\tremaining: 27m 34s\n",
      "351:\tlearn: 0.7494448\ttotal: 15m 5s\tremaining: 27m 47s\n",
      "352:\tlearn: 0.7486493\ttotal: 15m 9s\tremaining: 27m 47s\n",
      "353:\tlearn: 0.7480654\ttotal: 15m 15s\tremaining: 27m 51s\n",
      "354:\tlearn: 0.7476938\ttotal: 15m 17s\tremaining: 27m 47s\n",
      "355:\tlearn: 0.7472187\ttotal: 15m 19s\tremaining: 27m 42s\n",
      "356:\tlearn: 0.7466574\ttotal: 15m 20s\tremaining: 27m 38s\n",
      "357:\tlearn: 0.7460794\ttotal: 15m 22s\tremaining: 27m 33s\n",
      "358:\tlearn: 0.7455690\ttotal: 15m 23s\tremaining: 27m 29s\n",
      "359:\tlearn: 0.7450065\ttotal: 15m 25s\tremaining: 27m 24s\n",
      "360:\tlearn: 0.7445405\ttotal: 15m 26s\tremaining: 27m 20s\n",
      "361:\tlearn: 0.7435332\ttotal: 15m 27s\tremaining: 27m 15s\n",
      "362:\tlearn: 0.7431115\ttotal: 15m 29s\tremaining: 27m 11s\n",
      "363:\tlearn: 0.7427568\ttotal: 15m 30s\tremaining: 27m 6s\n",
      "364:\tlearn: 0.7423657\ttotal: 15m 32s\tremaining: 27m 1s\n",
      "365:\tlearn: 0.7414907\ttotal: 15m 33s\tremaining: 26m 56s\n",
      "366:\tlearn: 0.7410724\ttotal: 15m 34s\tremaining: 26m 52s\n",
      "367:\tlearn: 0.7400899\ttotal: 15m 36s\tremaining: 26m 48s\n",
      "368:\tlearn: 0.7396662\ttotal: 15m 38s\tremaining: 26m 44s\n",
      "369:\tlearn: 0.7384644\ttotal: 15m 39s\tremaining: 26m 39s\n",
      "370:\tlearn: 0.7381575\ttotal: 15m 41s\tremaining: 26m 35s\n",
      "371:\tlearn: 0.7376141\ttotal: 15m 42s\tremaining: 26m 31s\n",
      "372:\tlearn: 0.7369750\ttotal: 15m 46s\tremaining: 26m 31s\n",
      "373:\tlearn: 0.7364640\ttotal: 15m 52s\tremaining: 26m 33s\n",
      "374:\tlearn: 0.7357761\ttotal: 15m 59s\tremaining: 26m 38s\n",
      "375:\tlearn: 0.7353172\ttotal: 16m 4s\tremaining: 26m 40s\n",
      "376:\tlearn: 0.7346253\ttotal: 16m 9s\tremaining: 26m 41s\n",
      "377:\tlearn: 0.7341970\ttotal: 16m 14s\tremaining: 26m 43s\n",
      "378:\tlearn: 0.7337118\ttotal: 16m 19s\tremaining: 26m 44s\n",
      "379:\tlearn: 0.7330280\ttotal: 16m 25s\tremaining: 26m 48s\n",
      "380:\tlearn: 0.7324310\ttotal: 16m 31s\tremaining: 26m 50s\n",
      "381:\tlearn: 0.7319400\ttotal: 16m 37s\tremaining: 26m 53s\n",
      "382:\tlearn: 0.7316342\ttotal: 16m 44s\tremaining: 26m 57s\n",
      "383:\tlearn: 0.7311906\ttotal: 16m 50s\tremaining: 27m\n",
      "384:\tlearn: 0.7308392\ttotal: 16m 56s\tremaining: 27m 4s\n",
      "385:\tlearn: 0.7301734\ttotal: 17m 3s\tremaining: 27m 7s\n",
      "386:\tlearn: 0.7297890\ttotal: 17m 9s\tremaining: 27m 10s\n",
      "387:\tlearn: 0.7293536\ttotal: 17m 18s\tremaining: 27m 17s\n",
      "388:\tlearn: 0.7289426\ttotal: 17m 25s\tremaining: 27m 21s\n",
      "389:\tlearn: 0.7282747\ttotal: 17m 31s\tremaining: 27m 25s\n",
      "390:\tlearn: 0.7278309\ttotal: 17m 37s\tremaining: 27m 27s\n",
      "391:\tlearn: 0.7275297\ttotal: 17m 47s\tremaining: 27m 36s\n",
      "392:\tlearn: 0.7269362\ttotal: 17m 56s\tremaining: 27m 42s\n",
      "393:\tlearn: 0.7265119\ttotal: 18m\tremaining: 27m 41s\n",
      "394:\tlearn: 0.7261683\ttotal: 18m 1s\tremaining: 27m 36s\n",
      "395:\tlearn: 0.7258426\ttotal: 18m 2s\tremaining: 27m 31s\n",
      "396:\tlearn: 0.7254764\ttotal: 18m 4s\tremaining: 27m 26s\n",
      "397:\tlearn: 0.7242203\ttotal: 18m 5s\tremaining: 27m 21s\n",
      "398:\tlearn: 0.7230767\ttotal: 18m 6s\tremaining: 27m 17s\n",
      "399:\tlearn: 0.7224546\ttotal: 18m 8s\tremaining: 27m 12s\n",
      "400:\tlearn: 0.7219810\ttotal: 18m 9s\tremaining: 27m 7s\n",
      "401:\tlearn: 0.7210922\ttotal: 18m 11s\tremaining: 27m 2s\n",
      "402:\tlearn: 0.7191943\ttotal: 18m 12s\tremaining: 26m 58s\n",
      "403:\tlearn: 0.7184966\ttotal: 18m 13s\tremaining: 26m 53s\n",
      "404:\tlearn: 0.7181154\ttotal: 18m 15s\tremaining: 26m 48s\n",
      "405:\tlearn: 0.7176964\ttotal: 18m 16s\tremaining: 26m 44s\n",
      "406:\tlearn: 0.7172403\ttotal: 18m 17s\tremaining: 26m 39s\n",
      "407:\tlearn: 0.7169570\ttotal: 18m 19s\tremaining: 26m 35s\n",
      "408:\tlearn: 0.7162930\ttotal: 18m 21s\tremaining: 26m 32s\n",
      "409:\tlearn: 0.7159737\ttotal: 18m 25s\tremaining: 26m 31s\n",
      "410:\tlearn: 0.7155572\ttotal: 18m 30s\tremaining: 26m 31s\n",
      "411:\tlearn: 0.7149455\ttotal: 18m 33s\tremaining: 26m 29s\n",
      "412:\tlearn: 0.7145628\ttotal: 18m 36s\tremaining: 26m 26s\n",
      "413:\tlearn: 0.7142387\ttotal: 18m 42s\tremaining: 26m 28s\n",
      "414:\tlearn: 0.7138841\ttotal: 18m 44s\tremaining: 26m 25s\n",
      "415:\tlearn: 0.7134482\ttotal: 18m 47s\tremaining: 26m 22s\n",
      "416:\tlearn: 0.7130978\ttotal: 18m 52s\tremaining: 26m 23s\n",
      "417:\tlearn: 0.7126564\ttotal: 18m 55s\tremaining: 26m 20s\n",
      "418:\tlearn: 0.7123027\ttotal: 18m 58s\tremaining: 26m 18s\n",
      "419:\tlearn: 0.7117956\ttotal: 19m 7s\tremaining: 26m 24s\n",
      "420:\tlearn: 0.7113557\ttotal: 19m 16s\tremaining: 26m 30s\n",
      "421:\tlearn: 0.7110096\ttotal: 19m 19s\tremaining: 26m 28s\n",
      "422:\tlearn: 0.7106481\ttotal: 19m 27s\tremaining: 26m 32s\n",
      "423:\tlearn: 0.7101835\ttotal: 19m 31s\tremaining: 26m 31s\n",
      "424:\tlearn: 0.7098186\ttotal: 19m 36s\tremaining: 26m 31s\n",
      "425:\tlearn: 0.7093728\ttotal: 19m 41s\tremaining: 26m 32s\n",
      "426:\tlearn: 0.7088922\ttotal: 19m 46s\tremaining: 26m 32s\n",
      "427:\tlearn: 0.7084094\ttotal: 19m 51s\tremaining: 26m 32s\n",
      "428:\tlearn: 0.7079337\ttotal: 19m 57s\tremaining: 26m 34s\n",
      "429:\tlearn: 0.7076031\ttotal: 20m 1s\tremaining: 26m 32s\n",
      "430:\tlearn: 0.7070194\ttotal: 20m 6s\tremaining: 26m 32s\n",
      "431:\tlearn: 0.7063451\ttotal: 20m 10s\tremaining: 26m 31s\n",
      "432:\tlearn: 0.7059545\ttotal: 20m 16s\tremaining: 26m 32s\n",
      "433:\tlearn: 0.7055373\ttotal: 20m 19s\tremaining: 26m 30s\n",
      "434:\tlearn: 0.7050521\ttotal: 20m 22s\tremaining: 26m 28s\n",
      "435:\tlearn: 0.7043105\ttotal: 20m 27s\tremaining: 26m 27s\n",
      "436:\tlearn: 0.7036562\ttotal: 20m 32s\tremaining: 26m 27s\n",
      "437:\tlearn: 0.7034452\ttotal: 20m 37s\tremaining: 26m 27s\n",
      "438:\tlearn: 0.7030329\ttotal: 20m 40s\tremaining: 26m 24s\n",
      "439:\tlearn: 0.7026395\ttotal: 20m 46s\tremaining: 26m 25s\n",
      "440:\tlearn: 0.7020291\ttotal: 20m 51s\tremaining: 26m 26s\n",
      "441:\tlearn: 0.7017581\ttotal: 20m 57s\tremaining: 26m 27s\n",
      "442:\tlearn: 0.7015423\ttotal: 21m 2s\tremaining: 26m 27s\n",
      "443:\tlearn: 0.7004828\ttotal: 21m 9s\tremaining: 26m 29s\n",
      "444:\tlearn: 0.6999255\ttotal: 21m 15s\tremaining: 26m 31s\n",
      "445:\tlearn: 0.6995117\ttotal: 21m 21s\tremaining: 26m 31s\n",
      "446:\tlearn: 0.6992172\ttotal: 21m 24s\tremaining: 26m 28s\n",
      "447:\tlearn: 0.6987866\ttotal: 21m 29s\tremaining: 26m 28s\n",
      "448:\tlearn: 0.6981332\ttotal: 21m 35s\tremaining: 26m 30s\n",
      "449:\tlearn: 0.6976924\ttotal: 21m 40s\tremaining: 26m 28s\n",
      "450:\tlearn: 0.6973268\ttotal: 21m 43s\tremaining: 26m 26s\n",
      "451:\tlearn: 0.6970355\ttotal: 21m 50s\tremaining: 26m 28s\n",
      "452:\tlearn: 0.6967718\ttotal: 21m 54s\tremaining: 26m 27s\n",
      "453:\tlearn: 0.6965972\ttotal: 22m\tremaining: 26m 27s\n",
      "454:\tlearn: 0.6963708\ttotal: 22m 3s\tremaining: 26m 24s\n",
      "455:\tlearn: 0.6960118\ttotal: 22m 5s\tremaining: 26m 21s\n",
      "456:\tlearn: 0.6956228\ttotal: 22m 8s\tremaining: 26m 18s\n",
      "457:\tlearn: 0.6954022\ttotal: 22m 11s\tremaining: 26m 15s\n",
      "458:\tlearn: 0.6949324\ttotal: 22m 14s\tremaining: 26m 13s\n",
      "459:\tlearn: 0.6946017\ttotal: 22m 18s\tremaining: 26m 11s\n",
      "460:\tlearn: 0.6943663\ttotal: 22m 23s\tremaining: 26m 11s\n",
      "461:\tlearn: 0.6939597\ttotal: 22m 27s\tremaining: 26m 9s\n",
      "462:\tlearn: 0.6924258\ttotal: 22m 36s\tremaining: 26m 13s\n",
      "463:\tlearn: 0.6920735\ttotal: 22m 39s\tremaining: 26m 11s\n",
      "464:\tlearn: 0.6917719\ttotal: 22m 43s\tremaining: 26m 8s\n",
      "465:\tlearn: 0.6914921\ttotal: 22m 46s\tremaining: 26m 6s\n",
      "466:\tlearn: 0.6912307\ttotal: 22m 52s\tremaining: 26m 6s\n",
      "467:\tlearn: 0.6907000\ttotal: 22m 55s\tremaining: 26m 3s\n",
      "468:\tlearn: 0.6903162\ttotal: 22m 58s\tremaining: 26m\n",
      "469:\tlearn: 0.6899825\ttotal: 23m 1s\tremaining: 25m 57s\n",
      "470:\tlearn: 0.6897636\ttotal: 23m 4s\tremaining: 25m 55s\n",
      "471:\tlearn: 0.6894167\ttotal: 23m 14s\tremaining: 25m 59s\n",
      "472:\tlearn: 0.6890967\ttotal: 23m 18s\tremaining: 25m 57s\n",
      "473:\tlearn: 0.6887998\ttotal: 23m 21s\tremaining: 25m 54s\n",
      "474:\tlearn: 0.6882544\ttotal: 23m 24s\tremaining: 25m 52s\n",
      "475:\tlearn: 0.6879300\ttotal: 23m 27s\tremaining: 25m 49s\n",
      "476:\tlearn: 0.6876894\ttotal: 23m 31s\tremaining: 25m 47s\n",
      "477:\tlearn: 0.6874476\ttotal: 23m 36s\tremaining: 25m 46s\n",
      "478:\tlearn: 0.6870162\ttotal: 23m 39s\tremaining: 25m 44s\n",
      "479:\tlearn: 0.6867462\ttotal: 23m 43s\tremaining: 25m 41s\n",
      "480:\tlearn: 0.6864247\ttotal: 23m 47s\tremaining: 25m 40s\n",
      "481:\tlearn: 0.6861472\ttotal: 23m 50s\tremaining: 25m 37s\n",
      "482:\tlearn: 0.6857408\ttotal: 23m 53s\tremaining: 25m 34s\n",
      "483:\tlearn: 0.6854937\ttotal: 23m 55s\tremaining: 25m 30s\n",
      "484:\tlearn: 0.6852777\ttotal: 23m 58s\tremaining: 25m 27s\n",
      "485:\tlearn: 0.6850557\ttotal: 24m 1s\tremaining: 25m 24s\n",
      "486:\tlearn: 0.6847617\ttotal: 24m 6s\tremaining: 25m 24s\n",
      "487:\tlearn: 0.6844677\ttotal: 24m 11s\tremaining: 25m 23s\n",
      "488:\tlearn: 0.6841850\ttotal: 24m 17s\tremaining: 25m 22s\n",
      "489:\tlearn: 0.6839085\ttotal: 24m 23s\tremaining: 25m 22s\n",
      "490:\tlearn: 0.6836573\ttotal: 24m 28s\tremaining: 25m 22s\n",
      "491:\tlearn: 0.6833924\ttotal: 24m 34s\tremaining: 25m 22s\n",
      "492:\tlearn: 0.6830408\ttotal: 24m 41s\tremaining: 25m 23s\n",
      "493:\tlearn: 0.6828166\ttotal: 24m 47s\tremaining: 25m 23s\n",
      "494:\tlearn: 0.6825268\ttotal: 24m 52s\tremaining: 25m 22s\n",
      "495:\tlearn: 0.6819940\ttotal: 24m 57s\tremaining: 25m 22s\n",
      "496:\tlearn: 0.6816875\ttotal: 25m 4s\tremaining: 25m 22s\n",
      "497:\tlearn: 0.6813927\ttotal: 25m 10s\tremaining: 25m 22s\n",
      "498:\tlearn: 0.6795146\ttotal: 25m 18s\tremaining: 25m 24s\n",
      "499:\tlearn: 0.6791143\ttotal: 25m 31s\tremaining: 25m 31s\n",
      "500:\tlearn: 0.6789195\ttotal: 25m 40s\tremaining: 25m 34s\n",
      "501:\tlearn: 0.6786873\ttotal: 25m 49s\tremaining: 25m 37s\n",
      "502:\tlearn: 0.6783651\ttotal: 25m 54s\tremaining: 25m 36s\n",
      "503:\tlearn: 0.6775579\ttotal: 26m 2s\tremaining: 25m 37s\n",
      "504:\tlearn: 0.6770232\ttotal: 26m 7s\tremaining: 25m 36s\n",
      "505:\tlearn: 0.6765086\ttotal: 26m 16s\tremaining: 25m 38s\n",
      "506:\tlearn: 0.6763009\ttotal: 26m 25s\tremaining: 25m 41s\n",
      "507:\tlearn: 0.6760810\ttotal: 26m 34s\tremaining: 25m 44s\n",
      "508:\tlearn: 0.6756820\ttotal: 26m 44s\tremaining: 25m 48s\n",
      "509:\tlearn: 0.6754370\ttotal: 26m 52s\tremaining: 25m 49s\n",
      "510:\tlearn: 0.6752053\ttotal: 27m\tremaining: 25m 51s\n",
      "511:\tlearn: 0.6749575\ttotal: 27m 6s\tremaining: 25m 50s\n",
      "512:\tlearn: 0.6746428\ttotal: 27m 10s\tremaining: 25m 47s\n",
      "513:\tlearn: 0.6741132\ttotal: 27m 14s\tremaining: 25m 45s\n",
      "514:\tlearn: 0.6737728\ttotal: 27m 18s\tremaining: 25m 42s\n",
      "515:\tlearn: 0.6733375\ttotal: 27m 19s\tremaining: 25m 37s\n",
      "516:\tlearn: 0.6730372\ttotal: 27m 20s\tremaining: 25m 32s\n",
      "517:\tlearn: 0.6726379\ttotal: 27m 21s\tremaining: 25m 27s\n",
      "518:\tlearn: 0.6722715\ttotal: 27m 23s\tremaining: 25m 22s\n",
      "519:\tlearn: 0.6721327\ttotal: 27m 24s\tremaining: 25m 17s\n",
      "520:\tlearn: 0.6718820\ttotal: 27m 25s\tremaining: 25m 12s\n",
      "521:\tlearn: 0.6715924\ttotal: 27m 26s\tremaining: 25m 7s\n",
      "522:\tlearn: 0.6713883\ttotal: 27m 28s\tremaining: 25m 3s\n",
      "523:\tlearn: 0.6708984\ttotal: 27m 29s\tremaining: 24m 58s\n",
      "524:\tlearn: 0.6690301\ttotal: 27m 30s\tremaining: 24m 53s\n",
      "525:\tlearn: 0.6687938\ttotal: 27m 31s\tremaining: 24m 48s\n",
      "526:\tlearn: 0.6684382\ttotal: 27m 33s\tremaining: 24m 43s\n",
      "527:\tlearn: 0.6681366\ttotal: 27m 34s\tremaining: 24m 39s\n",
      "528:\tlearn: 0.6677733\ttotal: 27m 36s\tremaining: 24m 34s\n",
      "529:\tlearn: 0.6673018\ttotal: 27m 38s\tremaining: 24m 30s\n",
      "530:\tlearn: 0.6668899\ttotal: 27m 41s\tremaining: 24m 27s\n",
      "531:\tlearn: 0.6666116\ttotal: 27m 46s\tremaining: 24m 25s\n",
      "532:\tlearn: 0.6663601\ttotal: 27m 53s\tremaining: 24m 26s\n",
      "533:\tlearn: 0.6661723\ttotal: 28m 1s\tremaining: 24m 27s\n",
      "534:\tlearn: 0.6657871\ttotal: 28m 4s\tremaining: 24m 24s\n",
      "535:\tlearn: 0.6653796\ttotal: 28m 7s\tremaining: 24m 21s\n",
      "536:\tlearn: 0.6648416\ttotal: 28m 11s\tremaining: 24m 18s\n",
      "537:\tlearn: 0.6644874\ttotal: 28m 15s\tremaining: 24m 16s\n",
      "538:\tlearn: 0.6642200\ttotal: 28m 19s\tremaining: 24m 13s\n",
      "539:\tlearn: 0.6639928\ttotal: 28m 22s\tremaining: 24m 9s\n",
      "540:\tlearn: 0.6637651\ttotal: 28m 25s\tremaining: 24m 6s\n",
      "541:\tlearn: 0.6631402\ttotal: 28m 31s\tremaining: 24m 5s\n",
      "542:\tlearn: 0.6628280\ttotal: 28m 35s\tremaining: 24m 3s\n",
      "543:\tlearn: 0.6623807\ttotal: 28m 40s\tremaining: 24m 1s\n",
      "544:\tlearn: 0.6621672\ttotal: 28m 43s\tremaining: 23m 58s\n",
      "545:\tlearn: 0.6619060\ttotal: 28m 49s\tremaining: 23m 58s\n",
      "546:\tlearn: 0.6616851\ttotal: 28m 53s\tremaining: 23m 55s\n",
      "547:\tlearn: 0.6614028\ttotal: 28m 59s\tremaining: 23m 55s\n",
      "548:\tlearn: 0.6612333\ttotal: 29m 3s\tremaining: 23m 52s\n",
      "549:\tlearn: 0.6610028\ttotal: 29m 6s\tremaining: 23m 48s\n",
      "550:\tlearn: 0.6607571\ttotal: 29m 8s\tremaining: 23m 44s\n",
      "551:\tlearn: 0.6605590\ttotal: 29m 9s\tremaining: 23m 40s\n",
      "552:\tlearn: 0.6603455\ttotal: 29m 12s\tremaining: 23m 36s\n",
      "553:\tlearn: 0.6601443\ttotal: 29m 18s\tremaining: 23m 35s\n",
      "554:\tlearn: 0.6598630\ttotal: 29m 23s\tremaining: 23m 34s\n",
      "555:\tlearn: 0.6596497\ttotal: 29m 30s\tremaining: 23m 34s\n",
      "556:\tlearn: 0.6594380\ttotal: 29m 37s\tremaining: 23m 33s\n",
      "557:\tlearn: 0.6592244\ttotal: 29m 46s\tremaining: 23m 34s\n",
      "558:\tlearn: 0.6589687\ttotal: 29m 54s\tremaining: 23m 35s\n",
      "559:\tlearn: 0.6587335\ttotal: 30m 3s\tremaining: 23m 37s\n",
      "560:\tlearn: 0.6580109\ttotal: 30m 13s\tremaining: 23m 38s\n",
      "561:\tlearn: 0.6578046\ttotal: 30m 21s\tremaining: 23m 39s\n",
      "562:\tlearn: 0.6575490\ttotal: 30m 29s\tremaining: 23m 40s\n",
      "563:\tlearn: 0.6571781\ttotal: 30m 39s\tremaining: 23m 41s\n",
      "564:\tlearn: 0.6569344\ttotal: 30m 49s\tremaining: 23m 43s\n",
      "565:\tlearn: 0.6567403\ttotal: 30m 58s\tremaining: 23m 45s\n",
      "566:\tlearn: 0.6565304\ttotal: 31m 8s\tremaining: 23m 46s\n",
      "567:\tlearn: 0.6563497\ttotal: 31m 18s\tremaining: 23m 48s\n",
      "568:\tlearn: 0.6559702\ttotal: 31m 28s\tremaining: 23m 50s\n",
      "569:\tlearn: 0.6553326\ttotal: 31m 38s\tremaining: 23m 52s\n",
      "570:\tlearn: 0.6551455\ttotal: 31m 45s\tremaining: 23m 51s\n",
      "571:\tlearn: 0.6548857\ttotal: 31m 53s\tremaining: 23m 51s\n",
      "572:\tlearn: 0.6546773\ttotal: 32m\tremaining: 23m 51s\n",
      "573:\tlearn: 0.6543935\ttotal: 32m 7s\tremaining: 23m 50s\n",
      "574:\tlearn: 0.6541187\ttotal: 32m 13s\tremaining: 23m 49s\n",
      "575:\tlearn: 0.6538217\ttotal: 32m 20s\tremaining: 23m 48s\n",
      "576:\tlearn: 0.6535823\ttotal: 32m 27s\tremaining: 23m 47s\n",
      "577:\tlearn: 0.6533734\ttotal: 32m 33s\tremaining: 23m 45s\n",
      "578:\tlearn: 0.6531540\ttotal: 32m 40s\tremaining: 23m 45s\n",
      "579:\tlearn: 0.6529566\ttotal: 32m 48s\tremaining: 23m 45s\n",
      "580:\tlearn: 0.6527256\ttotal: 32m 55s\tremaining: 23m 44s\n",
      "581:\tlearn: 0.6524454\ttotal: 33m 2s\tremaining: 23m 44s\n",
      "582:\tlearn: 0.6520770\ttotal: 33m 10s\tremaining: 23m 43s\n",
      "583:\tlearn: 0.6518492\ttotal: 33m 18s\tremaining: 23m 43s\n",
      "584:\tlearn: 0.6515679\ttotal: 33m 26s\tremaining: 23m 43s\n",
      "585:\tlearn: 0.6514764\ttotal: 33m 36s\tremaining: 23m 44s\n",
      "586:\tlearn: 0.6512037\ttotal: 33m 45s\tremaining: 23m 45s\n",
      "587:\tlearn: 0.6508858\ttotal: 33m 54s\tremaining: 23m 45s\n",
      "588:\tlearn: 0.6506232\ttotal: 34m 3s\tremaining: 23m 45s\n",
      "589:\tlearn: 0.6503326\ttotal: 34m 10s\tremaining: 23m 44s\n",
      "590:\tlearn: 0.6499138\ttotal: 34m 18s\tremaining: 23m 44s\n",
      "591:\tlearn: 0.6496423\ttotal: 34m 26s\tremaining: 23m 43s\n",
      "592:\tlearn: 0.6491377\ttotal: 34m 35s\tremaining: 23m 44s\n",
      "593:\tlearn: 0.6489063\ttotal: 34m 44s\tremaining: 23m 44s\n",
      "594:\tlearn: 0.6486492\ttotal: 34m 53s\tremaining: 23m 44s\n",
      "595:\tlearn: 0.6483827\ttotal: 35m 2s\tremaining: 23m 45s\n",
      "596:\tlearn: 0.6480410\ttotal: 35m 11s\tremaining: 23m 45s\n",
      "597:\tlearn: 0.6477604\ttotal: 35m 21s\tremaining: 23m 45s\n",
      "598:\tlearn: 0.6474608\ttotal: 35m 29s\tremaining: 23m 45s\n",
      "599:\tlearn: 0.6470677\ttotal: 35m 37s\tremaining: 23m 45s\n",
      "600:\tlearn: 0.6469012\ttotal: 35m 43s\tremaining: 23m 42s\n",
      "601:\tlearn: 0.6466884\ttotal: 35m 49s\tremaining: 23m 40s\n",
      "602:\tlearn: 0.6463867\ttotal: 35m 55s\tremaining: 23m 38s\n",
      "603:\tlearn: 0.6461535\ttotal: 36m 1s\tremaining: 23m 37s\n",
      "604:\tlearn: 0.6455201\ttotal: 36m 8s\tremaining: 23m 35s\n",
      "605:\tlearn: 0.6453785\ttotal: 36m 15s\tremaining: 23m 34s\n",
      "606:\tlearn: 0.6451707\ttotal: 36m 21s\tremaining: 23m 32s\n",
      "607:\tlearn: 0.6449721\ttotal: 36m 28s\tremaining: 23m 31s\n",
      "608:\tlearn: 0.6447665\ttotal: 36m 35s\tremaining: 23m 29s\n",
      "609:\tlearn: 0.6444246\ttotal: 36m 43s\tremaining: 23m 28s\n",
      "610:\tlearn: 0.6441540\ttotal: 36m 52s\tremaining: 23m 28s\n",
      "611:\tlearn: 0.6439450\ttotal: 36m 58s\tremaining: 23m 26s\n",
      "612:\tlearn: 0.6437645\ttotal: 37m 6s\tremaining: 23m 25s\n",
      "613:\tlearn: 0.6430859\ttotal: 37m 13s\tremaining: 23m 24s\n",
      "614:\tlearn: 0.6429759\ttotal: 37m 21s\tremaining: 23m 22s\n",
      "615:\tlearn: 0.6428522\ttotal: 37m 29s\tremaining: 23m 22s\n",
      "616:\tlearn: 0.6427887\ttotal: 37m 38s\tremaining: 23m 21s\n",
      "617:\tlearn: 0.6425624\ttotal: 37m 47s\tremaining: 23m 21s\n",
      "618:\tlearn: 0.6423657\ttotal: 37m 56s\tremaining: 23m 20s\n",
      "619:\tlearn: 0.6417371\ttotal: 38m 4s\tremaining: 23m 20s\n",
      "620:\tlearn: 0.6415753\ttotal: 38m 11s\tremaining: 23m 18s\n",
      "621:\tlearn: 0.6413218\ttotal: 38m 20s\tremaining: 23m 17s\n",
      "622:\tlearn: 0.6410132\ttotal: 38m 29s\tremaining: 23m 17s\n",
      "623:\tlearn: 0.6407989\ttotal: 38m 40s\tremaining: 23m 18s\n",
      "624:\tlearn: 0.6406560\ttotal: 38m 50s\tremaining: 23m 18s\n",
      "625:\tlearn: 0.6404743\ttotal: 39m\tremaining: 23m 18s\n",
      "626:\tlearn: 0.6401444\ttotal: 39m 9s\tremaining: 23m 17s\n",
      "627:\tlearn: 0.6399788\ttotal: 39m 15s\tremaining: 23m 15s\n",
      "628:\tlearn: 0.6396645\ttotal: 39m 22s\tremaining: 23m 13s\n",
      "629:\tlearn: 0.6395607\ttotal: 39m 22s\tremaining: 23m 13s\n",
      "630:\tlearn: 0.6393585\ttotal: 39m 26s\tremaining: 23m 6s\n",
      "631:\tlearn: 0.6391581\ttotal: 39m 29s\tremaining: 23m 1s\n",
      "632:\tlearn: 0.6389963\ttotal: 39m 33s\tremaining: 22m 58s\n",
      "633:\tlearn: 0.6387200\ttotal: 39m 36s\tremaining: 22m 53s\n",
      "634:\tlearn: 0.6384282\ttotal: 39m 40s\tremaining: 22m 50s\n",
      "635:\tlearn: 0.6381445\ttotal: 39m 48s\tremaining: 22m 48s\n",
      "636:\tlearn: 0.6378456\ttotal: 39m 50s\tremaining: 22m 44s\n",
      "637:\tlearn: 0.6376775\ttotal: 39m 52s\tremaining: 22m 39s\n",
      "638:\tlearn: 0.6374713\ttotal: 39m 54s\tremaining: 22m 34s\n",
      "639:\tlearn: 0.6373148\ttotal: 39m 55s\tremaining: 22m 29s\n",
      "640:\tlearn: 0.6366602\ttotal: 39m 58s\tremaining: 22m 25s\n",
      "641:\tlearn: 0.6364346\ttotal: 40m 1s\tremaining: 22m 21s\n",
      "642:\tlearn: 0.6362076\ttotal: 40m 7s\tremaining: 22m 18s\n",
      "643:\tlearn: 0.6360160\ttotal: 40m 12s\tremaining: 22m 15s\n",
      "644:\tlearn: 0.6357997\ttotal: 40m 19s\tremaining: 22m 13s\n",
      "645:\tlearn: 0.6356603\ttotal: 40m 22s\tremaining: 22m 9s\n",
      "646:\tlearn: 0.6355188\ttotal: 40m 25s\tremaining: 22m 5s\n",
      "647:\tlearn: 0.6352703\ttotal: 40m 28s\tremaining: 22m 1s\n",
      "648:\tlearn: 0.6351271\ttotal: 40m 32s\tremaining: 21m 57s\n",
      "649:\tlearn: 0.6349171\ttotal: 40m 38s\tremaining: 21m 54s\n",
      "650:\tlearn: 0.6345958\ttotal: 40m 43s\tremaining: 21m 51s\n",
      "651:\tlearn: 0.6343606\ttotal: 40m 46s\tremaining: 21m 47s\n",
      "652:\tlearn: 0.6342009\ttotal: 40m 49s\tremaining: 21m 43s\n",
      "653:\tlearn: 0.6340015\ttotal: 40m 53s\tremaining: 21m 40s\n",
      "654:\tlearn: 0.6337636\ttotal: 41m 1s\tremaining: 21m 38s\n",
      "655:\tlearn: 0.6335123\ttotal: 41m 4s\tremaining: 21m 34s\n",
      "656:\tlearn: 0.6333460\ttotal: 41m 8s\tremaining: 21m 30s\n",
      "657:\tlearn: 0.6331071\ttotal: 41m 12s\tremaining: 21m 27s\n",
      "658:\tlearn: 0.6327010\ttotal: 41m 18s\tremaining: 21m 24s\n",
      "659:\tlearn: 0.6325096\ttotal: 41m 22s\tremaining: 21m 21s\n",
      "660:\tlearn: 0.6322904\ttotal: 41m 28s\tremaining: 21m 18s\n",
      "661:\tlearn: 0.6321239\ttotal: 41m 32s\tremaining: 21m 14s\n",
      "662:\tlearn: 0.6318389\ttotal: 41m 37s\tremaining: 21m 11s\n",
      "663:\tlearn: 0.6316467\ttotal: 41m 43s\tremaining: 21m 8s\n",
      "664:\tlearn: 0.6312769\ttotal: 41m 47s\tremaining: 21m 5s\n",
      "665:\tlearn: 0.6310031\ttotal: 41m 51s\tremaining: 21m 1s\n",
      "666:\tlearn: 0.6308254\ttotal: 41m 57s\tremaining: 20m 58s\n",
      "667:\tlearn: 0.6306521\ttotal: 42m\tremaining: 20m 54s\n",
      "668:\tlearn: 0.6304038\ttotal: 42m 2s\tremaining: 20m 50s\n",
      "669:\tlearn: 0.6301588\ttotal: 42m 6s\tremaining: 20m 46s\n",
      "670:\tlearn: 0.6299679\ttotal: 42m 9s\tremaining: 20m 41s\n",
      "671:\tlearn: 0.6297473\ttotal: 42m 11s\tremaining: 20m 37s\n",
      "672:\tlearn: 0.6295341\ttotal: 42m 15s\tremaining: 20m 34s\n",
      "673:\tlearn: 0.6293875\ttotal: 42m 20s\tremaining: 20m 30s\n",
      "674:\tlearn: 0.6290434\ttotal: 42m 28s\tremaining: 20m 28s\n",
      "675:\tlearn: 0.6286919\ttotal: 42m 35s\tremaining: 20m 26s\n",
      "676:\tlearn: 0.6285555\ttotal: 42m 37s\tremaining: 20m 21s\n",
      "677:\tlearn: 0.6283595\ttotal: 42m 38s\tremaining: 20m 16s\n",
      "678:\tlearn: 0.6282459\ttotal: 42m 39s\tremaining: 20m 11s\n",
      "679:\tlearn: 0.6280082\ttotal: 42m 40s\tremaining: 20m 6s\n",
      "680:\tlearn: 0.6277899\ttotal: 42m 41s\tremaining: 20m 1s\n",
      "681:\tlearn: 0.6275955\ttotal: 42m 42s\tremaining: 19m 56s\n",
      "682:\tlearn: 0.6274476\ttotal: 42m 43s\tremaining: 19m 51s\n",
      "683:\tlearn: 0.6271530\ttotal: 42m 44s\tremaining: 19m 46s\n",
      "684:\tlearn: 0.6265163\ttotal: 42m 46s\tremaining: 19m 41s\n",
      "685:\tlearn: 0.6263843\ttotal: 42m 47s\tremaining: 19m 36s\n",
      "686:\tlearn: 0.6262371\ttotal: 42m 48s\tremaining: 19m 31s\n",
      "687:\tlearn: 0.6260288\ttotal: 42m 49s\tremaining: 19m 27s\n",
      "688:\tlearn: 0.6257890\ttotal: 42m 51s\tremaining: 19m 22s\n",
      "689:\tlearn: 0.6256238\ttotal: 42m 52s\tremaining: 19m 17s\n",
      "690:\tlearn: 0.6254983\ttotal: 42m 54s\tremaining: 19m 12s\n",
      "691:\tlearn: 0.6252998\ttotal: 42m 55s\tremaining: 19m 7s\n",
      "692:\tlearn: 0.6251174\ttotal: 42m 56s\tremaining: 19m 3s\n",
      "693:\tlearn: 0.6250020\ttotal: 42m 58s\tremaining: 18m 58s\n",
      "694:\tlearn: 0.6247299\ttotal: 42m 59s\tremaining: 18m 53s\n",
      "695:\tlearn: 0.6245640\ttotal: 43m 1s\tremaining: 18m 48s\n",
      "696:\tlearn: 0.6244721\ttotal: 43m 2s\tremaining: 18m 44s\n",
      "697:\tlearn: 0.6242872\ttotal: 43m 3s\tremaining: 18m 39s\n",
      "698:\tlearn: 0.6241185\ttotal: 43m 5s\tremaining: 18m 34s\n",
      "699:\tlearn: 0.6239286\ttotal: 43m 6s\tremaining: 18m 30s\n",
      "700:\tlearn: 0.6237476\ttotal: 43m 7s\tremaining: 18m 25s\n",
      "701:\tlearn: 0.6236114\ttotal: 43m 9s\tremaining: 18m 20s\n",
      "702:\tlearn: 0.6233660\ttotal: 43m 10s\tremaining: 18m 16s\n",
      "703:\tlearn: 0.6231931\ttotal: 43m 12s\tremaining: 18m 11s\n",
      "704:\tlearn: 0.6229667\ttotal: 43m 13s\tremaining: 18m 6s\n",
      "705:\tlearn: 0.6226420\ttotal: 43m 14s\tremaining: 18m 2s\n",
      "706:\tlearn: 0.6225101\ttotal: 43m 16s\tremaining: 17m 57s\n",
      "707:\tlearn: 0.6223246\ttotal: 43m 17s\tremaining: 17m 52s\n",
      "708:\tlearn: 0.6221306\ttotal: 43m 19s\tremaining: 17m 48s\n",
      "709:\tlearn: 0.6220530\ttotal: 43m 20s\tremaining: 17m 43s\n",
      "710:\tlearn: 0.6218752\ttotal: 43m 22s\tremaining: 17m 39s\n",
      "711:\tlearn: 0.6216624\ttotal: 43m 24s\tremaining: 17m 34s\n",
      "712:\tlearn: 0.6215341\ttotal: 43m 25s\tremaining: 17m 30s\n",
      "713:\tlearn: 0.6213295\ttotal: 43m 27s\tremaining: 17m 25s\n",
      "714:\tlearn: 0.6211852\ttotal: 43m 28s\tremaining: 17m 21s\n",
      "715:\tlearn: 0.6209415\ttotal: 43m 30s\tremaining: 17m 16s\n",
      "716:\tlearn: 0.6208270\ttotal: 43m 32s\tremaining: 17m 12s\n",
      "717:\tlearn: 0.6207228\ttotal: 43m 34s\tremaining: 17m 8s\n",
      "718:\tlearn: 0.6204543\ttotal: 43m 36s\tremaining: 17m 3s\n",
      "719:\tlearn: 0.6202248\ttotal: 43m 37s\tremaining: 16m 59s\n",
      "720:\tlearn: 0.6200938\ttotal: 43m 39s\tremaining: 16m 55s\n",
      "721:\tlearn: 0.6197978\ttotal: 43m 41s\tremaining: 16m 50s\n",
      "722:\tlearn: 0.6195972\ttotal: 43m 42s\tremaining: 16m 46s\n",
      "723:\tlearn: 0.6194028\ttotal: 43m 43s\tremaining: 16m 41s\n",
      "724:\tlearn: 0.6191586\ttotal: 43m 44s\tremaining: 16m 36s\n",
      "725:\tlearn: 0.6189195\ttotal: 43m 46s\tremaining: 16m 32s\n",
      "726:\tlearn: 0.6187385\ttotal: 43m 47s\tremaining: 16m 28s\n",
      "727:\tlearn: 0.6185605\ttotal: 43m 49s\tremaining: 16m 23s\n",
      "728:\tlearn: 0.6184546\ttotal: 43m 50s\tremaining: 16m 19s\n",
      "729:\tlearn: 0.6181592\ttotal: 43m 52s\tremaining: 16m 15s\n",
      "730:\tlearn: 0.6179970\ttotal: 43m 54s\tremaining: 16m 10s\n",
      "731:\tlearn: 0.6178127\ttotal: 43m 56s\tremaining: 16m 6s\n",
      "732:\tlearn: 0.6175972\ttotal: 43m 57s\tremaining: 16m 2s\n",
      "733:\tlearn: 0.6175003\ttotal: 43m 59s\tremaining: 15m 58s\n",
      "734:\tlearn: 0.6170902\ttotal: 44m 1s\tremaining: 15m 53s\n",
      "735:\tlearn: 0.6169332\ttotal: 44m 3s\tremaining: 15m 49s\n",
      "736:\tlearn: 0.6167111\ttotal: 44m 5s\tremaining: 15m 45s\n",
      "737:\tlearn: 0.6165938\ttotal: 44m 7s\tremaining: 15m 41s\n",
      "738:\tlearn: 0.6163305\ttotal: 44m 9s\tremaining: 15m 36s\n",
      "739:\tlearn: 0.6161998\ttotal: 44m 11s\tremaining: 15m 32s\n",
      "740:\tlearn: 0.6159843\ttotal: 44m 13s\tremaining: 15m 28s\n",
      "741:\tlearn: 0.6156702\ttotal: 44m 15s\tremaining: 15m 24s\n",
      "742:\tlearn: 0.6154980\ttotal: 44m 16s\tremaining: 15m 20s\n",
      "743:\tlearn: 0.6153601\ttotal: 44m 18s\tremaining: 15m 16s\n",
      "744:\tlearn: 0.6152406\ttotal: 44m 20s\tremaining: 15m 11s\n",
      "745:\tlearn: 0.6150860\ttotal: 44m 22s\tremaining: 15m 7s\n",
      "746:\tlearn: 0.6149565\ttotal: 44m 24s\tremaining: 15m 3s\n",
      "747:\tlearn: 0.6147974\ttotal: 44m 26s\tremaining: 14m 59s\n",
      "748:\tlearn: 0.6145352\ttotal: 44m 27s\tremaining: 14m 55s\n",
      "749:\tlearn: 0.6143291\ttotal: 44m 29s\tremaining: 14m 50s\n",
      "750:\tlearn: 0.6142099\ttotal: 44m 30s\tremaining: 14m 46s\n",
      "751:\tlearn: 0.6140408\ttotal: 44m 32s\tremaining: 14m 42s\n",
      "752:\tlearn: 0.6139095\ttotal: 44m 34s\tremaining: 14m 38s\n",
      "753:\tlearn: 0.6137345\ttotal: 44m 35s\tremaining: 14m 34s\n",
      "754:\tlearn: 0.6135185\ttotal: 44m 37s\tremaining: 14m 30s\n",
      "755:\tlearn: 0.6133561\ttotal: 44m 39s\tremaining: 14m 25s\n",
      "756:\tlearn: 0.6131751\ttotal: 44m 40s\tremaining: 14m 21s\n",
      "757:\tlearn: 0.6129992\ttotal: 44m 42s\tremaining: 14m 17s\n",
      "758:\tlearn: 0.6127718\ttotal: 44m 43s\tremaining: 14m 13s\n",
      "759:\tlearn: 0.6120425\ttotal: 44m 45s\tremaining: 14m 9s\n",
      "760:\tlearn: 0.6118328\ttotal: 44m 46s\tremaining: 14m 4s\n",
      "761:\tlearn: 0.6117118\ttotal: 44m 48s\tremaining: 14m\n",
      "762:\tlearn: 0.6115381\ttotal: 44m 50s\tremaining: 13m 56s\n",
      "763:\tlearn: 0.6113862\ttotal: 44m 51s\tremaining: 13m 52s\n",
      "764:\tlearn: 0.6112022\ttotal: 44m 53s\tremaining: 13m 48s\n",
      "765:\tlearn: 0.6110231\ttotal: 44m 54s\tremaining: 13m 44s\n",
      "766:\tlearn: 0.6107340\ttotal: 44m 56s\tremaining: 13m 40s\n",
      "767:\tlearn: 0.6105678\ttotal: 44m 58s\tremaining: 13m 36s\n",
      "768:\tlearn: 0.6103826\ttotal: 44m 59s\tremaining: 13m 31s\n",
      "769:\tlearn: 0.6102584\ttotal: 45m 1s\tremaining: 13m 27s\n",
      "770:\tlearn: 0.6100431\ttotal: 45m 2s\tremaining: 13m 23s\n",
      "771:\tlearn: 0.6098369\ttotal: 45m 4s\tremaining: 13m 19s\n",
      "772:\tlearn: 0.6095817\ttotal: 45m 5s\tremaining: 13m 15s\n",
      "773:\tlearn: 0.6094829\ttotal: 45m 7s\tremaining: 13m 11s\n",
      "774:\tlearn: 0.6091898\ttotal: 45m 9s\tremaining: 13m 7s\n",
      "775:\tlearn: 0.6090567\ttotal: 45m 10s\tremaining: 13m 3s\n",
      "776:\tlearn: 0.6089124\ttotal: 45m 12s\tremaining: 12m 59s\n",
      "777:\tlearn: 0.6087736\ttotal: 45m 13s\tremaining: 12m 55s\n",
      "778:\tlearn: 0.6086934\ttotal: 45m 15s\tremaining: 12m 51s\n",
      "779:\tlearn: 0.6084296\ttotal: 45m 17s\tremaining: 12m 47s\n",
      "780:\tlearn: 0.6082746\ttotal: 45m 18s\tremaining: 12m 43s\n",
      "781:\tlearn: 0.6081001\ttotal: 45m 20s\tremaining: 12m 39s\n",
      "782:\tlearn: 0.6078976\ttotal: 45m 21s\tremaining: 12m 35s\n",
      "783:\tlearn: 0.6077648\ttotal: 45m 23s\tremaining: 12m 31s\n",
      "784:\tlearn: 0.6075062\ttotal: 45m 25s\tremaining: 12m 27s\n",
      "785:\tlearn: 0.6074043\ttotal: 45m 26s\tremaining: 12m 23s\n",
      "786:\tlearn: 0.6070934\ttotal: 45m 28s\tremaining: 12m 19s\n",
      "787:\tlearn: 0.6066523\ttotal: 45m 29s\tremaining: 12m 15s\n",
      "788:\tlearn: 0.6063784\ttotal: 45m 31s\tremaining: 12m 11s\n",
      "789:\tlearn: 0.6061637\ttotal: 45m 33s\tremaining: 12m 7s\n",
      "790:\tlearn: 0.6059187\ttotal: 45m 34s\tremaining: 12m 3s\n",
      "791:\tlearn: 0.6057910\ttotal: 45m 36s\tremaining: 11m 59s\n",
      "792:\tlearn: 0.6056694\ttotal: 45m 38s\tremaining: 11m 55s\n",
      "793:\tlearn: 0.6055738\ttotal: 45m 39s\tremaining: 11m 51s\n",
      "794:\tlearn: 0.6054473\ttotal: 45m 41s\tremaining: 11m 47s\n",
      "795:\tlearn: 0.6052147\ttotal: 45m 43s\tremaining: 11m 43s\n",
      "796:\tlearn: 0.6049825\ttotal: 45m 44s\tremaining: 11m 39s\n",
      "797:\tlearn: 0.6046786\ttotal: 45m 46s\tremaining: 11m 36s\n",
      "798:\tlearn: 0.6045525\ttotal: 45m 47s\tremaining: 11m 32s\n",
      "799:\tlearn: 0.6043060\ttotal: 45m 49s\tremaining: 11m 28s\n",
      "800:\tlearn: 0.6040295\ttotal: 45m 51s\tremaining: 11m 24s\n",
      "801:\tlearn: 0.6037459\ttotal: 45m 53s\tremaining: 11m 20s\n",
      "802:\tlearn: 0.6035336\ttotal: 45m 54s\tremaining: 11m 16s\n",
      "803:\tlearn: 0.6033287\ttotal: 45m 56s\tremaining: 11m 12s\n",
      "804:\tlearn: 0.6032280\ttotal: 45m 58s\tremaining: 11m 8s\n",
      "805:\tlearn: 0.6031377\ttotal: 45m 59s\tremaining: 11m 5s\n",
      "806:\tlearn: 0.6029879\ttotal: 46m 1s\tremaining: 11m 1s\n",
      "807:\tlearn: 0.6028598\ttotal: 46m 3s\tremaining: 10m 57s\n",
      "808:\tlearn: 0.6027264\ttotal: 46m 5s\tremaining: 10m 53s\n",
      "809:\tlearn: 0.6025222\ttotal: 46m 7s\tremaining: 10m 49s\n",
      "810:\tlearn: 0.6023265\ttotal: 46m 9s\tremaining: 10m 46s\n",
      "811:\tlearn: 0.6021717\ttotal: 46m 11s\tremaining: 10m 42s\n",
      "812:\tlearn: 0.6020373\ttotal: 46m 13s\tremaining: 10m 38s\n",
      "813:\tlearn: 0.6018225\ttotal: 46m 15s\tremaining: 10m 35s\n",
      "814:\tlearn: 0.6017203\ttotal: 46m 17s\tremaining: 10m 31s\n",
      "815:\tlearn: 0.6015162\ttotal: 46m 19s\tremaining: 10m 27s\n",
      "816:\tlearn: 0.6013806\ttotal: 46m 21s\tremaining: 10m 23s\n",
      "817:\tlearn: 0.6011316\ttotal: 46m 23s\tremaining: 10m 19s\n",
      "818:\tlearn: 0.6010450\ttotal: 46m 25s\tremaining: 10m 16s\n",
      "819:\tlearn: 0.6009203\ttotal: 46m 27s\tremaining: 10m 12s\n",
      "820:\tlearn: 0.6005839\ttotal: 46m 29s\tremaining: 10m 8s\n",
      "821:\tlearn: 0.6003996\ttotal: 46m 31s\tremaining: 10m 5s\n",
      "822:\tlearn: 0.6001857\ttotal: 46m 33s\tremaining: 10m 1s\n",
      "823:\tlearn: 0.6000251\ttotal: 46m 35s\tremaining: 9m 57s\n",
      "824:\tlearn: 0.5996298\ttotal: 46m 37s\tremaining: 9m 54s\n",
      "825:\tlearn: 0.5995210\ttotal: 46m 39s\tremaining: 9m 50s\n",
      "826:\tlearn: 0.5994267\ttotal: 46m 41s\tremaining: 9m 46s\n",
      "827:\tlearn: 0.5992317\ttotal: 46m 43s\tremaining: 9m 43s\n",
      "828:\tlearn: 0.5990119\ttotal: 46m 44s\tremaining: 9m 39s\n",
      "829:\tlearn: 0.5987903\ttotal: 46m 46s\tremaining: 9m 35s\n",
      "830:\tlearn: 0.5986290\ttotal: 46m 48s\tremaining: 9m 31s\n",
      "831:\tlearn: 0.5984761\ttotal: 46m 50s\tremaining: 9m 28s\n",
      "832:\tlearn: 0.5983694\ttotal: 46m 52s\tremaining: 9m 24s\n",
      "833:\tlearn: 0.5982507\ttotal: 46m 54s\tremaining: 9m 20s\n",
      "834:\tlearn: 0.5979618\ttotal: 46m 57s\tremaining: 9m 17s\n",
      "835:\tlearn: 0.5978243\ttotal: 46m 59s\tremaining: 9m 13s\n",
      "836:\tlearn: 0.5976873\ttotal: 47m 1s\tremaining: 9m 10s\n",
      "837:\tlearn: 0.5971927\ttotal: 47m 3s\tremaining: 9m 6s\n",
      "838:\tlearn: 0.5970470\ttotal: 47m 5s\tremaining: 9m 2s\n",
      "839:\tlearn: 0.5969192\ttotal: 47m 7s\tremaining: 8m 59s\n",
      "840:\tlearn: 0.5960291\ttotal: 47m 8s\tremaining: 8m 55s\n",
      "841:\tlearn: 0.5958521\ttotal: 47m 10s\tremaining: 8m 51s\n",
      "842:\tlearn: 0.5957500\ttotal: 47m 12s\tremaining: 8m 48s\n",
      "843:\tlearn: 0.5956526\ttotal: 47m 14s\tremaining: 8m 44s\n",
      "844:\tlearn: 0.5954177\ttotal: 47m 16s\tremaining: 8m 40s\n",
      "845:\tlearn: 0.5952385\ttotal: 47m 18s\tremaining: 8m 37s\n",
      "846:\tlearn: 0.5950308\ttotal: 47m 20s\tremaining: 8m 33s\n",
      "847:\tlearn: 0.5948870\ttotal: 47m 21s\tremaining: 8m 30s\n",
      "848:\tlearn: 0.5947073\ttotal: 47m 23s\tremaining: 8m 26s\n",
      "849:\tlearn: 0.5945522\ttotal: 47m 25s\tremaining: 8m 22s\n",
      "850:\tlearn: 0.5943970\ttotal: 47m 26s\tremaining: 8m 19s\n",
      "851:\tlearn: 0.5941829\ttotal: 47m 28s\tremaining: 8m 15s\n",
      "852:\tlearn: 0.5938957\ttotal: 47m 30s\tremaining: 8m 11s\n",
      "853:\tlearn: 0.5937424\ttotal: 47m 31s\tremaining: 8m 8s\n",
      "854:\tlearn: 0.5935741\ttotal: 47m 33s\tremaining: 8m 4s\n",
      "855:\tlearn: 0.5933662\ttotal: 47m 34s\tremaining: 8m\n",
      "856:\tlearn: 0.5932048\ttotal: 47m 36s\tremaining: 7m 57s\n",
      "857:\tlearn: 0.5930942\ttotal: 47m 38s\tremaining: 7m 53s\n",
      "858:\tlearn: 0.5929924\ttotal: 47m 39s\tremaining: 7m 49s\n",
      "859:\tlearn: 0.5928348\ttotal: 47m 41s\tremaining: 7m 46s\n",
      "860:\tlearn: 0.5927169\ttotal: 47m 42s\tremaining: 7m 42s\n",
      "861:\tlearn: 0.5926168\ttotal: 47m 44s\tremaining: 7m 39s\n",
      "862:\tlearn: 0.5923153\ttotal: 47m 46s\tremaining: 7m 35s\n",
      "863:\tlearn: 0.5922185\ttotal: 47m 47s\tremaining: 7m 31s\n",
      "864:\tlearn: 0.5919739\ttotal: 47m 49s\tremaining: 7m 28s\n",
      "865:\tlearn: 0.5918648\ttotal: 47m 50s\tremaining: 7m 24s\n",
      "866:\tlearn: 0.5917260\ttotal: 47m 52s\tremaining: 7m 21s\n",
      "867:\tlearn: 0.5915029\ttotal: 47m 54s\tremaining: 7m 17s\n",
      "868:\tlearn: 0.5913279\ttotal: 47m 55s\tremaining: 7m 14s\n",
      "869:\tlearn: 0.5911638\ttotal: 47m 57s\tremaining: 7m 10s\n",
      "870:\tlearn: 0.5910856\ttotal: 47m 59s\tremaining: 7m 6s\n",
      "871:\tlearn: 0.5909329\ttotal: 48m\tremaining: 7m 3s\n",
      "872:\tlearn: 0.5907927\ttotal: 48m 2s\tremaining: 6m 59s\n",
      "873:\tlearn: 0.5906077\ttotal: 48m 3s\tremaining: 6m 56s\n",
      "874:\tlearn: 0.5905147\ttotal: 48m 5s\tremaining: 6m 52s\n",
      "875:\tlearn: 0.5903999\ttotal: 48m 7s\tremaining: 6m 49s\n",
      "876:\tlearn: 0.5902744\ttotal: 48m 8s\tremaining: 6m 45s\n",
      "877:\tlearn: 0.5901604\ttotal: 48m 10s\tremaining: 6m 42s\n",
      "878:\tlearn: 0.5900084\ttotal: 48m 11s\tremaining: 6m 38s\n",
      "879:\tlearn: 0.5899414\ttotal: 48m 13s\tremaining: 6m 34s\n",
      "880:\tlearn: 0.5897811\ttotal: 48m 14s\tremaining: 6m 31s\n",
      "881:\tlearn: 0.5896639\ttotal: 48m 16s\tremaining: 6m 27s\n",
      "882:\tlearn: 0.5895555\ttotal: 48m 18s\tremaining: 6m 24s\n",
      "883:\tlearn: 0.5894517\ttotal: 48m 19s\tremaining: 6m 20s\n",
      "884:\tlearn: 0.5893033\ttotal: 48m 21s\tremaining: 6m 17s\n",
      "885:\tlearn: 0.5891407\ttotal: 48m 22s\tremaining: 6m 13s\n",
      "886:\tlearn: 0.5889784\ttotal: 48m 24s\tremaining: 6m 10s\n",
      "887:\tlearn: 0.5886920\ttotal: 48m 26s\tremaining: 6m 6s\n",
      "888:\tlearn: 0.5881882\ttotal: 48m 28s\tremaining: 6m 3s\n",
      "889:\tlearn: 0.5880639\ttotal: 48m 29s\tremaining: 6m\n",
      "890:\tlearn: 0.5876080\ttotal: 48m 31s\tremaining: 5m 56s\n",
      "891:\tlearn: 0.5874621\ttotal: 48m 33s\tremaining: 5m 53s\n",
      "892:\tlearn: 0.5872672\ttotal: 48m 35s\tremaining: 5m 49s\n",
      "893:\tlearn: 0.5871221\ttotal: 48m 37s\tremaining: 5m 46s\n",
      "894:\tlearn: 0.5869412\ttotal: 48m 38s\tremaining: 5m 42s\n",
      "895:\tlearn: 0.5868168\ttotal: 48m 40s\tremaining: 5m 39s\n",
      "896:\tlearn: 0.5865176\ttotal: 48m 41s\tremaining: 5m 35s\n",
      "897:\tlearn: 0.5863498\ttotal: 48m 43s\tremaining: 5m 32s\n",
      "898:\tlearn: 0.5862142\ttotal: 48m 45s\tremaining: 5m 28s\n",
      "899:\tlearn: 0.5859032\ttotal: 48m 46s\tremaining: 5m 25s\n",
      "900:\tlearn: 0.5856890\ttotal: 48m 48s\tremaining: 5m 22s\n",
      "901:\tlearn: 0.5850500\ttotal: 48m 50s\tremaining: 5m 18s\n",
      "902:\tlearn: 0.5848469\ttotal: 48m 52s\tremaining: 5m 15s\n",
      "903:\tlearn: 0.5847248\ttotal: 48m 53s\tremaining: 5m 11s\n",
      "904:\tlearn: 0.5846099\ttotal: 48m 55s\tremaining: 5m 8s\n",
      "905:\tlearn: 0.5844191\ttotal: 48m 57s\tremaining: 5m 5s\n",
      "906:\tlearn: 0.5843291\ttotal: 48m 59s\tremaining: 5m 1s\n",
      "907:\tlearn: 0.5840948\ttotal: 49m 1s\tremaining: 4m 58s\n",
      "908:\tlearn: 0.5839833\ttotal: 49m 3s\tremaining: 4m 54s\n",
      "909:\tlearn: 0.5839227\ttotal: 49m 4s\tremaining: 4m 51s\n",
      "910:\tlearn: 0.5838206\ttotal: 49m 6s\tremaining: 4m 48s\n",
      "911:\tlearn: 0.5836387\ttotal: 49m 8s\tremaining: 4m 44s\n",
      "912:\tlearn: 0.5835426\ttotal: 49m 9s\tremaining: 4m 41s\n",
      "913:\tlearn: 0.5834249\ttotal: 49m 11s\tremaining: 4m 38s\n",
      "914:\tlearn: 0.5833549\ttotal: 49m 13s\tremaining: 4m 34s\n",
      "915:\tlearn: 0.5831963\ttotal: 49m 14s\tremaining: 4m 31s\n",
      "916:\tlearn: 0.5830715\ttotal: 49m 16s\tremaining: 4m 27s\n",
      "917:\tlearn: 0.5828899\ttotal: 49m 18s\tremaining: 4m 24s\n",
      "918:\tlearn: 0.5827675\ttotal: 49m 19s\tremaining: 4m 21s\n",
      "919:\tlearn: 0.5827032\ttotal: 49m 21s\tremaining: 4m 17s\n",
      "920:\tlearn: 0.5825822\ttotal: 49m 23s\tremaining: 4m 14s\n",
      "921:\tlearn: 0.5824740\ttotal: 49m 25s\tremaining: 4m 11s\n",
      "922:\tlearn: 0.5823254\ttotal: 49m 27s\tremaining: 4m 7s\n",
      "923:\tlearn: 0.5822149\ttotal: 49m 29s\tremaining: 4m 4s\n",
      "924:\tlearn: 0.5820875\ttotal: 49m 31s\tremaining: 4m 1s\n",
      "925:\tlearn: 0.5818860\ttotal: 49m 33s\tremaining: 3m 57s\n",
      "926:\tlearn: 0.5816432\ttotal: 49m 35s\tremaining: 3m 54s\n",
      "927:\tlearn: 0.5814474\ttotal: 49m 37s\tremaining: 3m 51s\n",
      "928:\tlearn: 0.5811937\ttotal: 49m 39s\tremaining: 3m 47s\n",
      "929:\tlearn: 0.5810388\ttotal: 49m 41s\tremaining: 3m 44s\n",
      "930:\tlearn: 0.5809000\ttotal: 49m 43s\tremaining: 3m 41s\n",
      "931:\tlearn: 0.5807264\ttotal: 49m 45s\tremaining: 3m 38s\n",
      "932:\tlearn: 0.5806069\ttotal: 49m 47s\tremaining: 3m 34s\n",
      "933:\tlearn: 0.5804334\ttotal: 49m 49s\tremaining: 3m 31s\n",
      "934:\tlearn: 0.5803184\ttotal: 49m 51s\tremaining: 3m 28s\n",
      "935:\tlearn: 0.5799414\ttotal: 49m 53s\tremaining: 3m 24s\n",
      "936:\tlearn: 0.5798660\ttotal: 49m 55s\tremaining: 3m 21s\n",
      "937:\tlearn: 0.5797717\ttotal: 49m 56s\tremaining: 3m 18s\n",
      "938:\tlearn: 0.5796543\ttotal: 49m 58s\tremaining: 3m 15s\n",
      "939:\tlearn: 0.5794308\ttotal: 50m\tremaining: 3m 11s\n",
      "940:\tlearn: 0.5788062\ttotal: 50m 2s\tremaining: 3m 8s\n",
      "941:\tlearn: 0.5786940\ttotal: 50m 4s\tremaining: 3m 5s\n",
      "942:\tlearn: 0.5785561\ttotal: 50m 6s\tremaining: 3m 1s\n",
      "943:\tlearn: 0.5784372\ttotal: 50m 8s\tremaining: 2m 58s\n",
      "944:\tlearn: 0.5783386\ttotal: 50m 9s\tremaining: 2m 55s\n",
      "945:\tlearn: 0.5781788\ttotal: 50m 11s\tremaining: 2m 52s\n",
      "946:\tlearn: 0.5780633\ttotal: 50m 13s\tremaining: 2m 48s\n",
      "947:\tlearn: 0.5779443\ttotal: 50m 14s\tremaining: 2m 45s\n",
      "948:\tlearn: 0.5778433\ttotal: 50m 16s\tremaining: 2m 42s\n",
      "949:\tlearn: 0.5777028\ttotal: 50m 19s\tremaining: 2m 39s\n",
      "950:\tlearn: 0.5775746\ttotal: 50m 21s\tremaining: 2m 35s\n",
      "951:\tlearn: 0.5774656\ttotal: 50m 22s\tremaining: 2m 32s\n",
      "952:\tlearn: 0.5773576\ttotal: 50m 24s\tremaining: 2m 29s\n",
      "953:\tlearn: 0.5769688\ttotal: 50m 26s\tremaining: 2m 26s\n",
      "954:\tlearn: 0.5767837\ttotal: 50m 29s\tremaining: 2m 22s\n",
      "955:\tlearn: 0.5767040\ttotal: 50m 31s\tremaining: 2m 19s\n",
      "956:\tlearn: 0.5766286\ttotal: 50m 33s\tremaining: 2m 16s\n",
      "957:\tlearn: 0.5765507\ttotal: 50m 36s\tremaining: 2m 13s\n",
      "958:\tlearn: 0.5763175\ttotal: 50m 38s\tremaining: 2m 10s\n",
      "959:\tlearn: 0.5761878\ttotal: 50m 41s\tremaining: 2m 6s\n",
      "960:\tlearn: 0.5760955\ttotal: 50m 43s\tremaining: 2m 3s\n",
      "961:\tlearn: 0.5759884\ttotal: 50m 45s\tremaining: 2m\n",
      "962:\tlearn: 0.5759028\ttotal: 50m 47s\tremaining: 1m 57s\n",
      "963:\tlearn: 0.5758245\ttotal: 50m 49s\tremaining: 1m 54s\n",
      "964:\tlearn: 0.5756860\ttotal: 50m 51s\tremaining: 1m 50s\n",
      "965:\tlearn: 0.5755349\ttotal: 50m 54s\tremaining: 1m 47s\n",
      "966:\tlearn: 0.5753583\ttotal: 50m 56s\tremaining: 1m 44s\n",
      "967:\tlearn: 0.5752957\ttotal: 50m 59s\tremaining: 1m 41s\n",
      "968:\tlearn: 0.5751509\ttotal: 51m 1s\tremaining: 1m 38s\n",
      "969:\tlearn: 0.5750130\ttotal: 51m 3s\tremaining: 1m 34s\n",
      "970:\tlearn: 0.5748784\ttotal: 51m 5s\tremaining: 1m 31s\n",
      "971:\tlearn: 0.5748160\ttotal: 51m 7s\tremaining: 1m 28s\n",
      "972:\tlearn: 0.5740244\ttotal: 51m 10s\tremaining: 1m 25s\n",
      "973:\tlearn: 0.5738594\ttotal: 51m 12s\tremaining: 1m 22s\n",
      "974:\tlearn: 0.5736247\ttotal: 51m 14s\tremaining: 1m 18s\n",
      "975:\tlearn: 0.5734555\ttotal: 51m 16s\tremaining: 1m 15s\n",
      "976:\tlearn: 0.5733133\ttotal: 51m 18s\tremaining: 1m 12s\n",
      "977:\tlearn: 0.5731314\ttotal: 51m 20s\tremaining: 1m 9s\n",
      "978:\tlearn: 0.5729981\ttotal: 51m 23s\tremaining: 1m 6s\n",
      "979:\tlearn: 0.5728414\ttotal: 51m 24s\tremaining: 1m 3s\n",
      "980:\tlearn: 0.5726882\ttotal: 51m 27s\tremaining: 59.9s\n",
      "981:\tlearn: 0.5726503\ttotal: 51m 29s\tremaining: 56.7s\n",
      "982:\tlearn: 0.5725492\ttotal: 51m 31s\tremaining: 53.5s\n",
      "983:\tlearn: 0.5723656\ttotal: 51m 33s\tremaining: 50.4s\n",
      "984:\tlearn: 0.5723020\ttotal: 51m 35s\tremaining: 47.2s\n",
      "985:\tlearn: 0.5722203\ttotal: 51m 37s\tremaining: 44s\n",
      "986:\tlearn: 0.5721173\ttotal: 51m 40s\tremaining: 40.9s\n",
      "987:\tlearn: 0.5720192\ttotal: 51m 42s\tremaining: 37.7s\n",
      "988:\tlearn: 0.5719044\ttotal: 51m 44s\tremaining: 34.6s\n",
      "989:\tlearn: 0.5716592\ttotal: 51m 46s\tremaining: 31.4s\n",
      "990:\tlearn: 0.5715461\ttotal: 51m 48s\tremaining: 28.3s\n",
      "991:\tlearn: 0.5714230\ttotal: 51m 50s\tremaining: 25.1s\n",
      "992:\tlearn: 0.5712405\ttotal: 51m 52s\tremaining: 22s\n",
      "993:\tlearn: 0.5710982\ttotal: 51m 55s\tremaining: 18.8s\n",
      "994:\tlearn: 0.5709343\ttotal: 51m 56s\tremaining: 15.7s\n",
      "995:\tlearn: 0.5703144\ttotal: 51m 58s\tremaining: 12.5s\n",
      "996:\tlearn: 0.5701763\ttotal: 52m 1s\tremaining: 9.4s\n",
      "997:\tlearn: 0.5699408\ttotal: 52m 3s\tremaining: 6.26s\n",
      "998:\tlearn: 0.5698393\ttotal: 52m 5s\tremaining: 3.13s\n",
      "999:\tlearn: 0.5697353\ttotal: 52m 7s\tremaining: 0us\n",
      "CatBoostClassifier F1 score:  0.8915069715380561\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "catboost_classifier = CatBoostClassifier()\n",
    "catboost_classifier.fit(X_train_vect, y_train)\n",
    "pred_Catb = catboost_classifier.predict(X_test_vect)\n",
    "print(\"CatBoostClassifier F1 score: \", f1_score(y_test, pred_Catb,average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "params = {\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': len(result_df['Language_Index'].unique()),  \n",
    "    'metric': 'multi_logloss'\n",
    "}\n",
    "\n",
    "num_round = 100\n",
    "lgb_model = lgb.train(params, X_train_vect, num_round, valid_sets=[X_test_vect], early_stopping_rounds=10)\n",
    "\n",
    "y_pred = lgb_model.predict(X_test_vect)\n",
    "pred_lgb = [list(x).index(max(x)) for x in y_pred]\n",
    "\n",
    "print(\"lightgbm F1 score: \", f1_score(y_test, pred_lgb,average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9668449197860962\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, pred_nb)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=[\"m mase kono ullekhayogya tapapravaher dasha anubhav kara yyani.\"]\n",
    "vectorizer.transform(text)\n",
    "hehe=nb_classifier.predict(vectorizer.transform(text))\n",
    "hehe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(X_train_vect, y_train)\n",
    "pred_SVM = svm_model.predict(X_test_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9641711229946524\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, pred_SVM)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTC=DecisionTreeClassifier()\n",
    "DTC.fit(X_train_vect,y_train)\n",
    "pred_DTC=DTC.predict(X_test_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8491978609625669\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,pred_DTC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes F1 score:  0.9666462181924289\n",
      "SVM F1 score:  0.9645088734706874\n",
      "Decission Tree Classifier F1 score:  0.8529020724914755\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print(\"Naive Bayes F1 score: \", f1_score(y_test, pred_nb,average='weighted'))\n",
    "print(\"SVM F1 score: \", f1_score(y_test, pred_SVM,average='weighted'))\n",
    "print(\"Decission Tree Classifier F1 score: \",f1_score(y_test, pred_DTC,average='weighted'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred_LR' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 7\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StackingClassifier\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier\n\u001b[0;32m      4\u001b[0m stacking_train \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSVM\u001b[39m\u001b[38;5;124m\"\u001b[39m: pred_SVM,\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaive Bayes\u001b[39m\u001b[38;5;124m\"\u001b[39m: pred_nb,\n\u001b[1;32m----> 7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLogistic Regression\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mpred_LR\u001b[49m,\n\u001b[0;32m      8\u001b[0m })\n\u001b[0;32m     10\u001b[0m meta_learner \u001b[38;5;241m=\u001b[39m RandomForestClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m     11\u001b[0m stacking_model \u001b[38;5;241m=\u001b[39m StackingClassifier(estimators\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m     12\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msvm\u001b[39m\u001b[38;5;124m'\u001b[39m, svm_model),\n\u001b[0;32m     13\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnb\u001b[39m\u001b[38;5;124m'\u001b[39m, nb_classifier),\n\u001b[0;32m     14\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m, LR_model),\n\u001b[0;32m     15\u001b[0m ], final_estimator\u001b[38;5;241m=\u001b[39mmeta_learner)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pred_LR' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "stacking_train = pd.DataFrame({\n",
    "    \"SVM\": pred_SVM,\n",
    "    \"Naive Bayes\": pred_nb,\n",
    "    \"Logistic Regression\": pred_LR,\n",
    "})\n",
    "\n",
    "meta_learner = RandomForestClassifier(n_estimators=100)\n",
    "stacking_model = StackingClassifier(estimators=[\n",
    "    ('svm', svm_model),\n",
    "    ('nb', nb_classifier),\n",
    "    ('lr', LR_model),\n",
    "], final_estimator=meta_learner)\n",
    "\n",
    "stacking_model.fit(stacking_train, y_test)\n",
    "\n",
    "# Calculate F1 weighted score for the ensemble model\n",
    "stacking_pred = stacking_model.predict(stacking_train)\n",
    "stacking_f1 = f1_score(y_test, stacking_pred, average='weighted')\n",
    "print(\"F1 weighted score for ensemble model:\", stacking_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy:  0.9668449197860962\n",
      "SVM Accuracy:  0.9641711229946524\n",
      "Decission Tree Classifier Accuracy:  0.8491978609625669\n"
     ]
    }
   ],
   "source": [
    "print(\"Naive Bayes Accuracy: \", accuracy_score(y_test, pred_nb))\n",
    "print(\"SVM Accuracy: \", accuracy_score(y_test, pred_SVM))\n",
    "print(\"Decission Tree Classifier Accuracy: \",accuracy_score(y_test, pred_DTC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes MSE:  0.5783422459893048\n",
      "SVM MSE:  0.6459893048128342\n",
      "Decission Tree Classifier MSE:  3.3310160427807487\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "print(\"Naive Bayes MSE: \", mean_squared_error(y_test, pred_nb))\n",
    "print(\"SVM MSE: \", mean_squared_error(y_test, pred_SVM))\n",
    "print(\"Decission Tree Classifier MSE: \",mean_squared_error(y_test, pred_DTC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "\n",
    "\n",
    "MAX_FEATURES=200000 #no of words in our vocablary\n",
    "\n",
    "vectorizer=TextVectorization(max_tokens=MAX_FEATURES,\n",
    "                             output_sequence_length=600,  #This will be the maximum lenght of the sentence.\n",
    "                             output_mode='int')\n",
    "\n",
    "vectorizer.adapt(X.values)\n",
    "vectorized_text=vectorizer(X.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MCSHBAP - map,cache,shuffle,prefetch from_tensor_slices , list_files\n",
    "dataset=tf.data.Dataset.from_tensor_slices((vectorized_text,Y))\n",
    "dataset=dataset.cache()\n",
    "dataset=dataset.shuffle(160000)\n",
    "dataset=dataset.batch(16)\n",
    "dataset=dataset.prefetch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x,batch_y=dataset.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10],\n",
       "       [10],\n",
       "       [ 4],\n",
       "       [ 7],\n",
       "       [ 7],\n",
       "       [ 4],\n",
       "       [ 5],\n",
       "       [ 4],\n",
       "       [ 9],\n",
       "       [ 6],\n",
       "       [ 4],\n",
       "       [ 3],\n",
       "       [ 6],\n",
       "       [ 3],\n",
       "       [10],\n",
       "       [ 4]], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_y.reshape(16,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=dataset.take(int(len(dataset)*0.7))\n",
    "val=dataset.skip(int(len(dataset)*0.7)).take(int(len(dataset)*0.2))\n",
    "test=dataset.skip(int(len(dataset)*0.9)).take(int(len(dataset)*0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator=train.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[   47,   493,  7480, ...,     0,     0,     0],\n",
       "        [   26, 19704,  1620, ...,     0,     0,     0],\n",
       "        [   52,  3449,  2486, ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [26416,   918,  3583, ...,     0,     0,     0],\n",
       "        [   74, 21457,  7640, ...,     0,     0,     0],\n",
       "        [ 3110, 65036,   363, ...,     0,     0,     0]], dtype=int64),\n",
       " array([ 5,  4, 10,  2,  7,  6,  4,  1,  1, 10,  3,  6,  1,  0,  5,  1],\n",
       "       dtype=int64))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM,Dropout,Bidirectional, Dense, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#first create the embedding layer, +1 is for padding or unknown tokens\n",
    "model.add(Embedding(MAX_FEATURES+1,32))\n",
    "#Bidirectional LSTM layer\n",
    "model.add(Bidirectional(LSTM(32,activation='tanh')))  # let it be tanh for right now, we will also try for softmax\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(Dense(128,activation='relu'))\n",
    "#Final layers\n",
    "model.add(Dense(11,activation='softmax'))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='SparseCategoricalCrossentropy',optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Expected float32, but got <keras.src.losses.losses.SparseCategoricalCrossentropy object at 0x00000270A4DE2A10> of type 'SparseCategoricalCrossentropy'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\agrvi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\agrvi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:114\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[1;34m(x, dtype, sparse)\u001b[0m\n\u001b[0;32m    112\u001b[0m         x \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(x)\n\u001b[0;32m    113\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcast(x, dtype)\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m dtype:\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, tf\u001b[38;5;241m.\u001b[39mSparseTensor):\n",
      "\u001b[1;31mTypeError\u001b[0m: Expected float32, but got <keras.src.losses.losses.SparseCategoricalCrossentropy object at 0x00000270A4DE2A10> of type 'SparseCategoricalCrossentropy'."
     ]
    }
   ],
   "source": [
    "history=model.fit(train,epochs=15,validation_data=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'],label='Training loss')\n",
    "plt.plot(history.history['val_loss'],label='Validation loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 544ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[7.2954627e-08, 8.0388979e-17, 1.4588633e-13, 3.3431257e-20,\n",
       "        1.2408222e-15, 3.0556225e-07, 9.4313342e-22, 2.1636156e-13,\n",
       "        2.5689324e-19, 6.9405970e-10, 9.9999964e-01]], dtype=float32)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text=vectorizer('you freaking suck! i am going to kill you')\n",
    "model.predict(np.array([input_text]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type _TakeDataset).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[143], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(test, (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)) \n\u001b[1;32m----> 2\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\agrvi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\agrvi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[0;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type _TakeDataset)."
     ]
    }
   ],
   "source": [
    "test = np.reshape(test, (1, -1)) \n",
    "predictions = model.predict(np.array([test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.2954627e-08, 8.0388979e-17, 1.4588633e-13, 3.3431257e-20,\n",
       "        1.2408222e-15, 3.0556225e-07, 9.4313342e-22, 2.1636156e-13,\n",
       "        2.5689324e-19, 6.9405970e-10, 9.9999964e-01]], dtype=float32)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10], dtype=int64)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 3029s 26s/step\n"
     ]
    }
   ],
   "source": [
    "y_pred__NN=model.predict(X_test_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 0]])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_pred__NN > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4396     2\n",
       "16060    9\n",
       "1642     0\n",
       "4044     2\n",
       "13186    7\n",
       "        ..\n",
       "13590    7\n",
       "15717    9\n",
       "7082     4\n",
       "7188     4\n",
       "8237     4\n",
       "Name: Language_Index, Length: 3740, dtype: int64"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multilabel-indicator and multiclass targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[156], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred__NN\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, accuracy)\n\u001b[0;32m      3\u001b[0m mse \u001b[38;5;241m=\u001b[39m mean_squared_error((y_pred__NN \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m), y_test)\n",
      "File \u001b[1;32mc:\\Users\\agrvi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\agrvi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:220\u001b[0m, in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \n\u001b[0;32m    156\u001b[0m \u001b[38;5;124;03mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;124;03m0.5\u001b[39;00m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[1;32m--> 220\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\agrvi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:93\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     90\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m     95\u001b[0m             type_true, type_pred\n\u001b[0;32m     96\u001b[0m         )\n\u001b[0;32m     97\u001b[0m     )\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    100\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multilabel-indicator and multiclass targets"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score((y_pred__NN > 0.5).astype(int), y_test)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "mse = mean_squared_error((y_pred__NN > 0.5).astype(int), y_test)\n",
    "print(\"Mean Squared Error:\", mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'as_numpy_iterator'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[151], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m batch_X, batch_y \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_numpy_iterator\u001b[49m()\u001b[38;5;241m.\u001b[39mnext()\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Precision, Recall, CategoricalAccuracy\n\u001b[0;32m      3\u001b[0m pre \u001b[38;5;241m=\u001b[39m Precision()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'as_numpy_iterator'"
     ]
    }
   ],
   "source": [
    "batch_X, batch_y = test.as_numpy_iterator().next()\n",
    "from tensorflow.keras.metrics import Precision, Recall, CategoricalAccuracy\n",
    "pre = Precision()\n",
    "re = Recall()\n",
    "acc = CategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in test.as_numpy_iterator(): \n",
    "    # Unpack the batch \n",
    "    X_true, y_true = batch\n",
    "    # Make a prediction \n",
    "    yhat = model.predict(X_true)\n",
    "    \n",
    "    # Flatten the predictions\n",
    "    y_true = y_true.flatten()\n",
    "    yhat = yhat.flatten()\n",
    "    \n",
    "    pre.update_state(y_true, yhat)\n",
    "    re.update_state(y_true, yhat)\n",
    "    acc.update_state(y_true, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Precision: {pre.result().numpy()}, Recall:{re.result().numpy()}, Accuracy:{acc.result().numpy()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'indic-trans'...\n",
      "error: RPC failed; curl 92 HTTP/2 stream 5 was not closed cleanly: CANCEL (err 8)\n",
      "error: 3895 bytes of body are still expected\n",
      "fetch-pack: unexpected disconnect while reading sideband packet\n",
      "fatal: early EOF\n",
      "fatal: fetch-pack: invalid index-pack output\n"
     ]
    }
   ],
   "source": [
    "! git clone https://github.com/libindic/indic-trans.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm \n\u001b[0;32m      2\u001b[0m j\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m9e6\u001b[39;49m\u001b[43m)\u001b[49m):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'float' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm \n",
    "j=0\n",
    "for i in tqdm(range(9e6)):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
