{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cwDxwr9rNICd"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB # best\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zcJzFKBDNSCH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1700 entries, 0 to 1699\n",
            "Data columns (total 11 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   ben     1700 non-null   object\n",
            " 1   guj     1700 non-null   object\n",
            " 2   hin     1700 non-null   object\n",
            " 3   kan     1700 non-null   object\n",
            " 4   mal     1700 non-null   object\n",
            " 5   ori     1700 non-null   object\n",
            " 6   pan     1700 non-null   object\n",
            " 7   tam     1700 non-null   object\n",
            " 8   tel     1700 non-null   object\n",
            " 9   urd     1700 non-null   object\n",
            " 10  eng     1700 non-null   object\n",
            "dtypes: object(11)\n",
            "memory usage: 146.2+ KB\n"
          ]
        }
      ],
      "source": [
        "df_test = pd.read_csv('icdc\\english translation\\english-translation.csv')\n",
        "df = pd.read_csv(r'icdc\\train.csv')\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "LANGS = ['ben', 'hin', 'pan', 'tam', 'tel']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5\n"
          ]
        }
      ],
      "source": [
        "dfs=[]\n",
        "for i,col_name in enumerate(df.columns):\n",
        "    if col_name in LANGS:\n",
        "        df2=pd.DataFrame({'Comment':df[col_name],'Language_Index': LANGS.index(col_name), 'Language': col_name})\n",
        "        dfs.append(df2)\n",
        "\n",
        "result_df = pd.concat(dfs, ignore_index=True)   \n",
        "print(len(dfs)) \n",
        "\n",
        "X=result_df['Comment']\n",
        "Y=result_df['Language_Index']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=26)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "X_train_vect = vectorizer.fit_transform(X_train)\n",
        "X_test_vect = vectorizer.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Xj0lWCQcSs1D"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.981764705882353\n"
          ]
        }
      ],
      "source": [
        "lr_classifier = LogisticRegression(max_iter=300)\n",
        "lr_classifier.fit(X_train_vect, y_train)\n",
        "pred_lr = lr_classifier.predict(X_test_vect)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, lr_classifier.predict(X_test_vect)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9905882352941177\n"
          ]
        }
      ],
      "source": [
        "nb_classifier = MultinomialNB()\n",
        "nb_classifier.fit(X_train_vect, y_train)\n",
        "pred_nb = nb_classifier.predict(X_test_vect)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, pred_nb))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "tcqvcgZoqY-W"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 84.59it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 score:  0.9894222540839781\n",
            "Accuracy:  0.9894117647058823\n",
            "MSE:  0.05411764705882353\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# NORMALIZE and MAKE between 0 and 1\n",
        "def prob(arr:np.ndarray, gap_adjuster:int=3)->np.ndarray:\n",
        "    if len(arr.shape) == 1:\n",
        "        arr = (arr-arr.min())/(arr.max()-arr.min())\n",
        "        if gap_adjuster!=1: arr = arr**gap_adjuster\n",
        "        return arr/arr.sum()\n",
        "    else:\n",
        "        arr = (arr-arr.min(axis=1).reshape(-1, 1))/(arr.max(axis=1)-arr.min(axis=1)).reshape(-1, 1)\n",
        "        if gap_adjuster!=1: arr = arr**gap_adjuster\n",
        "        return arr/arr.sum(axis=1).reshape(-1, 1)\n",
        "    \n",
        "\n",
        "def emsemble_infer_v2(texts:str|list[str], printable=False):\n",
        "    if isinstance(texts, str): texts = [texts]\n",
        "    output = (\n",
        "        prob(lr_classifier.predict_proba(vectorizer.transform(texts)), gap_adjuster=1) + \n",
        "        prob(nb_classifier.predict_proba(vectorizer.transform(texts)), gap_adjuster=1) #+\n",
        "    ).argmax(axis=1)\n",
        "    if printable:\n",
        "        return [LANGS[i] for i in output.tolist()]\n",
        "    else:\n",
        "        return output\n",
        "    \n",
        "pred_emsemble_v2 = []\n",
        "for i in tqdm(range(0, len(X_test), 64)):\n",
        "    pred_emsemble_v2.append(emsemble_infer_v2(X_test[i:i+64]))\n",
        "\n",
        "pred_emsemble_v2 = np.concatenate(pred_emsemble_v2, axis = 0)\n",
        "\n",
        "print(\"F1 score: \", f1_score(y_test, pred_emsemble_v2, average='weighted'))\n",
        "print(\"Accuracy: \", accuracy_score(y_test, pred_emsemble_v2))\n",
        "print(\"MSE: \", mean_squared_error(y_test, pred_emsemble_v2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "T_XxzI5kUioa"
      },
      "outputs": [],
      "source": [
        "df_translitration=df_test['text'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "kuNtwBszP9ak"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 13/13 [00:00<00:00, 164.56it/s]\n"
          ]
        }
      ],
      "source": [
        "pred_emsemble_v2 = []\n",
        "for i in tqdm(range(0, len(df_translitration), 64)):\n",
        "    pred_emsemble_v2.append(emsemble_infer_v2(df_translitration[i:i+64]))\n",
        "\n",
        "pred_emsemble_v2 = np.concatenate(pred_emsemble_v2, axis = 0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>seta to khubi bhaal have!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>m mase kono ullekhayogya tapapravaher dasha an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ei sabkatai darun lagno shunate.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tar prabandh, ya ki na tar agami bayer ekati u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>bartaman mammla, njity taar ekhtiar parityag k...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>795</th>\n",
              "      <td>1997lo sanyo \"pioessiepi\" palimar tantelu chip...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>796</th>\n",
              "      <td>nenu i pradeshal gurinchi ippatike chala chadi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>797</th>\n",
              "      <td>gurtunda, edadi kindat me kolig biknu kalcharu.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>798</th>\n",
              "      <td>bharatvaesha gopp vaividhya-vyatyasabharit bhumi.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>799</th>\n",
              "      <td>repe ambedkar jayanti!</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>800 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  text\n",
              "0                            seta to khubi bhaal have!\n",
              "1    m mase kono ullekhayogya tapapravaher dasha an...\n",
              "2                     ei sabkatai darun lagno shunate.\n",
              "3    tar prabandh, ya ki na tar agami bayer ekati u...\n",
              "4    bartaman mammla, njity taar ekhtiar parityag k...\n",
              "..                                                 ...\n",
              "795  1997lo sanyo \"pioessiepi\" palimar tantelu chip...\n",
              "796  nenu i pradeshal gurinchi ippatike chala chadi...\n",
              "797    gurtunda, edadi kindat me kolig biknu kalcharu.\n",
              "798  bharatvaesha gopp vaividhya-vyatyasabharit bhumi.\n",
              "799                             repe ambedkar jayanti!\n",
              "\n",
              "[800 rows x 1 columns]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['ben', 'hin', 'pan', 'tam', 'tel']"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "LANGS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "1pRGuy2rqtWm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'ben', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'hin', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'hin', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tam', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel', 'tel']\n"
          ]
        }
      ],
      "source": [
        "# Mapping of integers to labels\n",
        "label_mapping = {\n",
        "    idx:name for idx, name in enumerate(LANGS)\n",
        "}\n",
        "\n",
        "# Assuming `output` is the concatenated list of integers\n",
        "labels = [label_mapping[i] for i in pred_emsemble_v2 ]\n",
        "\n",
        "print(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "2_Hnj_LcUTtB"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "800"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "TW93HTaCuppn"
      },
      "outputs": [],
      "source": [
        "df_test['Language'] = labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Hp_hqHS3wc_z"
      },
      "outputs": [],
      "source": [
        "df_test['Language_index']=pred_emsemble_v2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>Language</th>\n",
              "      <th>Language_index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>seta to khubi bhaal have!</td>\n",
              "      <td>ben</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>m mase kono ullekhayogya tapapravaher dasha an...</td>\n",
              "      <td>ben</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ei sabkatai darun lagno shunate.</td>\n",
              "      <td>ben</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tar prabandh, ya ki na tar agami bayer ekati u...</td>\n",
              "      <td>ben</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>bartaman mammla, njity taar ekhtiar parityag k...</td>\n",
              "      <td>ben</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>795</th>\n",
              "      <td>1997lo sanyo \"pioessiepi\" palimar tantelu chip...</td>\n",
              "      <td>tel</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>796</th>\n",
              "      <td>nenu i pradeshal gurinchi ippatike chala chadi...</td>\n",
              "      <td>tel</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>797</th>\n",
              "      <td>gurtunda, edadi kindat me kolig biknu kalcharu.</td>\n",
              "      <td>tel</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>798</th>\n",
              "      <td>bharatvaesha gopp vaividhya-vyatyasabharit bhumi.</td>\n",
              "      <td>tel</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>799</th>\n",
              "      <td>repe ambedkar jayanti!</td>\n",
              "      <td>tel</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>800 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  text Language  \\\n",
              "0                            seta to khubi bhaal have!      ben   \n",
              "1    m mase kono ullekhayogya tapapravaher dasha an...      ben   \n",
              "2                     ei sabkatai darun lagno shunate.      ben   \n",
              "3    tar prabandh, ya ki na tar agami bayer ekati u...      ben   \n",
              "4    bartaman mammla, njity taar ekhtiar parityag k...      ben   \n",
              "..                                                 ...      ...   \n",
              "795  1997lo sanyo \"pioessiepi\" palimar tantelu chip...      tel   \n",
              "796  nenu i pradeshal gurinchi ippatike chala chadi...      tel   \n",
              "797    gurtunda, edadi kindat me kolig biknu kalcharu.      tel   \n",
              "798  bharatvaesha gopp vaividhya-vyatyasabharit bhumi.      tel   \n",
              "799                             repe ambedkar jayanti!      tel   \n",
              "\n",
              "     Language_index  \n",
              "0                 0  \n",
              "1                 0  \n",
              "2                 0  \n",
              "3                 0  \n",
              "4                 0  \n",
              "..              ...  \n",
              "795               4  \n",
              "796               4  \n",
              "797               4  \n",
              "798               4  \n",
              "799               4  \n",
              "\n",
              "[800 rows x 3 columns]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
